{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize"
      ],
      "metadata": {
        "id": "WtZ-Zwt51Gak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "9EBxR7VG1Kq-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRJDpOJo05Yg"
      },
      "outputs": [],
      "source": [
        "# Google-Drive Mounting\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Pandas, numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Sklearn (Performance Metric Calculation)\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, cohen_kappa_score\n",
        "\n",
        "#Random for setting seeds\n",
        "import random\n",
        "\n",
        "#Import pickle\n",
        "import pickle\n",
        "\n",
        "#Import widgets\n",
        "import ipywidgets\n",
        "\n",
        "#NLTK\n",
        "!pip install nltk\n",
        "import nltk\n",
        "\n",
        "#HanTa (Hannover Tager) (for Lemmatization)\n",
        "!pip install HanTa\n",
        "from HanTa import HanoverTagger as ht\n",
        "\n",
        "#Import catboost\n",
        "!pip install catboost\n",
        "from catboost.text_processing import Tokenizer, Dictionary\n",
        "from catboost import CatBoostClassifier, Pool, metrics, cv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting"
      ],
      "metadata": {
        "id": "xGsU4Ofr1V0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google-Drive Mounting\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Working Directory\n",
        "os.chdir('drive/MyDrive')\n",
        "!ls"
      ],
      "metadata": {
        "id": "BztA0uam1Xa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read data"
      ],
      "metadata": {
        "id": "t-8KxpOK1aCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read: BBGCPure with Finetuning and without data augmentation"
      ],
      "metadata": {
        "id": "iJRRzK6c1dHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Path\n",
        "abspath = os.path.abspath('0_Ergebnisse/220402_0_bbgc_pure_train_fulldataset.pkl')\n",
        "\n",
        "# pkl\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  training_bbgcpure = pickle.load(pkl)\n",
        "\n",
        "#Path\n",
        "abspath = os.path.abspath('0_Ergebnisse/220402_0_bbgc_pure_test_fulldataset.pkl')\n",
        "\n",
        "# pkl\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  testing_bbgcpure = pickle.load(pkl)\n",
        "\n",
        "#Path\n",
        "abspath = os.path.abspath('0_Ergebnisse/220402_0_bbgc_pure_valid_fulldataset.pkl')\n",
        "\n",
        "# pkl\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  validation_bbgcpure = pickle.load(pkl)"
      ],
      "metadata": {
        "id": "5Vwwr0dI18kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "uz_k-8Ji2rTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General function: Text preprocessing"
      ],
      "metadata": {
        "id": "mkZH6I09KUWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Align / correct accident descriptions\n",
        "def correct_participant(df):\n",
        "  df_new = df.copy()\n",
        "  #Replace certain words, but not case sensitive -> lower / upper cases do not matter\n",
        "  #Participant 1\n",
        "  df_new[\"Description\"]= df_new[\"Description\"].str.replace(\"ON 01\", \"Beteiligter 1\", case = False)\n",
        "  df_new[\"Description\"]= df_new[\"Description\"].str.replace(\"ON01\", \"Beteiligter 1\", case = False)\n",
        "  df_new[\"Description\"]= df_new[\"Description\"].str.replace(\"01\", \"Beteiligter 1\", case = False)\n",
        "  df_new[\"Description\"]= df_new[\"Description\"].str.replace(\"Teilnehmer 1\", \"Beteiligter 1\", case = False) #relevant für data augmentation\n",
        "  #Participant 2\n",
        "  df_new[\"Description\"]= df_new[\"Description\"].str.replace(\"ON 02\", \"Beteiligter 2\", case = False)\n",
        "  df_new[\"Description\"]= df_new[\"Description\"].str.replace(\"ON02\", \"Beteiligter 2\", case = False)\n",
        "  df_new[\"Description\"]= df_new[\"Description\"].str.replace(\"02\", \"Beteiligter 2\", case = False)\n",
        "  df_new[\"Description\"]= df_new[\"Description\"].str.replace(\"Teilnehmer 2\", \"Beteiligter 2\", case = False) #relevant für data augmentation\n",
        "  ##_x000D_\n",
        "  df_new[\"Description\"] = df_new[\"Description\"].str.replace(\"_x000D_\", \" \", case = False)\n",
        "  df_new[\"Description\"] = df_new[\"Description\"].str.replace(\"\\n\", \" \", case = False)\n",
        "  #Return\n",
        "  return df_new\n",
        "\n",
        "#Correct empty accident descriptions\n",
        "def correct_na(df):\n",
        "  df.Description = df.Description.fillna('Keine Unfallbeschreibung vorhanden.')\n",
        "  return df\n",
        "\n",
        "#Split into single paragraphs\n",
        "def split_paragraphs(data):\n",
        "  #Donwload nltk\n",
        "  nltk.download(\"punkt\")\n",
        "  #Split into list of sentences\n",
        "  data[\"Description\"] = data.apply(lambda row: nltk.tokenize.sent_tokenize(row[\"Description\"]), axis = 1)\n",
        "  return data\n",
        "\n",
        "\n",
        "#Main function\n",
        "def main_correct(df):\n",
        "  #Align accident descriptions\n",
        "  df_lang = correct_participant(df)\n",
        "  #Correct empty accident descriptions\n",
        "  df_na = correct_na(df_lang)\n",
        "  #Split into single paragraphs\n",
        "  #df_split = split_paragraphs(df_na)\n",
        "  #Rückgabe\n",
        "  return df_na\n"
      ],
      "metadata": {
        "id": "zlL874ypKZYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General functions"
      ],
      "metadata": {
        "id": "mIXehOOQ85dW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#General functions\n",
        "\n",
        "#Force pandas to show all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "#List with all 47 possible 3ATs\n",
        "classes_list = [201, 202, 203, 204, 209,\n",
        "                211, 212, 213, 214, 215, 219,\n",
        "                221, 222, 223, 224, 225, 229,\n",
        "                231, 232, 233, 239,\n",
        "                241, 242, 243, 244, 245, 249,\n",
        "                251, 252, 259,\n",
        "                261, 262, 269,\n",
        "                271, 272, 273, 274, 275, 279,\n",
        "                281, 282, 283, 284, 285, 286, 289,\n",
        "                299]\n",
        "\n",
        "#Recode\n",
        "def recode(df, classes_list):\n",
        "  #Copy existing dataframe\n",
        "  df_new = df.copy()\n",
        "  #Set labels to zero according to classlist\n",
        "  df_new['AccidentType'] = df_new.apply(lambda x: classes_list.index(x['AccidentType']), axis = 1)\n",
        "  return df_new\n",
        "\n",
        "\n",
        "\n",
        "#Find variables with missing values\n",
        "def find_missingvalues(data):\n",
        "  null_value_stats = data.isnull().sum(axis=0)\n",
        "  result = null_value_stats[null_value_stats != 0]\n",
        "  #Print\n",
        "  #print(result)\n",
        "\n",
        "#Replace missing values with 9999\n",
        "def fill_na(data, fillna):\n",
        "  #df = data.copy()\n",
        "  if (fillna):\n",
        "    #Fill all NA with 9999\n",
        "    na_values_filled = data.fillna(\"-9999\")\n",
        "    df = na_values_filled\n",
        "    #Fill all NaN with 9999\n",
        "    #df = df.replace(np.na, -9999)\n",
        "  return df\n",
        "\n",
        "\n",
        "#Delete unnecessary columns not needed for prediction\n",
        "def delete_columns(data, twodigit, threedigit):\n",
        "  #Copy\n",
        "  df = data.copy()\n",
        "  #Delete ID\n",
        "  df.drop('ID', inplace = True, axis = 1)\n",
        "  #Delete Year: Prediction should not dependent on the year!\n",
        "  df.drop('Year', inplace = True, axis = 1)\n",
        "  #Delete Hour (is redundant, due to variable HourMinute)\n",
        "  df.drop('Hour', inplace = True, axis = 1)\n",
        "  #Delete Accidenttypetwo (if boolean = yes)\n",
        "  if (twodigit):\n",
        "    df.drop('AccidentType2', inplace = True, axis = 1)\n",
        "  #Delete accdienttypethree (if boolean = yes)\n",
        "  if (threedigit):\n",
        "    df.drop('AccidentType', inplace = True, axis = 1)\n",
        "  #Delete Accident Description\n",
        "  #if (nodescription):\n",
        "    #df.drop('Description', inplace = True, axis = 1)\n",
        "  #Return\n",
        "  new = df.copy()\n",
        "  return new\n",
        "\n",
        "\n",
        "\n",
        "#Convert string objects to integers (i.e. categorical variables)\n",
        "def convert_strings(data, cat_columns):\n",
        "  #Copy\n",
        "  df = data.copy()\n",
        "  #Convert the object columns to integers, based on the index of the categorical values and transform it then to categories\n",
        "  df.loc[:, cat_columns] = df.loc[:, cat_columns].apply(lambda col:pd.Categorical(col).codes)\n",
        "  df.loc[:, cat_columns] = df.loc[:, cat_columns].apply(lambda col:col.astype(\"category\"))\n",
        "  #Convert the wrongly classified object columns to numerical ones\n",
        "  df.loc[:, num_columns] = df.loc[:, num_columns].apply(lambda col:col.astype(\"int\"))\n",
        "  #Return\n",
        "  return df\n",
        "\n",
        "\n",
        "#Classify all categorical variables as categorical (important for later prediction)\n",
        "def classify_categorical(data, cat_columns):\n",
        "  #Copy\n",
        "  df = data.copy()\n",
        "  #Convert to categorical type\n",
        "  df.loc[:, cat_columns] = df.loc[:, cat_columns].apply(lambda col:col.astype(\"category\"))\n",
        "  #Return\n",
        "  return df\n",
        "\n",
        "\n",
        "#Numerical features must be treated as embedding\n",
        "def convert_to_embedding(data):\n",
        "  #Make copy\n",
        "  df = data.copy()\n",
        "  #Concatenate all 768 columns of Bert-Feature into one column to be able to treat it as embedding\n",
        "  df['Embedding'] = df.select_dtypes(include = ['float32']).apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)\n",
        "  #Drop all 768 columns\n",
        "  df = df.select_dtypes(exclude = ['float32'])\n",
        "  #Convert embedding column to list of floats\n",
        "  df.loc[:, 'Embedding'] = df.loc[:, 'Embedding'].apply(lambda col: [float(item) for item in col.split(sep=\",\") ])\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "#Main function\n",
        "def main_prepare(data, fillna, twodigit, threedigit, cat_columns):\n",
        "  #Print missing values\n",
        "  find_missingvalues(data)\n",
        "  #Correct text (see general functions \"Text preprocessing\")\n",
        "  df = main_correct(data)\n",
        "  #Recode accidenttype / labels\n",
        "  df = recode(df, classes_list)\n",
        "  #Replace missing values\n",
        "  df = fill_na(df, fillna)\n",
        "  #Convert strings to integers and classify them as category\n",
        "  df = convert_strings(df, cat_columns)\n",
        "  #Classify categorical\n",
        "  #df = classify_categorical(df, cat_columns)\n",
        "  #Convert BERT-columns (768 columns) to one embedding\n",
        "  df = convert_to_embedding(df)\n",
        "  #Delete unnecessary columns\n",
        "  df = delete_columns(df, twodigit, threedigit)\n",
        "  #Return\n",
        "  return df\n",
        ""
      ],
      "metadata": {
        "id": "N-_5JsnD4oMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare: BBGCPure with Finetuning and without data augmentation"
      ],
      "metadata": {
        "id": "di53rq61IaxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorical columns\n",
        "cat_columns = [\"Month\", \"Weekday\", \"StreetClass\", \"RoadCondition\", \"LightCondition\", \"Weather\" , \"Obstacle\",\"Urban\", \"Rural\", \"CyclePath\", \"Sidewalk\", \"TrafficLightOn\", \"TrafficLightOff\", \"Alcohol\", \"Drugs\", \"Medicines\", \"SpeedLimit\", \"HitAndRun\", \"CollisionType\",\"Cause\", \"Participant1\", \"InjuryP1\", \"CauseP1\",\"Participant2\", \"CauseP2\", \"InjuryP2\"]\n",
        "num_columns = [\"AgeP1\", \"AgeP2\", \"PropertyDamage\", \"TextLength\"]\n",
        "text_columns = [\"Description\"]\n",
        "emb_columns = [\"Embedding\"]\n",
        "\n",
        "\n",
        "#Datasets with only three digit accident types (twodigit is deleted), with replaced values\n",
        "train_bbgcpure_three = main_prepare(training_bbgcpure, True, True, False, cat_columns)\n",
        "test_bbgcpure_three = main_prepare(testing_bbgcpure, True, True, False,  cat_columns)\n",
        "valid_bbgcpure_three = main_prepare(validation_bbgcpure, True, True, False,  cat_columns)\n",
        "\n",
        "#Datasets with only two digit accident types (threedigit is deleted), with replaced values\n",
        "train_bbgcpure_two = main_prepare(training_bbgcpure, True, False, True,  cat_columns)\n",
        "test_bbgcpure_two = main_prepare(testing_bbgcpure, True, False, True, cat_columns)\n",
        "valid_bbgcpure_two = main_prepare(validation_bbgcpure, True, False, True,  cat_columns)\n",
        "\n",
        "#Head\n",
        "train_bbgcpure_three.head()"
      ],
      "metadata": {
        "id": "9_CZ3DSn2u69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate features and label variable\n",
        "\n",
        "#List with different subset of variables\n",
        "cat_num_col = cat_columns + num_columns\n",
        "cat_num_txt_col = cat_columns + num_columns + text_columns\n",
        "\n",
        "#3-digit\n",
        "X_train_three_all = train_bbgcpure_three.drop(columns = [\"AccidentType\"])\n",
        "X_train_three = train_bbgcpure_three.drop(columns = [\"AccidentType\", \"Description\"]) #without desription\n",
        "X_train_three_num = train_bbgcpure_three.select_dtypes(include=['float32']) #Just numerical features\n",
        "X_train_three_cat = train_bbgcpure_three.filter(cat_num_col) #All features except numerical features, but no description\n",
        "X_train_three_cat_txt = train_bbgcpure_three.filter(cat_num_txt_col) #All features except numerical features, and with description\n",
        "Y_train_three = train_bbgcpure_three.AccidentType\n",
        "\n",
        "X_test_three_all = test_bbgcpure_three.drop(columns = [\"AccidentType\"])\n",
        "X_test_three = test_bbgcpure_three.drop(columns = [\"AccidentType\", \"Description\"]) #without desription\n",
        "X_test_three_num = test_bbgcpure_three.select_dtypes(include=['float32']) #Just numerical features\n",
        "X_test_three_cat = test_bbgcpure_three.filter(cat_num_col) #All features except numerical features, but no description\n",
        "X_test_three_cat_txt = test_bbgcpure_three.filter(cat_num_txt_col) #All features except numerical features, and with description\n",
        "Y_test_three = test_bbgcpure_three.AccidentType\n",
        "\n",
        "X_valid_three_all = valid_bbgcpure_three.drop(columns = [\"AccidentType\"])\n",
        "X_valid_three = valid_bbgcpure_three.drop(columns = [\"AccidentType\", \"Description\"]) #without desription\n",
        "X_valid_three_num = valid_bbgcpure_three.select_dtypes(include=['float32']) #Just numerical features\n",
        "X_valid_three_cat = valid_bbgcpure_three.filter(cat_num_col) #All features except numerical features, but no description\n",
        "X_valid_three_cat_txt = valid_bbgcpure_three.filter(cat_num_txt_col) #All features except numerical features, and with description\n",
        "Y_valid_three = valid_bbgcpure_three.AccidentType\n",
        "\n",
        "\n",
        "#2-digit\n",
        "X_train_two_all = train_bbgcpure_two.drop(columns = [\"AccidentType2\"])\n",
        "X_train_two = train_bbgcpure_two.drop(columns = [\"AccidentType2\", \"Description\"]) #without desription\n",
        "X_train_two_num = train_bbgcpure_two.select_dtypes(include=['float32']) #Just numerical features\n",
        "X_train_two_cat = train_bbgcpure_two.filter(cat_num_col) #All features except numerical features, but no description\n",
        "X_train_two_cat_txt = train_bbgcpure_two.filter(cat_num_txt_col) #All features except numerical features, and with description\n",
        "Y_train_two = train_bbgcpure_two.AccidentType2\n",
        "\n",
        "X_test_two_all = test_bbgcpure_two.drop(columns = [\"AccidentType2\"])\n",
        "X_test_two = test_bbgcpure_two.drop(columns = [\"AccidentType2\", \"Description\"]) #without desription\n",
        "X_test_two_num = test_bbgcpure_two.select_dtypes(include=['float32']) #Just numerical features\n",
        "X_test_two_cat = test_bbgcpure_two.filter(cat_num_col) #All features except numerical features, but no description\n",
        "X_test_two_cat_txt = test_bbgcpure_two.filter(cat_num_txt_col) #All features except numerical features, and with description\n",
        "Y_test_two = test_bbgcpure_two.AccidentType2\n",
        "\n",
        "X_valid_two_all = valid_bbgcpure_two.drop(columns = [\"AccidentType2\"])\n",
        "X_valid_two = valid_bbgcpure_two.drop(columns = [\"AccidentType2\", \"Description\"]) #without desription\n",
        "X_valid_two_num = valid_bbgcpure_two.select_dtypes(include=['float32']) #Just numerical features\n",
        "X_valid_two_cat = valid_bbgcpure_two.filter(cat_num_col) #All features except numerical features, but no description\n",
        "X_valid_two_cat_txt = valid_bbgcpure_two.filter(cat_num_txt_col) #All features except numerical features, and with description\n",
        "Y_valid_two = valid_bbgcpure_two.AccidentType2"
      ],
      "metadata": {
        "id": "4nCYW6Tp4crw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect dataset\n",
        "#Head\n",
        "Y_train_three.head()\n",
        "#Variable types\n",
        "#X_train_three.info(verbose = True)"
      ],
      "metadata": {
        "id": "MkzPDRHf6QZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_three.head()"
      ],
      "metadata": {
        "id": "Ygd84i2Jd-BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CatBoost: Text preprocessing"
      ],
      "metadata": {
        "id": "caaxG_39MVN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions for Tokenizing, Dictionary, etc.\n",
        "\n",
        "\n",
        "#Initialize Tokenizer\n",
        "#https://catboost.ai/en/docs/concepts/python-reference_tokenizer\n",
        "tokenizer = Tokenizer(\n",
        "        separator_type = 'BySense',\n",
        "        lowercasing = True,\n",
        "        number_process_policy = \"LeaveAsIs\",\n",
        "        skip_empty = True,\n",
        "        token_types = ['Word', 'Number', 'SentenceBreak', 'ParagraphBreak'],\n",
        "        sub_tokens_policy = 'SeveralTokens')\n",
        "\n",
        "\n",
        "def tokenize_data(df, tokenizer):\n",
        "  #Copy\n",
        "  df_new = df.copy()\n",
        "  #Tokenize\n",
        "  df_new['Description'] = df_new.apply(lambda x: tokenizer.tokenize(x['Description']), axis = 1)\n",
        "  #Return\n",
        "  return df_new\n",
        "\n",
        "\n",
        "def lemmatize_sentence(tokenlist):\n",
        "  #Load trained model\n",
        "  tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
        "  #Lemmatize\n",
        "  tokens = [tagger.analyze(word, taglevel = 1) for word in tokenlist]\n",
        "  #Lemmas, without POS\n",
        "  lemmalist = [lemma[0] for lemma in tokens]\n",
        "  #Return\n",
        "  return lemmalist\n",
        "\n",
        "\n",
        "def lemmatize_data(df):\n",
        "  #https://textmining.wp.hs-hannover.de/Preprocessing.html (HanTa = HannoverTagger, published in 2019 here: https://doi.org/10.25968/opus-1527 )\n",
        "  #Copy\n",
        "  df_new = df.copy()\n",
        "  # Iterate over data frame and apply lemmatization\n",
        "  df_new[\"Description\"] = df_new.apply(lambda x: lemmatize_sentence(x[\"Description\"]), axis = 1)\n",
        "  #Return\n",
        "  return df_new\n",
        "\n",
        "\n",
        "#Convert tokenized data\n",
        "#Join tokenized text again to one string\n",
        "def jointostring(df):\n",
        "  #Copy\n",
        "  df_new = df.copy()\n",
        "  #Joinstring\n",
        "  df_new[\"Description\"] = df_new.apply(lambda x: ' '.join(x[\"Description\"]), axis = 1)\n",
        "  #Return\n",
        "  return df_new\n",
        "\n",
        "\n",
        "def main_textpreprocessing(df, tokenizer, token, lemma, join):\n",
        "  #Tokenize Data\n",
        "  if token:\n",
        "    df = tokenize_data(df, tokenizer)\n",
        "  #Lemmatize Data\n",
        "  if lemma:\n",
        "    df = lemmatize_data(df)\n",
        "  #Convert it back to string (Catboost does not accept tokenized data as input, tokenizer must be defined within catboost)\n",
        "  #But at least the data is not lemmatized.\n",
        "  if join:\n",
        "    df = jointostring(df)\n",
        "  #Return\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "1V1158cqPw0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess data for prediction: 3-digit-accident type (3AT)\n",
        "#The text data is tokenized, then lemmatized (only possible if tokenized) and then de-tokenized again, as the actual tokenizer must be addressed directly via Catboost.\n",
        "#This is, so to speak, a detour for lemmatization.\n",
        "\n",
        "#Training data\n",
        "X_train_three_all_pre = main_textpreprocessing(X_train_three_all, tokenizer, token = True, lemma = True, join = True)\n",
        "#Test data\n",
        "X_test_three_all_pre = main_textpreprocessing(X_test_three_all, tokenizer, token = True, lemma = True, join = True)\n",
        "#Validation data\n",
        "X_valid_three_all_pre = main_textpreprocessing(X_valid_three_all, tokenizer, token = True, lemma = True, join = True)"
      ],
      "metadata": {
        "id": "t-iuuDUjTbgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess data for prediction: 2-digit-accident type (2AT)\n",
        "#The text data is tokenized, then lemmatized (only possible if tokenized) and then de-tokenized again, as the actual tokenizer must be addressed directly via Catboost.\n",
        "#This is, so to speak, a detour for lemmatization.\n",
        "\n",
        "#Training data\n",
        "X_train_two_all_pre = main_textpreprocessing(X_train_two_all, tokenizer, token = True, lemma = True, join = True)\n",
        "#Test data\n",
        "X_test_two_all_pre = main_textpreprocessing(X_test_two_all, tokenizer, token = True, lemma = True, join = True)\n",
        "#Validation data\n",
        "X_valid_two_all_pre = main_textpreprocessing(X_valid_two_all, tokenizer, token = True, lemma = True, join = True)"
      ],
      "metadata": {
        "id": "ect6ywDp8vr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save preprocessed data: 3-digit-accident type (3AT)\n",
        "\n",
        "#Training data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_train_three_all_pre.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(X_train_three_all_pre, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_train_three.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(Y_train_three, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#Test data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_test_three_all_pre.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(X_test_three_all_pre, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_test_three.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(Y_test_three, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#Validation data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_valid_three_all_pre.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(X_valid_three_all_pre, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_valid_three.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(Y_valid_three, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "1KBmXBXTdRbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save preprocessed data: 2-digit-accident type (2AT)\n",
        "\n",
        "#Training data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_train_two_all_pre.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(X_train_two_all_pre, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_train_two.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(Y_train_two, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#Test data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_test_two_all_pre.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(X_test_two_all_pre, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_test_two.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(Y_test_two, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#Validation data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_valid_two_all_pre.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(X_valid_two_all_pre, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_valid_two.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(Y_valid_two, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "Ecz17EvG893q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CatBoost: Load preprocessed data"
      ],
      "metadata": {
        "id": "ZOg50tu6FH-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "iXBfP9K0ypLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import preprocessed data: 3-digit accident type (3AT)\n",
        "\n",
        "#Training data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_train_three_all_pre.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  X_train_three_all_pre = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_train_three.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  Y_train_three = pickle.load(pkl)\n",
        "\n",
        "#Test data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_test_three_all_pre.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  X_test_three_all_pre = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_test_three.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  Y_test_three = pickle.load(pkl)\n",
        "\n",
        "#Validation data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_valid_three_all_pre.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  X_valid_three_all_pre = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_valid_three.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  Y_valid_three = pickle.load(pkl)"
      ],
      "metadata": {
        "id": "gOcccc6lhYpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import preprocessed data: 2-digit accident type (2AT)\n",
        "\n",
        "#Training data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_train_two_all_pre.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  X_train_two_all_pre = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_train_two.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  Y_train_two = pickle.load(pkl)\n",
        "\n",
        "#Test data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_test_two_all_pre.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  X_test_two_all_pre = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_test_two.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  Y_test_two = pickle.load(pkl)\n",
        "\n",
        "#Validation data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_valid_two_all_pre.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  X_valid_two_all_pre = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_valid_two.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  Y_valid_two = pickle.load(pkl)"
      ],
      "metadata": {
        "id": "1KtpVISzfgeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes"
      ],
      "metadata": {
        "id": "LnV4t76JyrZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#List with all possible 47 accident types\n",
        "classes_list = [201, 202, 203, 204, 209,\n",
        "                211, 212, 213, 214, 215, 219,\n",
        "                221, 222, 223, 224, 225, 229,\n",
        "                231, 232, 233, 239,\n",
        "                241, 242, 243, 244, 245, 249,\n",
        "                251, 252, 259,\n",
        "                261, 262, 269,\n",
        "                271, 272, 273, 274, 275, 279,\n",
        "                281, 282, 283, 284, 285, 286, 289,\n",
        "                299]\n",
        "\n",
        "#Column specifications\n",
        "cat_columns = [\"Month\", \"Weekday\", \"StreetClass\", \"RoadCondition\", \"LightCondition\", \"Weather\" , \"Obstacle\",\"Urban\", \"Rural\", \"CyclePath\", \"Sidewalk\", \"TrafficLightOn\", \"TrafficLightOff\", \"Alcohol\", \"Drugs\", \"Medicines\", \"SpeedLimit\", \"HitAndRun\", \"CollisionType\",\"Cause\", \"Participant1\", \"InjuryP1\", \"CauseP1\",\"Participant2\", \"CauseP2\", \"InjuryP2\"]\n",
        "num_columns = [\"AgeP1\", \"AgeP2\", \"PropertyDamage\", \"TextLength\"]\n",
        "text_columns = [\"Description\"]\n",
        "emb_columns = [\"Embedding\"]"
      ],
      "metadata": {
        "id": "23-mmNvbN-tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class weights"
      ],
      "metadata": {
        "id": "d62ooXltytKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to get class weights\n",
        "\n",
        "def get_weights(Y_data):\n",
        "  #get weigths\n",
        "  weights = class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(Y_data), y = Y_data)\n",
        "\n",
        "  #Convert to interpretable dict\n",
        "  classes = list(np.unique(Y_data))\n",
        "  class_weights = dict(zip(classes, weights))\n",
        "\n",
        "  #Return\n",
        "  return class_weights\n",
        "\n",
        "#2-digit (2AT)\n",
        "Y_train_two_weights_balanced = get_weights(Y_train_two)\n",
        "print(Y_train_two_weights_balanced)\n",
        "#3-digit (3AT)\n",
        "Y_train_three_weights_balanced = get_weights(Y_train_three)\n",
        "print(Y_train_three_weights_balanced)"
      ],
      "metadata": {
        "id": "AImomP7eYFlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling"
      ],
      "metadata": {
        "id": "h2zy09egyvd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pool data: 3-digit-accident type (3AT)\n",
        "train_three_data = Pool(X_train_three_all_pre,\n",
        "                  label = Y_train_three,\n",
        "                  cat_features = [X_train_three_all_pre.columns.get_loc(c) for c in cat_columns if c in X_train_three_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])\n",
        "\n",
        "\n",
        "test_three_data = Pool(X_test_three_all_pre,\n",
        "                  label = Y_test_three,\n",
        "                  cat_features = [X_test_three_all_pre.columns.get_loc(c) for c in cat_columns if c in X_test_three_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])\n",
        "\n",
        "\n",
        "valid_three_data = Pool(X_valid_three_all_pre,\n",
        "                  label = Y_valid_three,\n",
        "                  cat_features = [X_valid_three_all_pre.columns.get_loc(c) for c in cat_columns if c in X_valid_three_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])\n",
        ""
      ],
      "metadata": {
        "id": "ehwhTPfpFUV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_two_all_pre"
      ],
      "metadata": {
        "id": "SlXslP4vYsla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pool data: 2-digit-accident type (2AT)\n",
        "train_two_data = Pool(X_train_two_all_pre,\n",
        "                  label = Y_train_two,\n",
        "                  cat_features = [X_train_two_all_pre.columns.get_loc(c) for c in cat_columns if c in X_train_two_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])\n",
        "\n",
        "\n",
        "test_two_data = Pool(X_test_two_all_pre,\n",
        "                  label = Y_test_two,\n",
        "                  cat_features = [X_test_two_all_pre.columns.get_loc(c) for c in cat_columns if c in X_test_two_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])\n",
        "\n",
        "\n",
        "valid_two_data = Pool(X_valid_two_all_pre,\n",
        "                  label = Y_valid_two,\n",
        "                  cat_features = [X_valid_two_all_pre.columns.get_loc(c) for c in cat_columns if c in X_valid_two_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])"
      ],
      "metadata": {
        "id": "IS-hJDZRFUjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Catboost: Experiments with flat model design"
      ],
      "metadata": {
        "id": "tywws6xtLiNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic model configuration"
      ],
      "metadata": {
        "id": "_0ZSC8BhLucT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic model initialization\n",
        "\n",
        "#https://catboost.ai/en/docs/references/text-processing__specification-example\n",
        "\n",
        "#Training parameters: https://catboost.ai/en/docs/references/training-parameters/\n",
        "\n",
        "\n",
        "\n",
        "def fit_model(train_pool, test_pool, **kwargs):\n",
        "    model = CatBoostClassifier(\n",
        "        loss_function = \"MultiClass\",\n",
        "        random_seed = 42,\n",
        "        eval_metric='Accuracy',\n",
        "        **kwargs,\n",
        "        #################\n",
        "        l2_leaf_reg = 3.0, #Default value is 3.0 and gives best values.\n",
        "        depth = 5, #5 =84,0% / depth 10 is too slow and bad. / default value = 6\n",
        "        one_hot_max_size = 0, #This means that no feature is one-hot-encoded -> default value is different from 0\n",
        "        bootstrap_type = 'Bayesian', #Bernoulli, Poisson and NO worse than Bayesian, MVS not for Multiclass GPU -> default = Bayesian\n",
        "        bagging_temperature = 0.7, #Just for Bayesian bootstrap, default value = 1\n",
        "        sampling_frequency = 'PerTree', #Default level = PerTreeLevel\n",
        "        sampling_unit = 'Object',\n",
        "        grow_policy = 'SymmetricTree',\n",
        "        has_time = False,\n",
        "        leaf_estimation_method = 'Newton',\n",
        "        #leaf_estimation_iterations = 5,\n",
        "        fold_len_multiplier = 2,\n",
        "        approx_on_full_history = False,\n",
        "        auto_class_weights = 'None',\n",
        "        boosting_type = 'Plain',\n",
        "        boost_from_average = False, #Defaul value = False\n",
        "        score_function = 'Cosine',\n",
        "        ################\n",
        "        ##Overfitting detection\n",
        "        od_type='Iter',\n",
        "        od_wait=500,\n",
        "        ################\n",
        "        tokenizers = [ {\n",
        "            \"tokenizer_id\" : \"Sense\",\n",
        "            \"separator_type\" : \"BySense\",\n",
        "            \"lowercasing\" : \"true\",\n",
        "            \"number_process_policy\": \"LeaveAsIs\",\n",
        "            \"skip_empty\": 'true',\n",
        "            'token_types':['Word', 'Number', 'SentenceBreak', 'ParagraphBreak'],\n",
        "            'sub_tokens_policy': 'SeveralTokens',\n",
        "        }],\n",
        "\n",
        "        dictionaries = [{\n",
        "            \"dictionary_id\" : \"BiGram\",\n",
        "            \"gram_order\" : \"2\",\n",
        "            'min_token_occurence': '1',\n",
        "            'max_dictionary_size': '150000'\n",
        "        }, {\n",
        "            \"dictionary_id\" : \"Word\",\n",
        "            \"gram_order\" : \"1\",\n",
        "            'min_token_occurence': '1',\n",
        "            'max_dictionary_size': '150000'\n",
        "        }],\n",
        "\n",
        "        feature_calcers = [\n",
        "                          'BoW:top_tokens_count=1000',\n",
        "                          'BoW:dictionary_names=BiGram',\n",
        "                          'NaiveBayes:top_tokens_count=1000',\n",
        "                          'NaiveBayes:dictionary_names=Word',\n",
        "                          'BM25:top_tokens_count=1000',\n",
        "                          'BM25:dictionary_names=Word'\n",
        "\n",
        "\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model.fit(\n",
        "        train_pool,\n",
        "        eval_set=test_pool,\n",
        "        verbose=50,\n",
        "        plot=True,\n",
        "        use_best_model=True)\n"
      ],
      "metadata": {
        "id": "d4mhBeQ4Gw4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to get classification report with correct accident type labels\n",
        "\n",
        "def get_report(true, pred, labellist=None):\n",
        "  #Get initial report\n",
        "  report = classification_report(true, pred, output_dict=True, labels = np.unique(true))\n",
        "  #Transform it to pandas\n",
        "  report_pd = pd.DataFrame(report).transpose()\n",
        "  #Get true labels\n",
        "  if labellist != None:\n",
        "    #Get indicies\n",
        "    index_list = list(report_pd.index)\n",
        "    #Remove last three leements\n",
        "    index_list_short = index_list[:len(index_list)-3]\n",
        "    #Convert list elements to integer\n",
        "    index_list_short = [int(x) for x in index_list_short]\n",
        "    #Get true class labels based on index\n",
        "    label_series = pd.Series(labellist)\n",
        "    true_labels = list(label_series[index_list_short])\n",
        "    #Get new classification report with correct labels\n",
        "    report_new = classification_report(true, pred, output_dict=True, target_names = true_labels)\n",
        "    #Transform to pandas again\n",
        "    report_new_pd = pd.DataFrame(report_new).transpose()\n",
        "    #Print report\n",
        "    print(report_new_pd)\n",
        "    #Return\n",
        "    return true_labels, report_new_pd\n",
        "  else:\n",
        "    print(report_pd)\n",
        "    return report_pd"
      ],
      "metadata": {
        "id": "6K8HX1vKe539"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##V1: Catboost kct/num\n",
        "\n",
        "Catboost model trained in basic configuration just with categorical / numerical data, but without embeddings and without text data (accident description)."
      ],
      "metadata": {
        "id": "xSvts7PRM9rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "#Training parameters: https://catboost.ai/en/docs/references/training-parameters/\n",
        "\n",
        "\n",
        "model_v1 = fit_model(\n",
        "    ################\n",
        "    train_three_data, test_three_data,\n",
        "    ignored_features = [\"Embedding\", \"Description\"],\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "xrpwwUHTpzh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_v1.save_model('0_Ergebnisse/Catboost/models/V1_220627_model_0.6891241578', format = \"cbm\")"
      ],
      "metadata": {
        "id": "kGov1y7vu06g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "v1_test_pred_class = model_v1.predict(test_three_data)\n",
        "#Report\n",
        "v1_test_labels, v1_test_report = get_report( Y_test_three, v1_test_pred_class, classes_list)\n",
        "#Save\n",
        "v1_test_report.to_pickle('0_Ergebnisse/Catboost/results/V1_220627_test_report_0.6891241578')"
      ],
      "metadata": {
        "id": "fGXS_Vy8P86j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "v1_valid_pred_class = model_v1.predict(valid_three_data)\n",
        "#Report\n",
        "v1_valid_labels, v1_valid_report = get_report(Y_valid_three, v1_valid_pred_class, classes_list)\n"
      ],
      "metadata": {
        "id": "65MfV05xi38J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "v1_valid_report.to_pickle('0_Ergebnisse/Catboost/results/V1_220627_valid_report_0.635688')"
      ],
      "metadata": {
        "id": "9CHQ6HMRgwhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "v1_results = pd.concat([pd.DataFrame(Y_test_three), pd.DataFrame(v1_test_pred_class),pd.DataFrame(Y_valid_three), pd.DataFrame(v1_valid_pred_class)], axis = 1)\n",
        "v1_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "v1_results.to_pickle('0_Ergebnisse/Catboost/results/V1_220627_all_results')"
      ],
      "metadata": {
        "id": "87jIY8YjQLuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V2: Catboost text\n",
        "\n",
        "Catboost model trained in basic configuration just with text (accident description) data, but without embeddings and without categorical / numerical data."
      ],
      "metadata": {
        "id": "UD3fdVuQncj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "\n",
        "model_v2 = fit_model(\n",
        "    ################\n",
        "    train_three_data, test_three_data,\n",
        "    ignored_features = cat_columns + num_columns + emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "_9sIavGbnyWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_v2.save_model('0_Ergebnisse/Catboost/models/V2_220627_model_0.8046198268', format = \"cbm\")"
      ],
      "metadata": {
        "id": "FUxlEDiUomsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "v2_test_pred_class = model_v2.predict(test_three_data)\n",
        "#Report\n",
        "v2_test_labels, v2_test_report = get_report(Y_test_three, v2_test_pred_class, classes_list)\n",
        "#Save\n",
        "v2_test_report.to_pickle('0_Ergebnisse/Catboost/results/V2_220627_test_report_0.8046198268')"
      ],
      "metadata": {
        "id": "8L6M0Zm8ov8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "v2_valid_pred_class = model_v2.predict(valid_three_data)\n",
        "#Report\n",
        "v2_valid_labels, v2_valid_report = get_report(Y_valid_three, v2_valid_pred_class, classes_list)\n"
      ],
      "metadata": {
        "id": "7xTvvjG0pFVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "v2_valid_report.to_pickle('0_Ergebnisse/Catboost/results/V2_220627_valid_report_0.790892')"
      ],
      "metadata": {
        "id": "1LydY7KnpRFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "v2_results = pd.concat([pd.DataFrame(Y_test_three), pd.DataFrame(v2_test_pred_class),pd.DataFrame(Y_valid_three), pd.DataFrame(v2_valid_pred_class)], axis = 1)\n",
        "v2_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "v2_results.to_pickle('0_Ergebnisse/Catboost/results/V2_220627_all_results')"
      ],
      "metadata": {
        "id": "-oLANvTYReO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V3a: Catboost cat/num/text without class_weights\n",
        "\n",
        "Catboost model trained in basic configuration with text (description), categorical and numerical data, but without embeddings."
      ],
      "metadata": {
        "id": "2neKhZ-Wpzzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "\n",
        "model_v3 = fit_model(\n",
        "    ################\n",
        "    train_three_data, test_three_data,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "7X9PvjcLqBlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_v3.save_model('0_Ergebnisse/Catboost/models/V3_220627_model_0.8392685274', format = \"cbm\")"
      ],
      "metadata": {
        "id": "KCYb5Fa4qxPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "v3_test_pred_class = model_v3.predict(test_three_data)\n",
        "#Report\n",
        "v3_test_labels, v3_test_report = get_report(Y_test_three, v3_test_pred_class, classes_list)\n",
        "#Save\n",
        "v3_test_report.to_pickle('0_Ergebnisse/Catboost/results/V3_220627_test_report_0.8392685274')"
      ],
      "metadata": {
        "id": "b8Hsf3ZErBj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "v3_valid_pred_class = model_v3.predict(valid_three_data)\n",
        "#Report\n",
        "v3_valid_labels, v3_valid_report = get_report(Y_valid_three, v3_valid_pred_class, classes_list)"
      ],
      "metadata": {
        "id": "_J-LhwblrXHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "v3_valid_report.to_pickle('0_Ergebnisse/Catboost/results/V3_220627_valid_report_0.808550')"
      ],
      "metadata": {
        "id": "h3cIG7ZdrmpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "v3_results = pd.concat([pd.DataFrame(Y_test_three), pd.DataFrame(v3_test_pred_class),pd.DataFrame(Y_valid_three), pd.DataFrame(v3_valid_pred_class)], axis = 1)\n",
        "v3_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "v3_results.to_pickle('0_Ergebnisse/Catboost/results/V3_220627_all_results')"
      ],
      "metadata": {
        "id": "R6b-xg7FRm7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V3b: Catboost cat/num/text with class_weights"
      ],
      "metadata": {
        "id": "tEddKjRPmSn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights_three = class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(Y_train_three), y = Y_train_three)\n",
        "\n",
        "a = list(np.unique(Y_train_three))\n",
        "b = class_weights_three\n",
        "\n",
        "class_weights_three_catboost = dict(zip(a, b))\n",
        "class_weights_three_catboost"
      ],
      "metadata": {
        "id": "cYc8FzQGmXG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "def get_class_weights(Y_train):\n",
        "  #Get class weights by sklearn function\n",
        "  cw = class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(Y_train), y = Y_train)\n",
        "  #Transform into catboost format\n",
        "  a_cw = list(np.unique(Y_train))\n",
        "  b_cw = cw\n",
        "\n",
        "  catboost_weights = dict(zip(a_cw, b_cw))\n",
        "\n",
        "  return catboost_weights\n",
        ""
      ],
      "metadata": {
        "id": "Fx3P8drtxE_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "\n",
        "model_v3b = fit_model(\n",
        "    ################\n",
        "    train_three_data, test_three_data,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = class_weights_three_catboost,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n"
      ],
      "metadata": {
        "id": "r-W6v7v1mjg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_v3b.save_model('0_Ergebnisse/Catboost/models/V3b_220629_model_0.546679376', format = \"cbm\")"
      ],
      "metadata": {
        "id": "IbWlu6sptq0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "v3b_test_pred_class = model_v3b.predict(test_three_data)\n",
        "#Report\n",
        "v3b_test_labels, v3b_test_report = get_report(Y_test_three, v3b_test_pred_class, classes_list)\n",
        "#Save\n",
        "v3b_test_report.to_pickle('0_Ergebnisse/Catboost/results/V3b_220629_test_report_0.546679376')"
      ],
      "metadata": {
        "id": "_-3zQELPud_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "v3b_valid_pred_class = model_v3b.predict(valid_three_data)\n",
        "#Report\n",
        "v3b_valid_labels, v3b_valid_report = get_report(Y_valid_three, v3b_valid_pred_class, classes_list)"
      ],
      "metadata": {
        "id": "I6PqoaUxnTsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "v3b_valid_report.to_pickle('0_Ergebnisse/Catboost/results/V3b_220629_valid_report_0.668216')"
      ],
      "metadata": {
        "id": "UTm6p4_Nuupu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "v3b_results = pd.concat([pd.DataFrame(Y_test_three), pd.DataFrame(v3b_test_pred_class),pd.DataFrame(Y_valid_three), pd.DataFrame(v3b_valid_pred_class)], axis = 1)\n",
        "v3b_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "v3b_results.to_pickle('0_Ergebnisse/Catboost/results/V3b_220629_all_results')"
      ],
      "metadata": {
        "id": "Mqc9GDi8u7C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V4: Catboost cat/num with BERT embeddings\n",
        "\n",
        "Catboost model trained in basic configuration with categorical and numerical data and with BERT embeddings, but without text (description) processed by Catboost."
      ],
      "metadata": {
        "id": "y70417T2r-2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "\n",
        "model_v4 = fit_model(\n",
        "    ################\n",
        "    train_three_data, test_three_data,\n",
        "    ignored_features = text_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='CPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "hAfcqbz3sgpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_v4.save_model('0_Ergebnisse/Catboost/models/V4_220627_model_0.7305101059', format = \"cbm\")"
      ],
      "metadata": {
        "id": "uqZaA4UexXyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "v4_test_pred_class = model_v4.predict(test_three_data)\n",
        "#Report\n",
        "v4_test_labels, v4_test_report = get_report(classes_list, Y_test_three, v4_test_pred_class)\n",
        "#Save\n",
        "v4_test_report.to_pickle('0_Ergebnisse/Catboost/results/V4_220627_test_report_0.7305101059')"
      ],
      "metadata": {
        "id": "reGUKjamxfjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "v4_valid_pred_class = model_v4.predict(valid_three_data)\n",
        "#Report\n",
        "v4_valid_labels, v4_valid_report = get_report(classes_list, Y_valid_three, v4_valid_pred_class)"
      ],
      "metadata": {
        "id": "nFq2WtAfxt8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "v4_valid_report.to_pickle('0_Ergebnisse/Catboost/results/V4_220627_valid_report_0.663569')"
      ],
      "metadata": {
        "id": "2DBMG5Wkx1ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "v4_results = pd.concat([pd.DataFrame(Y_test_three), pd.DataFrame(v4_test_pred_class),pd.DataFrame(Y_valid_three), pd.DataFrame(v4_valid_pred_class)], axis = 1)\n",
        "v4_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "v4_results.to_pickle('0_Ergebnisse/Catboost/results/V4_220627_all_results')"
      ],
      "metadata": {
        "id": "YryIvkcIRxkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V5: Catboost kat/num/text with BERT embeddings\n",
        "\n",
        "Catboost model trained in basic configuration with categorical, numerical and text data and with BERT embeddings."
      ],
      "metadata": {
        "id": "swLLoa-VyCLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "\n",
        "model_v5 = fit_model(\n",
        "    ################\n",
        "    train_three_data, test_three_data,\n",
        "    ignored_features = [],\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='CPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "5Pgw9lWxycIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_v5.save_model('0_Ergebnisse/Catboost/models/V5_220627_model_0.8267564966', format = \"cbm\")"
      ],
      "metadata": {
        "id": "SOuAjx9bynNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "v5_test_pred_class = model_v5.predict(test_three_data)\n",
        "#Report\n",
        "v5_test_labels, v5_test_report = get_report(Y_test_three, v5_test_pred_class, classes_list)\n",
        "#Save\n",
        "v5_test_report.to_pickle('0_Ergebnisse/Catboost/results/V5_220627_test_report_0.8267564966')"
      ],
      "metadata": {
        "id": "41fX7PxaysXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "v5_valid_pred_class = model_v5.predict(valid_three_data)\n",
        "#Report\n",
        "v5_valid_labels, v5_valid_report = get_report( Y_valid_three, v5_valid_pred_class, classes_list)"
      ],
      "metadata": {
        "id": "TX5VkGgpy9xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "v5_valid_report.to_pickle('0_Ergebnisse/Catboost/results/V5_220627_valid_report_0.774164')"
      ],
      "metadata": {
        "id": "rNnT5gTqzNrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "v5_results = pd.concat([pd.DataFrame(Y_test_three), pd.DataFrame(v5_test_pred_class),pd.DataFrame(Y_valid_three), pd.DataFrame(v5_valid_pred_class)], axis = 1)\n",
        "v5_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "v5_results.to_pickle('0_Ergebnisse/Catboost/results/V5_220627_all_results')"
      ],
      "metadata": {
        "id": "aHMIVznzR9rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V6: Catboost only BERT embeddings\n",
        "\n",
        "Catboost model trained only with BERT embeddings."
      ],
      "metadata": {
        "id": "p6WCe91wE1DG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "\n",
        "model_v6 = fit_model(\n",
        "    ################\n",
        "    train_three_data, test_three_data,\n",
        "    ignored_features = cat_columns + num_columns + text_columns,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='CPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "rr-45zYhFkEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_v6.save_model('0_Ergebnisse/Catboost/models/V6_220909_model_0.7074109721', format = \"cbm\")"
      ],
      "metadata": {
        "id": "M0b9eRjwLyGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "v6_test_pred_class = model_v6.predict(test_three_data)\n",
        "#Report\n",
        "v6_test_labels, v6_test_report = get_report(Y_test_three, v6_test_pred_class, classes_list)\n",
        "#Save\n",
        "v6_test_report.to_pickle('0_Ergebnisse/Catboost/results/V6_220909_test_report_0.7074109721')"
      ],
      "metadata": {
        "id": "u_HygMQpMA00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "v6_valid_pred_class = model_v6.predict(valid_three_data)\n",
        "#Report\n",
        "v6_valid_labels, v6_valid_report = get_report(Y_valid_three, v6_valid_pred_class, classes_list)"
      ],
      "metadata": {
        "id": "dzRsAkdYMS1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "v6_valid_report.to_pickle('0_Ergebnisse/Catboost/results/V6_220909_valid_report_0.682156')"
      ],
      "metadata": {
        "id": "ZqqKc7K6Mfzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "v6_results = pd.concat([pd.DataFrame(Y_test_three), pd.DataFrame(v6_test_pred_class),pd.DataFrame(Y_valid_three), pd.DataFrame(v6_valid_pred_class)], axis = 1)\n",
        "v6_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "v6_results.to_pickle('0_Ergebnisse/Catboost/results/V6_220909_all_results')"
      ],
      "metadata": {
        "id": "pk8DvDXKMpN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V7: Catboost text and BERT embeddings\n",
        "\n",
        "Catboost model trained with text and BERT embeddings."
      ],
      "metadata": {
        "id": "UIVVcdHaFD6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "\n",
        "model_v7 = fit_model(\n",
        "    ################\n",
        "    train_three_data, test_three_data,\n",
        "    ignored_features = cat_columns + num_columns,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='CPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "DSO-j84JFYRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_v7.save_model('0_Ergebnisse/Catboost/models/V7_220909_model_0.8113570741', format = \"cbm\")"
      ],
      "metadata": {
        "id": "VfqCJm0dhoZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "v7_test_pred_class = model_v7.predict(test_three_data)\n",
        "#Report\n",
        "v7_test_labels, v7_test_report = get_report(Y_test_three, v7_test_pred_class, classes_list)\n",
        "#Save\n",
        "v7_test_report.to_pickle('0_Ergebnisse/Catboost/results/V7_220909_test_report_0.8113570741')"
      ],
      "metadata": {
        "id": "xg7cB7Jyh0ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "v7_valid_pred_class = model_v7.predict(valid_three_data)\n",
        "#Report\n",
        "v7_valid_labels, v7_valid_report = get_report( Y_valid_three, v7_valid_pred_class, classes_list)"
      ],
      "metadata": {
        "id": "ZuinwdusiDOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "v7_valid_report.to_pickle('0_Ergebnisse/Catboost/results/V7_220909_valid_report_0.803903')"
      ],
      "metadata": {
        "id": "0YzoHf8LiE6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "v7_results = pd.concat([pd.DataFrame(Y_test_three), pd.DataFrame(v7_test_pred_class),pd.DataFrame(Y_valid_three), pd.DataFrame(v7_valid_pred_class)], axis = 1)\n",
        "v7_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "v7_results.to_pickle('0_Ergebnisse/Catboost/results/V7_220909_all_results')"
      ],
      "metadata": {
        "id": "GY6q0TRSiXFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V8: Catboost with cat/num/text without class_weights, but with feature selection  \n",
        "\n",
        "Catboost model trained after feature selection.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y9zg5Nm06IbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create dataset just with cat/num features"
      ],
      "metadata": {
        "id": "iJOtIQhZoP79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pool data: 3-digit-accident type -> without embedding!\n",
        "\n",
        "X = X_train_three_all_pre.drop([\"Embedding\", \"Description\"], axis = 1)\n",
        "Xtest = X_test_three_all_pre.drop([\"Embedding\", \"Description\"], axis = 1)\n",
        "Xvalid = X_valid_three_all_pre.drop([\"Embedding\", \"Description\"], axis = 1)\n",
        "\n",
        "\n",
        "train_three_data_selection = Pool(X,\n",
        "                  label = Y_train_three,\n",
        "                  cat_features = [X.columns.get_loc(c) for c in cat_columns if c in X])\n",
        "\n",
        "\n",
        "test_three_data_selection = Pool(Xtest,\n",
        "                  label = Y_test_three,\n",
        "                  cat_features = [Xtest.columns.get_loc(c) for c in cat_columns if c in Xtest])\n",
        "\n",
        "\n",
        "valid_three_data_selection = Pool(Xvalid,\n",
        "                  label = Y_valid_three,\n",
        "                  cat_features = [Xvalid.columns.get_loc(c) for c in cat_columns if c in Xvalid])"
      ],
      "metadata": {
        "id": "inFKLQ12GqLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to perform feature selection"
      ],
      "metadata": {
        "id": "tZy2qeVkoXpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier, EShapCalcType, EFeaturesSelectionAlgorithm\n",
        "\n",
        "#Reference: https://catboost.ai/en/docs/concepts/python-reference_catboost_select_features\n",
        "\n",
        "def select_features(algorithm: EFeaturesSelectionAlgorithm, steps: int = 1):\n",
        "    print('Algorithm:', algorithm)\n",
        "    model = CatBoostClassifier(iterations=2000, random_seed=0,  task_type = \"GPU\")\n",
        "    summary = model.select_features(\n",
        "        train_three_data_selection,\n",
        "        eval_set=test_three_data_selection,\n",
        "        #features_for_select= cat_columns,\n",
        "        features_for_select = cat_columns + num_columns,\n",
        "        num_features_to_select=1,\n",
        "        steps=steps,\n",
        "        algorithm=algorithm,\n",
        "        shap_calc_type=EShapCalcType.Approximate, #EShapCalcType.Regular\n",
        "        #train_final_model=True,\n",
        "        train_final_model = False,\n",
        "        logging_level='Silent',\n",
        "        plot=True,\n",
        "    )\n",
        "    print('Selected features:', summary['selected_features_names'])\n",
        "    return summary"
      ],
      "metadata": {
        "id": "LHKzPUE0B29l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform feature selection with the following parameters:\n",
        "\n",
        "\n",
        "*   RecursiveByLossFunctionChange\n",
        "*   Steps = 10\n",
        "*   Features for select: cat_columns + num_columns\n",
        "*   Num features to select = 1\n",
        "*   Train final model = False\n",
        "*   task type = GPU\n",
        "\n"
      ],
      "metadata": {
        "id": "X-mSQ6m1or8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://catboost.ai/en/docs/concepts/python-reference_catboost_select_features\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_cat_num_stepsten = select_features(algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)\n",
        "\n",
        "\n",
        "#Conclusion, which features should be contained:\n",
        "#CollisionType\n",
        "#CauseP1\n",
        "#Participant2\n",
        "#Sidewalk"
      ],
      "metadata": {
        "id": "W8TF6SRcJR57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print results\n",
        "test_cat_num_stepsten\n",
        "\n",
        "#Save results\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220913_FS_LossChange_10steps_cat_num.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(test_cat_num_stepsten, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "ThhlD77tpN0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Selection based on PredictionValueChange\n",
        "\n",
        "test_cat_num_stepsten_predchange = select_features(algorithm=EFeaturesSelectionAlgorithm.RecursiveByPredictionValuesChange, steps=10)"
      ],
      "metadata": {
        "id": "suLDWBPl3X77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print results\n",
        "print(test_cat_num_stepsten_predchange)\n",
        "\n",
        "#Save results\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220913_FS_PredChange_10steps_cat_num.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(test_cat_num_stepsten_predchange, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmc8nGB57JV2",
        "outputId": "93d3d0d6-d3fc-477c-a718-6b0900b5e26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'selected_features': [], 'eliminated_features_names': ['SpeedLimit', 'Weather', 'Drugs', 'Medicines', 'Cause', 'Participant1', 'Alcohol', 'HitAndRun', 'Weekday', 'Month', 'InjuryP2', 'Rural', 'LightCondition', 'RoadCondition', 'InjuryP1', 'TrafficLightOn', 'Sidewalk', 'Obstacle', 'CyclePath', 'TextLength', 'AgeP1', 'CauseP2', 'Urban', 'AgeP2', 'Participant2', 'TrafficLightOff', 'StreetClass', 'PropertyDamage', 'CauseP1', 'CollisionType'], 'loss_graph': {'main_indices': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'removed_features_count': [0, 9, 15, 19, 22, 25, 26, 27, 28, 29, 30], 'loss_values': [0.8955511278731381, 0.8893087511900288, 0.8832701396597197, 0.9062516727219562, 0.8785402704931249, 0.9155735785195508, 0.9332283776693718, 0.9373888063938385, 0.9512595106339121, 1.2786623998275644, 2.1342190890985417]}, 'eliminated_features': [28, 7, 14, 15, 18, 19, 13, 16, 1, 0, 23, 3, 6, 5, 20, 11, 10, 8, 9, 33, 29, 24, 2, 30, 22, 12, 4, 31, 21, 17], 'selected_features_names': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Selection based on ShapValueChange\n",
        "\n",
        "#Most important features\n",
        "#CollisionType\n",
        "#CauseP1\n",
        "#Participant2\n",
        "#CyclePath\n",
        "#(TrafficLightOn)\n",
        "\n",
        "test_cat_num_stepsten_shapchange = select_features(algorithm=EFeaturesSelectionAlgorithm.RecursiveByShapValues, steps=10)"
      ],
      "metadata": {
        "id": "e6ivkGdc7U4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print results\n",
        "print(test_cat_num_stepsten_shapchange)\n",
        "\n",
        "#Save results\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220913_FS_ShapChange_10steps_cat_num.pkl')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(test_cat_num_stepsten_shapchange, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "tnI-EyTc7iEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test selected features on new model"
      ],
      "metadata": {
        "id": "38bO0KderfPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pool data: 3-digit-accident type based on the results of the feature selection\n",
        "\n",
        "#Contain all data except the specified features\n",
        "\n",
        "\n",
        "####Test: Loss Value Change\n",
        "#features = [\"CollisionType\", \"CauseP1\", \"Participant2\", \"Sidewalk\", \"TrafficLightOn\", \"PropertyDamage\", \"TrafficLightOff\",\"HitAndRun\", \"Description\"]\n",
        "####features = [\"CollisionType\", \"CauseP1\", \"Participant2\", \"Sidewalk\", \"TrafficLightOn\", \"PropertyDamage\", \"TrafficLightOff\", \"Description\"]\n",
        "#features = [\"CollisionType\", \"CauseP1\", \"Participant2\", \"Sidewalk\", \"TrafficLightOn\", \"PropertyDamage\", \"Description\"]\n",
        "#features = [\"CollisionType\", \"CauseP1\", \"Participant2\", \"Sidewalk\", \"TrafficLightOn\", \"Description\"]\n",
        "features = [\"CollisionType\", \"CauseP1\", \"Participant2\", \"Sidewalk\", \"Description\"]\n",
        "#features = [\"CollisionType\", \"CauseP1\", \"Participant2\",  \"Description\"]\n",
        "#features = [\"CollisionType\", \"CauseP1\", \"Description\"]\n",
        "#features = [\"CollisionType\", \"Description\"]\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "Xtrain_fs = X_train_three_all_pre[features]\n",
        "Xtest_fs = X_test_three_all_pre[features]\n",
        "Xvalid_fs = X_valid_three_all_pre[features]\n",
        "\n",
        "\n",
        "train_three_data_fs = Pool(Xtrain_fs,\n",
        "                  label = Y_train_three,\n",
        "                  cat_features = [Xtrain_fs.columns.get_loc(c) for c in cat_columns if c in Xtrain_fs],\n",
        "                  text_features = [\"Description\"])\n",
        "\n",
        "\n",
        "test_three_data_fs = Pool(Xtest_fs,\n",
        "                  label = Y_test_three,\n",
        "                  cat_features = [Xtest_fs.columns.get_loc(c) for c in cat_columns if c in Xtest_fs],\n",
        "                  text_features = [\"Description\"])\n",
        "\n",
        "\n",
        "valid_three_data_fs = Pool(Xvalid_fs,\n",
        "                  label = Y_valid_three,\n",
        "                  cat_features = [Xvalid_fs.columns.get_loc(c) for c in cat_columns if c in Xvalid_fs],\n",
        "                  text_features = [\"Description\"])"
      ],
      "metadata": {
        "id": "Q1cBIx-Jrqzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model V3a\n",
        "\n",
        "model_v3a_fs = fit_model(\n",
        "    ################\n",
        "    train_three_data_fs, test_three_data_fs,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "z-U4CzYvyxNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_v3a_fs.save_model('0_Ergebnisse/Catboost/models/V3afs_220914_model_0.8363811357', format = \"cbm\")"
      ],
      "metadata": {
        "id": "AeinEtPVVEfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "v3afs_test_pred_class = model_v3a_fs.predict(test_three_data_fs)\n",
        "#Report\n",
        "v3afs_test_labels, v3afs_test_report = get_report(Y_test_three, v3afs_test_pred_class, classes_list)\n",
        "#Save\n",
        "v3afs_test_report.to_pickle('0_Ergebnisse/Catboost/results/V3afs_220914_test_report_0.8363811357')"
      ],
      "metadata": {
        "id": "iCUQYEkpVeXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "v3afs_valid_pred_class = model_v3a_fs.predict(valid_three_data_fs)\n",
        "#Report\n",
        "v3afs_valid_labels, v3afs_valid_report = get_report(Y_valid_three, v3afs_valid_pred_class, classes_list)"
      ],
      "metadata": {
        "id": "zijZvL7aWCIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "v3afs_valid_report.to_pickle('0_Ergebnisse/Catboost/results/V3afs_220914_valid_report_0.799123')"
      ],
      "metadata": {
        "id": "AVkWNl6QWUKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(v3afs_valid_report)"
      ],
      "metadata": {
        "id": "9kYHGXkvWw_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "v3afs_results = pd.concat([pd.DataFrame(Y_test_three), pd.DataFrame(v3afs_test_pred_class),pd.DataFrame(Y_valid_three), pd.DataFrame(v3afs_valid_pred_class)], axis = 1)\n",
        "v3afs_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "v3afs_results.to_pickle('0_Ergebnisse/Catboost/results/V3afs_220914_all_results')"
      ],
      "metadata": {
        "id": "XytOkX9yWegV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(v3afs_results)"
      ],
      "metadata": {
        "id": "IPCSmXStWs-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shap values"
      ],
      "metadata": {
        "id": "8ir1Xtro5E9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load existing model\n",
        "#https://www.youtube.com/watch?v=ZkIxZ5xlMuI\n",
        "\n",
        "model_v3 = CatBoostClassifier()\n",
        "\n",
        "model_v3.load_model('0_Ergebnisse/Catboost/models/V3_220627_model_0.8392685274', format='cbm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbEi7BgkMC3S",
        "outputId": "de7ac1da-81ac-4d9b-f593-2c69f85c5a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fe72f2a86d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic model just with categorical values for feature selection\n",
        "\n",
        "model_cat_features = fit_model(\n",
        "    ################\n",
        "    train_three_data_selection, test_three_data_selection,\n",
        "    #ignored_features = [\"Embedding\", \"Description\"] + num_columns,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )"
      ],
      "metadata": {
        "id": "FirtKftJw-WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "\n",
        "import shap\n",
        "shap.initjs()"
      ],
      "metadata": {
        "id": "fE17OHL9Ms2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(model_cat_features)\n",
        "#shap_values = explainer.shap_values(Pool(X_train_three_all_pre.drop([\"Embedding\", \"Description\"]+num_columns, axis = 1), Y_train_three,cat_features = cat_columns))\n",
        "shap_values = explainer.shap_values(Pool(X, Y_train_three, cat_features = cat_columns))"
      ],
      "metadata": {
        "id": "9sisCXeOwHN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shap Values\n",
        "\n",
        "shap_values = model_v3.get_feature_importance(train_three_data, type = \"ShapValues\")"
      ],
      "metadata": {
        "id": "Re3SPvY4M0zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values"
      ],
      "metadata": {
        "id": "gtLWvjj0OAqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V8b: Catboost with cat/num/text with class_weights, and selected features\n",
        "\n",
        "Catboost model trained with selected features (see experiment V8) and class weights (comparable to V3b)\n"
      ],
      "metadata": {
        "id": "l15bWW9mEnP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Class weights\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights_three_fs = class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(Y_train_three), y = Y_train_three)\n",
        "\n",
        "a = list(np.unique(Y_train_three))\n",
        "b = class_weights_three_fs\n",
        "\n",
        "class_weights_three_catboost_fs = dict(zip(a, b))\n",
        "class_weights_three_catboost_fs"
      ],
      "metadata": {
        "id": "FG8ODxbAE7xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "\n",
        "model_v8b = fit_model(\n",
        "    ################\n",
        "    train_three_data_fs, test_three_data_fs,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = class_weights_three_catboost_fs,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "I-6X-RRzFI--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_v8b.save_model('0_Ergebnisse/Catboost/models/V8b_220914_model_0.5362665832', format = \"cbm\")"
      ],
      "metadata": {
        "id": "2diQa8abGWOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "v8b_test_pred_class = model_v8b.predict(test_three_data_fs)\n",
        "#Report\n",
        "v8b_test_labels, v8b_test_report = get_report(Y_test_three, v8b_test_pred_class, classes_list)\n",
        "#Save\n",
        "v8b_test_report.to_pickle('0_Ergebnisse/Catboost/results/V8b_220914_test_report_0.5362665832')"
      ],
      "metadata": {
        "id": "7B71lyA5GeTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "v8b_valid_pred_class = model_v8b.predict(valid_three_data_fs)\n",
        "#Report\n",
        "v8b_valid_labels, v8b_valid_report = get_report(Y_valid_three, v8b_valid_pred_class, classes_list)"
      ],
      "metadata": {
        "id": "F2WZfRWvHNFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "v8b_valid_report.to_pickle('0_Ergebnisse/Catboost/results/V8b_220914_valid_report_0.728589')"
      ],
      "metadata": {
        "id": "JHXIkgx-HbUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "v8b_results = pd.concat([pd.DataFrame(Y_test_three), pd.DataFrame(v8b_test_pred_class),pd.DataFrame(Y_valid_three), pd.DataFrame(v8b_valid_pred_class)], axis = 1)\n",
        "v8b_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "v8b_results.to_pickle('0_Ergebnisse/Catboost/results/V8b_220914_all_results')"
      ],
      "metadata": {
        "id": "UNOfIsQTHkGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Catboost: Experiments with LCPN design\n",
        "\n"
      ],
      "metadata": {
        "id": "hLMLbzXygSll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preparation for hierarchical classification"
      ],
      "metadata": {
        "id": "YLLDPD2nz_vz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjust here, if features should be selected or not:"
      ],
      "metadata": {
        "id": "jl4ehJc4naeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparation of feature selection\n",
        "\n",
        "#Selected features\n",
        "#features = [\"CollisionType\", \"CauseP1\", \"Participant2\", \"Sidewalk\", \"Description\"] #use just selected features\n",
        "features = [] #use alll features except embeddings\n",
        "\n",
        "#When features are selected then reduce the dataset, otherwise leave it:\n",
        "#When feature vector is empty and thus no features are selected\n",
        "if not features:\n",
        "  Xtrain_fs = X_train_three_all_pre\n",
        "  Xtest_fs = X_test_three_all_pre\n",
        "  Xvalid_fs = X_valid_three_all_pre\n",
        "#When features are selected, then reduce the dataset:\n",
        "if features:\n",
        "  Xtrain_fs = X_train_three_all_pre[features]\n",
        "  Xtest_fs = X_test_three_all_pre[features]\n",
        "  Xvalid_fs = X_valid_three_all_pre[features]"
      ],
      "metadata": {
        "id": "YNkMk-JMynSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xvalid_fs"
      ],
      "metadata": {
        "id": "IDkJeNI-LIxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "####\n",
        "#Decode 2AT\n",
        "\n",
        "twenty = [0, 1, 2, 3, 4]\n",
        "twentyone = [5, 6, 7, 8, 9, 10]\n",
        "twentytwo = [11, 12, 13, 14, 15, 16]\n",
        "twentythree = [17, 18, 19, 20]\n",
        "twentyfour = [21, 22, 23, 24, 25, 26]\n",
        "twentyfive = [27, 28, 29]\n",
        "twentysix = [30, 31, 32]\n",
        "twentyseven = [33, 34, 35, 36, 37, 38]\n",
        "twentyeight = [39, 40, 41, 42, 43, 44, 45]\n",
        "twentynine = [46]\n",
        "\n",
        "#Combine X and Y for filtering (will be splitted later again)\n",
        "#Train\n",
        "#XY_train_three_all_pre = pd.concat([X_train_three_all_pre, Y_train_three], axis = 1) #with all features\n",
        "XY_train_three_all_pre = pd.concat([Xtrain_fs, Y_train_three], axis = 1) #with fs\n",
        "#Test\n",
        "#XY_test_three_all_pre = pd.concat([X_test_three_all_pre, Y_test_three], axis = 1) #with all features\n",
        "XY_test_three_all_pre = pd.concat([Xtest_fs, Y_test_three], axis = 1) #with fs\n",
        "#Valid\n",
        "#XY_valid_three_all_pre = pd.concat([X_valid_three_all_pre, Y_valid_three], axis = 1) #with all features\n",
        "XY_valid_three_all_pre = pd.concat([Xvalid_fs, Y_valid_three], axis = 1) #with fs\n",
        "\n",
        "#Filter for the corresponding accident types\n",
        "#Category 20\n",
        "XY_train_20 = XY_train_three_all_pre[XY_train_three_all_pre['AccidentType'].isin(twenty)]\n",
        "XY_test_20 = XY_test_three_all_pre[XY_test_three_all_pre['AccidentType'].isin(twenty)]\n",
        "XY_valid_20 = XY_valid_three_all_pre[XY_valid_three_all_pre['AccidentType'].isin(twenty)]\n",
        "\n",
        "X_train_20 = XY_train_20.drop([\"AccidentType\"], axis = 1)\n",
        "Y_train_20 = XY_train_20.AccidentType\n",
        "\n",
        "X_test_20 = XY_test_20.drop([\"AccidentType\"], axis = 1)\n",
        "Y_test_20 = XY_test_20.AccidentType\n",
        "\n",
        "X_valid_20 = XY_valid_20.drop([\"AccidentType\"], axis = 1)\n",
        "Y_valid_20 = XY_valid_20.AccidentType\n",
        "\n",
        "#Category 21\n",
        "XY_train_21 = XY_train_three_all_pre[XY_train_three_all_pre['AccidentType'].isin(twentyone)]\n",
        "XY_test_21 = XY_test_three_all_pre[XY_test_three_all_pre['AccidentType'].isin(twentyone)]\n",
        "XY_valid_21 = XY_valid_three_all_pre[XY_valid_three_all_pre['AccidentType'].isin(twentyone)]\n",
        "\n",
        "X_train_21 = XY_train_21.drop([\"AccidentType\"], axis = 1)\n",
        "Y_train_21 = XY_train_21.AccidentType\n",
        "\n",
        "X_test_21 = XY_test_21.drop([\"AccidentType\"], axis = 1)\n",
        "Y_test_21 = XY_test_21.AccidentType\n",
        "\n",
        "X_valid_21 = XY_valid_21.drop([\"AccidentType\"], axis = 1)\n",
        "Y_valid_21 = XY_valid_21.AccidentType\n",
        "\n",
        "\n",
        "#Category 22\n",
        "XY_train_22 = XY_train_three_all_pre[XY_train_three_all_pre['AccidentType'].isin(twentytwo)]\n",
        "XY_test_22 = XY_test_three_all_pre[XY_test_three_all_pre['AccidentType'].isin(twentytwo)]\n",
        "XY_valid_22 = XY_valid_three_all_pre[XY_valid_three_all_pre['AccidentType'].isin(twentytwo)]\n",
        "\n",
        "X_train_22 = XY_train_22.drop([\"AccidentType\"], axis = 1)\n",
        "Y_train_22 = XY_train_22.AccidentType\n",
        "\n",
        "X_test_22 = XY_test_22.drop([\"AccidentType\"], axis = 1)\n",
        "Y_test_22 = XY_test_22.AccidentType\n",
        "\n",
        "X_valid_22 = XY_valid_22.drop([\"AccidentType\"], axis = 1)\n",
        "Y_valid_22 = XY_valid_22.AccidentType\n",
        "\n",
        "\n",
        "#Category 23\n",
        "XY_train_23 = XY_train_three_all_pre[XY_train_three_all_pre['AccidentType'].isin(twentythree)]\n",
        "XY_test_23 = XY_test_three_all_pre[XY_test_three_all_pre['AccidentType'].isin(twentythree)]\n",
        "XY_valid_23 = XY_valid_three_all_pre[XY_valid_three_all_pre['AccidentType'].isin(twentythree)]\n",
        "\n",
        "X_train_23 = XY_train_23.drop([\"AccidentType\"], axis = 1)\n",
        "Y_train_23 = XY_train_23.AccidentType\n",
        "\n",
        "X_test_23 = XY_test_23.drop([\"AccidentType\"], axis = 1)\n",
        "Y_test_23 = XY_test_23.AccidentType\n",
        "\n",
        "X_valid_23 = XY_valid_23.drop([\"AccidentType\"], axis = 1)\n",
        "Y_valid_23 = XY_valid_23.AccidentType\n",
        "\n",
        "\n",
        "#Category 24\n",
        "XY_train_24 = XY_train_three_all_pre[XY_train_three_all_pre['AccidentType'].isin(twentyfour)]\n",
        "XY_test_24 = XY_test_three_all_pre[XY_test_three_all_pre['AccidentType'].isin(twentyfour)]\n",
        "XY_valid_24 = XY_valid_three_all_pre[XY_valid_three_all_pre['AccidentType'].isin(twentyfour)]\n",
        "\n",
        "X_train_24 = XY_train_24.drop([\"AccidentType\"], axis = 1)\n",
        "Y_train_24 = XY_train_24.AccidentType\n",
        "\n",
        "X_test_24 = XY_test_24.drop([\"AccidentType\"], axis = 1)\n",
        "Y_test_24 = XY_test_24.AccidentType\n",
        "\n",
        "X_valid_24 = XY_valid_24.drop([\"AccidentType\"], axis = 1)\n",
        "Y_valid_24 = XY_valid_24.AccidentType\n",
        "\n",
        "\n",
        "#Category 25\n",
        "XY_train_25 = XY_train_three_all_pre[XY_train_three_all_pre['AccidentType'].isin(twentyfive)]\n",
        "XY_test_25 = XY_test_three_all_pre[XY_test_three_all_pre['AccidentType'].isin(twentyfive)]\n",
        "XY_valid_25 = XY_valid_three_all_pre[XY_valid_three_all_pre['AccidentType'].isin(twentyfive)]\n",
        "\n",
        "X_train_25 = XY_train_25.drop([\"AccidentType\"], axis = 1)\n",
        "Y_train_25 = XY_train_25.AccidentType\n",
        "\n",
        "X_test_25 = XY_test_25.drop([\"AccidentType\"], axis = 1)\n",
        "Y_test_25 = XY_test_25.AccidentType\n",
        "\n",
        "X_valid_25 = XY_valid_25.drop([\"AccidentType\"], axis = 1)\n",
        "Y_valid_25 = XY_valid_25.AccidentType\n",
        "\n",
        "\n",
        "#Category 26\n",
        "XY_train_26 = XY_train_three_all_pre[XY_train_three_all_pre['AccidentType'].isin(twentysix)]\n",
        "XY_test_26 = XY_test_three_all_pre[XY_test_three_all_pre['AccidentType'].isin(twentysix)]\n",
        "XY_valid_26 = XY_valid_three_all_pre[XY_valid_three_all_pre['AccidentType'].isin(twentysix)]\n",
        "\n",
        "X_train_26 = XY_train_26.drop([\"AccidentType\"], axis = 1)\n",
        "Y_train_26 = XY_train_26.AccidentType\n",
        "\n",
        "X_test_26 = XY_test_26.drop([\"AccidentType\"], axis = 1)\n",
        "Y_test_26 = XY_test_26.AccidentType\n",
        "\n",
        "X_valid_26 = XY_valid_26.drop([\"AccidentType\"], axis = 1)\n",
        "Y_valid_26 = XY_valid_26.AccidentType\n",
        "\n",
        "\n",
        "#Category 27\n",
        "XY_train_27 = XY_train_three_all_pre[XY_train_three_all_pre['AccidentType'].isin(twentyseven)]\n",
        "XY_test_27 = XY_test_three_all_pre[XY_test_three_all_pre['AccidentType'].isin(twentyseven)]\n",
        "XY_valid_27 = XY_valid_three_all_pre[XY_valid_three_all_pre['AccidentType'].isin(twentyseven)]\n",
        "\n",
        "X_train_27 = XY_train_27.drop([\"AccidentType\"], axis = 1)\n",
        "Y_train_27 = XY_train_27.AccidentType\n",
        "\n",
        "X_test_27 = XY_test_27.drop([\"AccidentType\"], axis = 1)\n",
        "Y_test_27 = XY_test_27.AccidentType\n",
        "\n",
        "X_valid_27 = XY_valid_27.drop([\"AccidentType\"], axis = 1)\n",
        "Y_valid_27 = XY_valid_27.AccidentType\n",
        "\n",
        "\n",
        "#Category 28\n",
        "XY_train_28 = XY_train_three_all_pre[XY_train_three_all_pre['AccidentType'].isin(twentyeight)]\n",
        "XY_test_28 = XY_test_three_all_pre[XY_test_three_all_pre['AccidentType'].isin(twentyeight)]\n",
        "XY_valid_28 = XY_valid_three_all_pre[XY_valid_three_all_pre['AccidentType'].isin(twentyeight)]\n",
        "\n",
        "X_train_28 = XY_train_28.drop([\"AccidentType\"], axis = 1)\n",
        "Y_train_28 = XY_train_28.AccidentType\n",
        "\n",
        "X_test_28 = XY_test_28.drop([\"AccidentType\"], axis = 1)\n",
        "Y_test_28 = XY_test_28.AccidentType\n",
        "\n",
        "X_valid_28 = XY_valid_28.drop([\"AccidentType\"], axis = 1)\n",
        "Y_valid_28 = XY_valid_28.AccidentType\n",
        "\n",
        "\n",
        "#Category 29\n",
        "XY_train_29 = XY_train_three_all_pre[XY_train_three_all_pre['AccidentType'].isin(twentynine)]\n",
        "XY_test_29 = XY_test_three_all_pre[XY_test_three_all_pre['AccidentType'].isin(twentynine)]\n",
        "XY_valid_29 = XY_valid_three_all_pre[XY_valid_three_all_pre['AccidentType'].isin(twentynine)]\n",
        "\n",
        "X_train_29 = XY_train_29.drop([\"AccidentType\"], axis = 1)\n",
        "Y_train_29 = XY_train_29.AccidentType\n",
        "\n",
        "X_test_29 = XY_test_29.drop([\"AccidentType\"], axis = 1)\n",
        "Y_test_29 = XY_test_29.AccidentType\n",
        "\n",
        "X_valid_29 = XY_valid_29.drop([\"AccidentType\"], axis = 1)\n",
        "Y_valid_29 = XY_valid_29.AccidentType\n"
      ],
      "metadata": {
        "id": "PY7-v2yhjgsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid_22"
      ],
      "metadata": {
        "id": "3g0gPIpJLxia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pooling\n",
        "\n",
        "#Category 20\n",
        "train_20 = Pool(X_train_20,\n",
        "                  label = Y_train_20,\n",
        "                  cat_features = [X_train_20.columns.get_loc(c) for c in cat_columns if c in X_train_20],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "test_20 = Pool(X_test_20,\n",
        "                  label = Y_test_20,\n",
        "                  cat_features = [X_test_20.columns.get_loc(c) for c in cat_columns if c in X_test_20],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "               )\n",
        "\n",
        "valid_20 = Pool(X_valid_20,\n",
        "                  label = Y_valid_20,\n",
        "                  cat_features = [X_valid_20.columns.get_loc(c) for c in cat_columns if c in X_valid_20],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "#Category 21\n",
        "train_21 = Pool(X_train_21,\n",
        "                  label = Y_train_21,\n",
        "                  cat_features = [X_train_21.columns.get_loc(c) for c in cat_columns if c in X_train_21],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "test_21 = Pool(X_test_21,\n",
        "                  label = Y_test_21,\n",
        "                  cat_features = [X_test_21.columns.get_loc(c) for c in cat_columns if c in X_test_21],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "               )\n",
        "\n",
        "valid_21 = Pool(X_valid_21,\n",
        "                  label = Y_valid_21,\n",
        "                  cat_features = [X_valid_21.columns.get_loc(c) for c in cat_columns if c in X_valid_21],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "\n",
        "#Category 22\n",
        "train_22 = Pool(X_train_22,\n",
        "                  label = Y_train_22,\n",
        "                  cat_features = [X_train_22.columns.get_loc(c) for c in cat_columns if c in X_train_22],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "test_22 = Pool(X_test_22,\n",
        "                  label = Y_test_22,\n",
        "                  cat_features = [X_test_22.columns.get_loc(c) for c in cat_columns if c in X_test_22],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "               )\n",
        "\n",
        "valid_22 = Pool(X_valid_22,\n",
        "                  label = Y_valid_22,\n",
        "                  cat_features = [X_valid_22.columns.get_loc(c) for c in cat_columns if c in X_valid_22],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "\n",
        "#Category 23\n",
        "train_23 = Pool(X_train_23,\n",
        "                  label = Y_train_23,\n",
        "                  cat_features = [X_train_23.columns.get_loc(c) for c in cat_columns if c in X_train_23],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "test_23 = Pool(X_test_23,\n",
        "                  label = Y_test_23,\n",
        "                  cat_features = [X_test_23.columns.get_loc(c) for c in cat_columns if c in X_test_23],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "               )\n",
        "\n",
        "valid_23 = Pool(X_valid_23,\n",
        "                  label = Y_valid_23,\n",
        "                  cat_features = [X_valid_23.columns.get_loc(c) for c in cat_columns if c in X_valid_23],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "\n",
        "#Category 24\n",
        "train_24 = Pool(X_train_24,\n",
        "                  label = Y_train_24,\n",
        "                  cat_features = [X_train_24.columns.get_loc(c) for c in cat_columns if c in X_train_24],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "test_24 = Pool(X_test_24,\n",
        "                  label = Y_test_24,\n",
        "                  cat_features = [X_test_24.columns.get_loc(c) for c in cat_columns if c in X_test_24],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "               )\n",
        "\n",
        "valid_24 = Pool(X_valid_24,\n",
        "                  label = Y_valid_24,\n",
        "                  cat_features = [X_valid_24.columns.get_loc(c) for c in cat_columns if c in X_valid_24],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "\n",
        "#Category 25\n",
        "train_25 = Pool(X_train_25,\n",
        "                  label = Y_train_25,\n",
        "                  cat_features = [X_train_25.columns.get_loc(c) for c in cat_columns if c in X_train_25],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "test_25 = Pool(X_test_25,\n",
        "                  label = Y_test_25,\n",
        "                  cat_features = [X_test_25.columns.get_loc(c) for c in cat_columns if c in X_test_25],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "               )\n",
        "\n",
        "valid_25 = Pool(X_valid_25,\n",
        "                  label = Y_valid_25,\n",
        "                  cat_features = [X_valid_25.columns.get_loc(c) for c in cat_columns if c in X_valid_25],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "#Category 26\n",
        "train_26 = Pool(X_train_26,\n",
        "                  label = Y_train_26,\n",
        "                  cat_features = [X_train_26.columns.get_loc(c) for c in cat_columns if c in X_train_26],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "test_26 = Pool(X_test_26,\n",
        "                  label = Y_test_26,\n",
        "                  cat_features = [X_test_26.columns.get_loc(c) for c in cat_columns if c in X_test_26],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "               )\n",
        "\n",
        "valid_26 = Pool(X_valid_26,\n",
        "                  label = Y_valid_26,\n",
        "                  cat_features = [X_valid_26.columns.get_loc(c) for c in cat_columns if c in X_valid_26],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "\n",
        "#Category 27\n",
        "train_27 = Pool(X_train_27,\n",
        "                  label = Y_train_27,\n",
        "                  cat_features = [X_train_27.columns.get_loc(c) for c in cat_columns if c in X_train_27],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "test_27 = Pool(X_test_27,\n",
        "                  label = Y_test_27,\n",
        "                  cat_features = [X_test_27.columns.get_loc(c) for c in cat_columns if c in X_test_27],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "               )\n",
        "\n",
        "valid_27 = Pool(X_valid_27,\n",
        "                  label = Y_valid_27,\n",
        "                  cat_features = [X_valid_27.columns.get_loc(c) for c in cat_columns if c in X_valid_27],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "#Category 28\n",
        "train_28 = Pool(X_train_28,\n",
        "                  label = Y_train_28,\n",
        "                  cat_features = [X_train_28.columns.get_loc(c) for c in cat_columns if c in X_train_28],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "test_28 = Pool(X_test_28,\n",
        "                  label = Y_test_28,\n",
        "                  cat_features = [X_test_28.columns.get_loc(c) for c in cat_columns if c in X_test_28],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "               )\n",
        "\n",
        "valid_28 = Pool(X_valid_28,\n",
        "                  label = Y_valid_28,\n",
        "                  cat_features = [X_valid_28.columns.get_loc(c) for c in cat_columns if c in X_valid_28],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "#Category 29\n",
        "train_29 = Pool(X_train_29,\n",
        "                  label = Y_train_29,\n",
        "                  cat_features = [X_train_29.columns.get_loc(c) for c in cat_columns if c in X_train_29],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )\n",
        "\n",
        "test_29 = Pool(X_test_29,\n",
        "                  label = Y_test_29,\n",
        "                  cat_features = [X_test_29.columns.get_loc(c) for c in cat_columns if c in X_test_29],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "               )\n",
        "\n",
        "valid_29 = Pool(X_valid_29,\n",
        "                  label = Y_valid_29,\n",
        "                  cat_features = [X_valid_29.columns.get_loc(c) for c in cat_columns if c in X_valid_29],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                )"
      ],
      "metadata": {
        "cellView": "code",
        "id": "DGVP-0qou0XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When feature selection"
      ],
      "metadata": {
        "id": "0FEC3_AXqKTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare two digit data with selected features\n",
        "\n",
        "Xtrain_two_fs = X_train_two_all_pre[features]\n",
        "Xtest_two_fs = X_test_two_all_pre[features]\n",
        "Xvalid_two_fs = X_valid_two_all_pre[features]"
      ],
      "metadata": {
        "id": "tnNpVq2DRxEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_two_fs"
      ],
      "metadata": {
        "id": "Q6vYiz3hNB8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## M1: Local classifier per parent node (LCPN)\n",
        "\n"
      ],
      "metadata": {
        "id": "SOwrxAKRgjOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First parent node: Two-digit-model"
      ],
      "metadata": {
        "id": "bz15y9qBpjAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data"
      ],
      "metadata": {
        "id": "0ZPPMOhvXqfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data without feature selection"
      ],
      "metadata": {
        "id": "8C-Qu_cykeEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pool data: 2-digit-accident type\n",
        "train_two_data = Pool(\n",
        "                  X_train_two_all_pre, #without feature selection\n",
        "                  label = Y_train_two,\n",
        "                  cat_features = [X_train_two_all_pre.columns.get_loc(c) for c in cat_columns if c in X_train_two_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"]\n",
        "                  )\n",
        "\n",
        "\n",
        "test_two_data = Pool(\n",
        "                  X_test_two_all_pre, #without feature selection\n",
        "                  label = Y_test_two,\n",
        "                  cat_features = [X_test_two_all_pre.columns.get_loc(c) for c in cat_columns if c in X_test_two_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"]\n",
        "                  )\n",
        "\n",
        "\n",
        "valid_two_data = Pool(\n",
        "                  X_valid_two_all_pre, #without feature selection\n",
        "                  label = Y_valid_two,\n",
        "                  cat_features = [X_valid_two_all_pre.columns.get_loc(c) for c in cat_columns if c in X_valid_two_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"]\n",
        "                  )"
      ],
      "metadata": {
        "id": "jbFIxE19kj16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data with feature selection"
      ],
      "metadata": {
        "id": "W9LjVk1Cka09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pool data: 2-digit-accident type\n",
        "train_two_data_fs = Pool(\n",
        "                  #X_train_two_all_pre, #without feature selection\n",
        "                  Xtrain_two_fs, #with selected features\n",
        "                  label = Y_train_two,\n",
        "                  #cat_features = [X_train_two_all_pre.columns.get_loc(c) for c in cat_columns if c in X_train_two_all_pre],\n",
        "                  cat_features = [Xtrain_two_fs.columns.get_loc(c) for c in cat_columns if c in Xtrain_two_fs],\n",
        "                  text_features= [\"Description\"],\n",
        "                  #embedding_features = [\"Embedding\"]\n",
        "                  )\n",
        "\n",
        "\n",
        "test_two_data_fs = Pool(\n",
        "                  #X_test_two_all_pre, #without feature selection\n",
        "                  Xtest_two_fs,\n",
        "                  label = Y_test_two,\n",
        "                  #cat_features = [X_test_two_all_pre.columns.get_loc(c) for c in cat_columns if c in X_test_two_all_pre],\n",
        "                  cat_features = [Xtest_two_fs.columns.get_loc(c) for c in cat_columns if c in Xtest_two_fs],\n",
        "                  text_features= [\"Description\"],\n",
        "                  #embedding_features = [\"Embedding\"]\n",
        "                  )\n",
        "\n",
        "\n",
        "valid_two_data_fs = Pool(\n",
        "                  #X_valid_two_all_pre, #without feature selection\n",
        "                  Xvalid_two_fs,\n",
        "                  label = Y_valid_two,\n",
        "                  #cat_features = [X_valid_two_all_pre.columns.get_loc(c) for c in cat_columns if c in X_valid_two_all_pre],\n",
        "                  cat_features = [Xvalid_two_fs.columns.get_loc(c) for c in cat_columns if c in Xvalid_two_fs],\n",
        "                  text_features= [\"Description\"],\n",
        "                  #embedding_features = [\"Embedding\"]\n",
        "                  )"
      ],
      "metadata": {
        "id": "wWMr2BIJXuL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 2X"
      ],
      "metadata": {
        "id": "HV0nQJCZXyQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic model initialization\n",
        "\n",
        "\n",
        "#Training parameters: https://catboost.ai/en/docs/references/training-parameters/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fit_m1_two_model(train_pool, test_pool, **kwargs):\n",
        "    model = CatBoostClassifier(\n",
        "        loss_function = \"MultiClass\",\n",
        "        random_seed = 42,\n",
        "        eval_metric='Accuracy',\n",
        "        **kwargs,\n",
        "        #################\n",
        "        l2_leaf_reg = 3.0,\n",
        "        ###START: MODIFIEABLE###\n",
        "        depth = 5,\n",
        "        ###END: MODIFIEABLE###\n",
        "        one_hot_max_size = 0, #This means that no feature is one-hot-encoded -> default value is different from 0\n",
        "        bootstrap_type = 'Bayesian',\n",
        "        ###START: MODIFIEABLE###\n",
        "        bagging_temperature = 0.6,\n",
        "        ###END: MODIFIEABLE###\n",
        "        sampling_frequency = 'PerTree', #Default level = PerTreeLevel\n",
        "        sampling_unit = 'Object',\n",
        "        grow_policy = 'SymmetricTree',\n",
        "        has_time = False,\n",
        "        leaf_estimation_method = 'Newton',\n",
        "        #leaf_estimation_iterations = 5,\n",
        "        fold_len_multiplier = 2,\n",
        "        approx_on_full_history = False,\n",
        "        auto_class_weights = 'None',\n",
        "        boosting_type = 'Plain',\n",
        "        boost_from_average = False,\n",
        "        score_function = 'Cosine',\n",
        "        ################\n",
        "        ##Overfitting detection\n",
        "        od_type='Iter',\n",
        "        od_wait=500,\n",
        "        ################\n",
        "        tokenizers = [ {\n",
        "            \"tokenizer_id\" : \"Sense\",\n",
        "            \"separator_type\" : \"BySense\",\n",
        "            \"lowercasing\" : \"true\",\n",
        "            \"number_process_policy\": \"LeaveAsIs\",\n",
        "            \"skip_empty\": 'true',\n",
        "            'token_types':['Word', 'Number', 'SentenceBreak', 'ParagraphBreak'],\n",
        "            'sub_tokens_policy': 'SeveralTokens',\n",
        "        }],\n",
        "\n",
        "        dictionaries = [{\n",
        "            \"dictionary_id\" : \"BiGram\",\n",
        "            \"gram_order\" : \"2\",\n",
        "            'min_token_occurence': '1',\n",
        "            'max_dictionary_size': '150000'\n",
        "        }, {\n",
        "            \"dictionary_id\" : \"Word\",\n",
        "            \"gram_order\" : \"1\",\n",
        "            'min_token_occurence': '1',\n",
        "            'max_dictionary_size': '150000'\n",
        "        }],\n",
        "\n",
        "        feature_calcers = [\n",
        "                          'BoW:top_tokens_count=1000',\n",
        "                          'BoW:dictionary_names=BiGram',\n",
        "                          'NaiveBayes:top_tokens_count=1000',\n",
        "                          'NaiveBayes:dictionary_names=Word',\n",
        "                          'BM25:top_tokens_count=1000',\n",
        "                          'BM25:dictionary_names=Word'\n",
        "\n",
        "\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model.fit(\n",
        "        train_pool,\n",
        "        eval_set=test_pool,\n",
        "        verbose=50,\n",
        "        plot=True,\n",
        "        use_best_model=True)\n"
      ],
      "metadata": {
        "id": "EqFybEh2pNsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "M1_two_model with all features"
      ],
      "metadata": {
        "id": "Hod-JF7pzYlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "#Prediction of the two-digit-accident type\n",
        "\n",
        "model_m1_two = fit_m1_two_model(\n",
        "    ################\n",
        "    train_two_data, test_two_data,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = [],\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SmfGjzLsg_2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_two.save_model('0_Ergebnisse/Catboost/models/M1_two_220629_model_0.885466795', format = \"cbm\")"
      ],
      "metadata": {
        "id": "fAHGTica0mni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "M1_two_model with all features and with class weights (cw)"
      ],
      "metadata": {
        "id": "faFVruTQk8ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "#Prediction of the two-digit-accident type\n",
        "\n",
        "model_m1_two_cw = fit_m1_two_model(\n",
        "    ################\n",
        "    train_two_data, test_two_data,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_two),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KhzbL14kk_0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_two_cw.save_model('0_Ergebnisse/Catboost/models/M1_two_cw_220916_model_0.6996135353', format = \"cbm\")"
      ],
      "metadata": {
        "id": "yJFNUCjjlVTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "M1_two_model with feature selection (fs)"
      ],
      "metadata": {
        "id": "_ueXlK_tzWnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select the most suitable features\n",
        "\n",
        "from catboost import CatBoostClassifier, EShapCalcType, EFeaturesSelectionAlgorithm\n",
        "\n",
        "\n",
        "def select_features_lcpn(featurenumber, Xtrain, Ytrain, Xtest, Ytest, algorithm: EFeaturesSelectionAlgorithm, steps: int = 1):\n",
        "    print('Algorithm:', algorithm)\n",
        "    #Drop not needed columns\n",
        "    Xtrain = Xtrain.drop([\"Embedding\", \"Description\"], axis = 1)\n",
        "    Xtest = Xtest.drop([\"Embedding\", \"Description\"], axis = 1)\n",
        "    #Build model\n",
        "    model = CatBoostClassifier(iterations=2000, random_seed=0,  task_type = \"GPU\")\n",
        "    summary = model.select_features(\n",
        "        #Training features\n",
        "        Pool(Xtrain, Ytrain, cat_features = [Xtrain.columns.get_loc(c) for c in cat_columns if c in Xtrain]),\n",
        "        #Evaluation features\n",
        "        eval_set=Pool(Xtest, Ytest, cat_features = [Xtest.columns.get_loc(c) for c in cat_columns if c in Xtest]),\n",
        "        #Features to be selected\n",
        "        features_for_select = cat_columns + num_columns,\n",
        "        #Number of features to be selected\n",
        "        num_features_to_select= featurenumber,\n",
        "        steps=steps,\n",
        "        algorithm=algorithm,\n",
        "        shap_calc_type=EShapCalcType.Approximate, #EShapCalcType.Regular\n",
        "        #train_final_model=True,\n",
        "        train_final_model = False,\n",
        "        logging_level='Silent',\n",
        "        plot=True,\n",
        "    )\n",
        "    print('Selected features:', summary['selected_features_names'])\n",
        "    return summary\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gIBleXAo1vmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "#Most important features:\n",
        "#CollisionType\n",
        "#CauseP1\n",
        "#Participant2\n",
        "#Sidewalk\n",
        "\n",
        "\n",
        "feat_m1_two = select_features_lcpn(X_train_three_all_pre, Y_train_two, X_test_three_all_pre, Y_test_two, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "B5GH8D3b3zm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_m1_two = [\"Description\", \"CollisionType\", \"CauseP1\", \"Participant2\", \"Sidewalk\" ]\n",
        "\n",
        "X_train_two = X_train_two_all_pre[features_m1_two]\n",
        "X_test_two = X_test_two_all_pre[features_m1_two]\n",
        "\n",
        "train_two_data_fs = Pool(X_train_two,\n",
        "                  label = Y_train_two,\n",
        "                  cat_features = [X_train_two.columns.get_loc(c) for c in cat_columns if c in X_train_two],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_two_data_fs = Pool(X_test_two,\n",
        "                  label = Y_test_two,\n",
        "                  cat_features = [X_test_two.columns.get_loc(c) for c in cat_columns if c in X_test_two],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "OV5n9GSHThQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_two_220914_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_m1_two, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "KGIDYb707RDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_two_220914_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "ouYuRn7frqYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "#Prediction of the two-digit-accident type WITH feature selection\n",
        "\n",
        "model_m1_two_fs = fit_m1_two_model(\n",
        "    ################\n",
        "    train_two_data_fs, test_two_data_fs,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = [],\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "8Tluf8pYTXcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_two_fs.save_model('0_Ergebnisse/Catboost/models/M1_two_fs4_220916_model_0.8864292589', format = \"cbm\")"
      ],
      "metadata": {
        "id": "SkWtBkwkT-EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "m1_two_test_pred_class = model_m1_two_fs.predict(test_two_data)\n",
        "#Report\n",
        "m1_two_test_report = get_report(Y_test_two, m1_two_test_pred_class, labellist = None)\n",
        "#Save\n",
        "m1_two_test_report.to_pickle('0_Ergebnisse/Catboost/results/M1_two_fs_220914_test_report_0.8845043311')"
      ],
      "metadata": {
        "id": "odo63TwjSSHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "m1_two_valid_pred_class = model_m1_two_fs.predict(valid_two_data)\n",
        "#Report\n",
        "m1_two_valid_report = get_report(Y_valid_two, m1_two_valid_pred_class)"
      ],
      "metadata": {
        "id": "6Dq0Z0KPoDSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "m1_two_valid_report.to_pickle('0_Ergebnisse/Catboost/results/M1_two_fs_220914_valid_report_0.841048')"
      ],
      "metadata": {
        "id": "LjxM17QHojXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "m1_two_results = pd.concat([pd.DataFrame(Y_test_two), pd.DataFrame(m1_two_test_pred_class),pd.DataFrame(Y_valid_two), pd.DataFrame(m1_two_valid_pred_class)], axis = 1)\n",
        "m1_two_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "m1_two_results.to_pickle('0_Ergebnisse/Catboost/results/M1_two_fs_220914_all_results')"
      ],
      "metadata": {
        "id": "96JqQGCiopew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "M1_two_model with feature selection and class weights"
      ],
      "metadata": {
        "id": "sOJIR4cXzRNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "#Prediction of the two-digit-accident type WITH feature selection AND WITH Class weights\n",
        "\n",
        "model_m1_two = fit_m1_two_model(\n",
        "    ################\n",
        "    train_two_data_fs, test_two_data_fs,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_two),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n",
        "#Ergebnis: 14.09.2022 with feature selection and class weights\n",
        "#bestTest = 0.691949208 | bestIteration = 109 | Shrink model to first iterations. 110 | approx. time for best model with GPU: 1.46s\n",
        "\n"
      ],
      "metadata": {
        "id": "b2ztATsGzOMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_two.save_model('0_Ergebnisse/Catboost/models/M1_two_fs_cw_220914_model_0.691949208', format = \"cbm\")"
      ],
      "metadata": {
        "id": "3kmfFGj0iFho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second parent node: Three-digit-models"
      ],
      "metadata": {
        "id": "OHvO3VIWoqfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 20"
      ],
      "metadata": {
        "id": "pPLc1cgeuw0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with all features and class weights"
      ],
      "metadata": {
        "id": "UGq-Cnm-l1_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_20 = fit_model(\n",
        "    ################\n",
        "    train_20, test_20,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_20),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n"
      ],
      "metadata": {
        "id": "Ixt_N44Ll4Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_20.save_model('0_Ergebnisse/Catboost/models/M1_20_cw_220916_model_0.7207721973', format = \"cbm\")"
      ],
      "metadata": {
        "id": "VfOR1F-tmAaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With feature selection"
      ],
      "metadata": {
        "id": "Ssj2AOgt05k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "#Take maximum four features\n",
        "#CollisionType\n",
        "#CauseP1\n",
        "#Participant2\n",
        "#CauseP2\n",
        "\n",
        "feat_m1_20 = select_features_lcpn(4, X_train_20, Y_train_20, X_test_20, Y_test_20, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "Xho8Zy9S71Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_m1_20 = [\"Description\", \"CauseP1\", \"CollisionType\", \"CauseP2\", \"Participant2\" ]\n",
        "\n",
        "X_train_20 = X_train_20[features_m1_20]\n",
        "X_test_20 = X_test_20[features_m1_20]\n",
        "\n",
        "train_20 = Pool(X_train_20,\n",
        "                  label = Y_train_20,\n",
        "                  cat_features = [X_train_20.columns.get_loc(c) for c in cat_columns if c in X_train_20],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_20 = Pool(X_test_20,\n",
        "                  label = Y_test_20,\n",
        "                  cat_features = [X_test_20.columns.get_loc(c) for c in cat_columns if c in X_test_20],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "hWeljCgN81am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_20_220916_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_m1_20, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "U2mQX_ck8d0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_20_220916_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "_6BGn9VPsWjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_20 = fit_model(\n",
        "    ################\n",
        "    train_20,\n",
        "    ################\n",
        "    test_20,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hgQ2n2HhA5Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "#model_m1_20.save_model('0_Ergebnisse/Catboost/models/M1_20_220628_model_0.96875', format = \"cbm\")\n",
        "model_m1_20.save_model('0_Ergebnisse/Catboost/models/M1_20_fs4_220916_model_0.96875', format = \"cbm\")"
      ],
      "metadata": {
        "id": "HvUZT5C0Cowz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved model\n",
        "\n",
        "model_m1_20 = CatBoostClassifier()\n",
        "model_m1_20.load_model('0_Ergebnisse/Catboost/models/M1_20_220628_model_0.96875', format='cbm')"
      ],
      "metadata": {
        "id": "ncu56dojO4jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection and class weights"
      ],
      "metadata": {
        "id": "dnf5MG9T09Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_20 = fit_model(\n",
        "    ################\n",
        "    train_20, test_20,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_20),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WAjhiLlr1CNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_20.save_model('0_Ergebnisse/Catboost/models/M1_20_fs_cw_220914_model_0.7085018686', format = \"cbm\")"
      ],
      "metadata": {
        "id": "IvRJpymBiP6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 21"
      ],
      "metadata": {
        "id": "ugbqAe2Vu3KU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection"
      ],
      "metadata": {
        "id": "OY4GGgIJ_GnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "#Select maximum 4 features\n",
        "#Rural\n",
        "#Medicines\n",
        "#CauseP1\n",
        "#SpeedLimit\n",
        "\n",
        "feat_m1_21 = select_features_lcpn(4, X_train_21, Y_train_21, X_test_21, Y_test_21, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "4ZaDL3a5_KQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_m1_21 = [\"Description\", \"Rural\", \"Medicines\", \"CauseP1\", \"SpeedLimit\" ]\n",
        "\n",
        "X_train_21 = X_train_21[features_m1_21]\n",
        "X_test_21 = X_test_21[features_m1_21]\n",
        "\n",
        "train_21 = Pool(X_train_21,\n",
        "                  label = Y_train_21,\n",
        "                  cat_features = [X_train_21.columns.get_loc(c) for c in cat_columns if c in X_train_21],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_21 = Pool(X_test_21,\n",
        "                  label = Y_test_21,\n",
        "                  cat_features = [X_test_21.columns.get_loc(c) for c in cat_columns if c in X_test_21],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "5n16Na4m_Qil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_21_220916_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_m1_21, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "7bR92P5t_j48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_21_220916_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "TvCSfAPMsx34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_21 = fit_model(\n",
        "    ################\n",
        "    train_21, test_21,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "QNGcbkH0BJYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "#model_m1_21.save_model('0_Ergebnisse/Catboost/models/M1_21_220628_model_0.9878934625', format = \"cbm\")\n",
        "model_m1_21.save_model('0_Ergebnisse/Catboost/models/M1_21_fs4_220916_model_0.985472155', format = \"cbm\")"
      ],
      "metadata": {
        "id": "1pCPta0uCzRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with all features and class weights"
      ],
      "metadata": {
        "id": "nidqJTxQq4jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_21 = fit_model(\n",
        "    ################\n",
        "    train_21, test_21,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_21),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F-XLgMcpq6wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_21.save_model('0_Ergebnisse/Catboost/models/M1_21_cw_220916_model_0.7625820956', format = \"cbm\")"
      ],
      "metadata": {
        "id": "2hH6bO1JrEvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection and class weights"
      ],
      "metadata": {
        "id": "2u7gUDcP1ryf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_21 = fit_model(\n",
        "    ################\n",
        "    train_21, test_21,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_21),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "3-wK_aqu1uGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_21.save_model('0_Ergebnisse/Catboost/models/M1_21_fs_cw_220914_model_0.7505045686', format = \"cbm\")"
      ],
      "metadata": {
        "id": "TNH-whFridMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 22"
      ],
      "metadata": {
        "id": "E13gErIUu9ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection"
      ],
      "metadata": {
        "id": "yc1BSYP5Evl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "#Select maximum 4 features\n",
        "#CyclePath\n",
        "#Sidewalk\n",
        "#TrafficLightOff\n",
        "#CollisionType\n",
        "\n",
        "feat_m1_22 = select_features_lcpn(4, X_train_22, Y_train_22, X_test_22, Y_test_22, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "boA04b3FExwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_m1_22 = [\"Description\", 'CyclePath', 'Sidewalk', 'TrafficLightOff', 'CollisionType' ]\n",
        "\n",
        "X_train_22 = X_train_22[features_m1_22]\n",
        "X_test_22 = X_test_22[features_m1_22]\n",
        "\n",
        "train_22 = Pool(X_train_22,\n",
        "                  label = Y_train_22,\n",
        "                  cat_features = [X_train_22.columns.get_loc(c) for c in cat_columns if c in X_train_22],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_22 = Pool(X_test_22,\n",
        "                  label = Y_test_22,\n",
        "                  cat_features = [X_test_22.columns.get_loc(c) for c in cat_columns if c in X_test_22],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "0d2HlN1ZGoZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_22_220916_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_m1_22, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "9NOxjHV-G9Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_22_220916_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "YAbG9cwrtWCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_22 = fit_model(\n",
        "    ################\n",
        "    train_22, test_22,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "CYVBKE9yBRjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "#model_m1_22.save_model('0_Ergebnisse/Catboost/models/M1_22_220628_model_0.7692307692', format = \"cbm\")\n",
        "model_m1_22.save_model('0_Ergebnisse/Catboost/models/M1_22_fs4_220916_model_0.7362637363', format = \"cbm\")"
      ],
      "metadata": {
        "id": "lEkmqO4FC70D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with all features and class weights"
      ],
      "metadata": {
        "id": "Adi9FkDzrQXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_22 = fit_model(\n",
        "    ################\n",
        "    train_22, test_22,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_22),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n"
      ],
      "metadata": {
        "id": "9iLRnmFwrSZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_22.save_model('0_Ergebnisse/Catboost/models/M1_22_cw_220916_model_0.8403373182', format = \"cbm\")"
      ],
      "metadata": {
        "id": "YGlc4AvJrZFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection and class weights"
      ],
      "metadata": {
        "id": "_lQWq3Q116Zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_22 = fit_model(\n",
        "    ################\n",
        "    train_22, test_22,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_22),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "5YYjyuFB19M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_22.save_model('0_Ergebnisse/Catboost/models/M1_22_fs_cw_220914_model_0.8293699808', format = \"cbm\")"
      ],
      "metadata": {
        "id": "3BIeHxc6iooe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 23"
      ],
      "metadata": {
        "id": "mZaMl0rsu_6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection"
      ],
      "metadata": {
        "id": "DAPjDChcHGhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "#Select maximum 4 features\n",
        "#StreetClass\n",
        "#CollisionType\n",
        "#CauseP1\n",
        "#Participant2\n",
        "\n",
        "feat_m1_23 = select_features_lcpn(4, X_train_23, Y_train_23, X_test_23, Y_test_23, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "wHMZvonbHIbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_m1_23 = [\"Description\", 'StreetClass', 'CollisionType', 'CauseP1', 'Participant2' ]\n",
        "\n",
        "X_train_23 = X_train_23[features_m1_23]\n",
        "X_test_23 = X_test_23[features_m1_23]\n",
        "\n",
        "train_23 = Pool(X_train_23,\n",
        "                  label = Y_train_23,\n",
        "                  cat_features = [X_train_23.columns.get_loc(c) for c in cat_columns if c in X_train_23],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_23 = Pool(X_test_23,\n",
        "                  label = Y_test_23,\n",
        "                  cat_features = [X_test_23.columns.get_loc(c) for c in cat_columns if c in X_test_23],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "ZArQLYofHStH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_23_220916_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_m1_23, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "dq2318xpHmnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_23_220916_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "XObcUVrgtgXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_23 = fit_model(\n",
        "    ################\n",
        "    train_23, test_23,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n",
        "#Ergebnis: 28.06.2022\n",
        "#bestTest = 0.9741935484 | bestIteration = 422 | Shrink model to first 423 iterations. | approx. time for best model with GPU: 4,83s"
      ],
      "metadata": {
        "id": "P-eZVaynBX5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "#model_m1_23.save_model('0_Ergebnisse/Catboost/models/M1_23_220628_model_0.9741935484', format = \"cbm\")\n",
        "model_m1_23.save_model('0_Ergebnisse/Catboost/models/M1_23_fs4_220916_model_0.9741935484', format = \"cbm\")"
      ],
      "metadata": {
        "id": "RktF-Zl9DCBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with all features and class weights"
      ],
      "metadata": {
        "id": "jjNXOFEUrk2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_23 = fit_model(\n",
        "    ################\n",
        "    train_23, test_23,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_23),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )"
      ],
      "metadata": {
        "id": "KUHcr06Frms0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_23.save_model('0_Ergebnisse/Catboost/models/M1_23_fs_cw_220914_model_0.8815909068', format = \"cbm\")"
      ],
      "metadata": {
        "id": "Ope-f9P6rvC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection and class weights"
      ],
      "metadata": {
        "id": "9FVD3iAb2JaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_23 = fit_model(\n",
        "    ################\n",
        "    train_23, test_23,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_23),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XEydGamE2I01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_23.save_model('0_Ergebnisse/Catboost/models/M1_23_fs_cw_220914_model_0.8977272705', format = \"cbm\")"
      ],
      "metadata": {
        "id": "YKnfmTcYixZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 24"
      ],
      "metadata": {
        "id": "B4G3eSFAvBt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection"
      ],
      "metadata": {
        "id": "krjFFIyBIhDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "#Select maximum 4 features\n",
        "#StreetClass\n",
        "#CollisionType\n",
        "#Participant2\n",
        "#CauseP2\n",
        "\n",
        "feat_m1_24 = select_features_lcpn(4, X_train_24, Y_train_24, X_test_24, Y_test_24, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "4WJhcTy7ImpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_m1_24 = [\"Description\", 'StreetClass', 'CollisionType', 'Participant2', 'CauseP2']\n",
        "\n",
        "X_train_24 = X_train_24[features_m1_24]\n",
        "X_test_24 = X_test_24[features_m1_24]\n",
        "\n",
        "train_24 = Pool(X_train_24,\n",
        "                  label = Y_train_24,\n",
        "                  cat_features = [X_train_24.columns.get_loc(c) for c in cat_columns if c in X_train_24],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_24 = Pool(X_test_24,\n",
        "                  label = Y_test_24,\n",
        "                  cat_features = [X_test_24.columns.get_loc(c) for c in cat_columns if c in X_test_24],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "HRpb8rNWIvVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_24_220916_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_m1_24, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "nUR7DWWRI-uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_24_220916_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "Du-jYn8ctm_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_24 = fit_model(\n",
        "    ################\n",
        "    train_24, test_24,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4NI_uB0QBkdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "#model_m1_24.save_model('0_Ergebnisse/Catboost/models/M1_24_220628_model_0.6891891892', format = \"cbm\")\n",
        "model_m1_24.save_model('0_Ergebnisse/Catboost/models/M1_24_fs4_220016_model_0.7702702703', format = \"cbm\")"
      ],
      "metadata": {
        "id": "NgqDNErjDIOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with all features and class weights"
      ],
      "metadata": {
        "id": "xq_eVsy6r57_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_24 = fit_model(\n",
        "    ################\n",
        "    train_24, test_24,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_24),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )"
      ],
      "metadata": {
        "id": "3HNiMYNEr4fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_24.save_model('0_Ergebnisse/Catboost/models/M1_24_cw_220916_model_0.5860650638', format = \"cbm\")"
      ],
      "metadata": {
        "id": "vfAc7UXOsAAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection and class weights"
      ],
      "metadata": {
        "id": "1MacZbYQ2gTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_24 = fit_model(\n",
        "    ################\n",
        "    train_24, test_24,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_24),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GFbVJjIZ2jzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_24.save_model('0_Ergebnisse/Catboost/models/M1_24_fs_cw_220914_model_0.6505734715', format = \"cbm\")"
      ],
      "metadata": {
        "id": "curt8F73i3LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 25"
      ],
      "metadata": {
        "id": "COYZPdZOvEP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection"
      ],
      "metadata": {
        "id": "QJFOro9tKYKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "#Select maximum 4 features\n",
        " #RoadCondition\n",
        " #CollisionType\n",
        " #SpeedLimit\n",
        " #TextLength\n",
        "\n",
        "feat_m1_25 = select_features_lcpn(4, X_train_25, Y_train_25, X_test_25, Y_test_25, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "EK-bZTsaKd16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_m1_25 = [\"Description\", 'RoadCondition', 'CollisionType', 'SpeedLimit', 'TextLength' ]\n",
        "\n",
        "X_train_25 = X_train_25[features_m1_25]\n",
        "X_test_25 = X_test_25[features_m1_25]\n",
        "\n",
        "train_25 = Pool(X_train_25,\n",
        "                  label = Y_train_25,\n",
        "                  cat_features = [X_train_25.columns.get_loc(c) for c in cat_columns if c in X_train_25],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_25 = Pool(X_test_25,\n",
        "                  label = Y_test_25,\n",
        "                  cat_features = [X_test_25.columns.get_loc(c) for c in cat_columns if c in X_test_25],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "JzofBYV3K1DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_25_220916_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_m1_25, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "-ZrkXXXVLdDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_25_220916_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "S5dyITpUtuHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_25 = fit_model(\n",
        "    ################\n",
        "    train_25, test_25,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "cqzhoqPcBqNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "#model_m1_25.save_model('0_Ergebnisse/Catboost/models/M1_25_220628_model_1.0', format = \"cbm\")\n",
        "model_m1_25.save_model('0_Ergebnisse/Catboost/models/M1_25_fs4_220916_model_0.5', format = \"cbm\")"
      ],
      "metadata": {
        "id": "Chi8ERYkDPMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with all features and class weights"
      ],
      "metadata": {
        "id": "f2i8uOhlsG29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_25 = fit_model(\n",
        "    ################\n",
        "    train_25, test_25,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_25),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )"
      ],
      "metadata": {
        "id": "CWfiLKBZsIja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_25.save_model('0_Ergebnisse/Catboost/models/M1_25_cw_220916_model_1', format = \"cbm\")"
      ],
      "metadata": {
        "id": "9dWmn0O1sLXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection and class weights"
      ],
      "metadata": {
        "id": "0nDhnhrM2x-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_25 = fit_model(\n",
        "    ################\n",
        "    train_25, test_25,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_25),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n",
        "#Ergebnis:"
      ],
      "metadata": {
        "id": "vIagl75y2z_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_25.save_model('0_Ergebnisse/Catboost/models/M1_25_fs_cw_220914_model_1', format = \"cbm\")"
      ],
      "metadata": {
        "id": "zHOfiCMwi-oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 26"
      ],
      "metadata": {
        "id": "OlfZAZadvGRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection"
      ],
      "metadata": {
        "id": "1kVAPwmUNJQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "#Select maximum 4 features\n",
        "#Month\n",
        "#StreetClass\n",
        "#Weather\n",
        "#CauseP1\n",
        "\n",
        "feat_m1_26 = select_features_lcpn(4, X_train_26, Y_train_26, X_test_26, Y_test_26, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "PKDMirOANe_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_m1_26 = [\"Description\",  \"Month\", \"StreetClass\", \"Weather\", \"CauseP1\"]\n",
        "\n",
        "X_train_26 = X_train_26[features_m1_26]\n",
        "X_test_26 = X_test_26[features_m1_26]\n",
        "\n",
        "train_26 = Pool(X_train_26,\n",
        "                  label = Y_train_26,\n",
        "                  cat_features = [X_train_26.columns.get_loc(c) for c in cat_columns if c in X_train_26],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_26 = Pool(X_test_26,\n",
        "                  label = Y_test_26,\n",
        "                  cat_features = [X_test_26.columns.get_loc(c) for c in cat_columns if c in X_test_26],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "KacU6IA6ODfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_26_220916_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_m1_26, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "5WSLzm_0PAAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_26_220916_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "Y6qF_LGBt0ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_26 = fit_model(\n",
        "    ################\n",
        "    train_26, test_26,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "L9WjeQ1KBxek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "#model_m1_26.save_model('0_Ergebnisse/Catboost/models/M1_26_220628_model_0.9473684211', format = \"cbm\")\n",
        "model_m1_26.save_model('0_Ergebnisse/Catboost/models/M1_26_fs4_220916_model_0.9473684211', format = \"cbm\")"
      ],
      "metadata": {
        "id": "LBX9qlVgDU1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with all features and class weights"
      ],
      "metadata": {
        "id": "lF4E9T9VsSB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_26 = fit_model(\n",
        "    ################\n",
        "    train_26, test_26,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_26),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )"
      ],
      "metadata": {
        "id": "8bWq2OpEsT1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_26.save_model('0_Ergebnisse/Catboost/models/M1_26_cw_220916_model_0.7754318618', format = \"cbm\")"
      ],
      "metadata": {
        "id": "gwxaLlf6sYx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection and class weights"
      ],
      "metadata": {
        "id": "AoYlzl6K29ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_26 = fit_model(\n",
        "    ################\n",
        "    train_26, test_26,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_26),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n",
        "#Ergebnis:"
      ],
      "metadata": {
        "id": "PHfft6qu2_2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_26.save_model('0_Ergebnisse/Catboost/models/M1_26_fs_cw_220914_model_0.7428023032', format = \"cbm\")"
      ],
      "metadata": {
        "id": "T90qKNM7jHOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 27"
      ],
      "metadata": {
        "id": "ToaPh1GgvIUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection"
      ],
      "metadata": {
        "id": "pI9cTWpgPJCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "#Select maximum 4 features\n",
        "#CyclePath\n",
        "#Sidewalk\n",
        "#HitAndRun\n",
        "#CollisionType\n",
        "\n",
        "feat_m1_27 = select_features_lcpn(4, X_train_27, Y_train_27, X_test_27, Y_test_27, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "3OaseTCRPM2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_m1_27 = [\"Description\", 'CyclePath', 'Sidewalk', 'HitAndRun', 'CollisionType' ]\n",
        "\n",
        "X_train_27 = X_train_27[features_m1_27]\n",
        "X_test_27 = X_test_27[features_m1_27]\n",
        "\n",
        "train_27 = Pool(X_train_27,\n",
        "                  label = Y_train_27,\n",
        "                  cat_features = [X_train_27.columns.get_loc(c) for c in cat_columns if c in X_train_27],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_27 = Pool(X_test_27,\n",
        "                  label = Y_test_27,\n",
        "                  cat_features = [X_test_27.columns.get_loc(c) for c in cat_columns if c in X_test_27],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "8k7ox5imPVnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_27_220916_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_m1_27, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "WGUpjuYoPm6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_27_220916_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "gI_-lkbtt-0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_27 = fit_model(\n",
        "    ################\n",
        "    train_27, test_27,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "icrTrQv2B4iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "#model_m1_27.save_model('0_Ergebnisse/Catboost/models/M1_27_220628_model_1.0', format = \"cbm\")\n",
        "model_m1_27.save_model('0_Ergebnisse/Catboost/models/M1_27_fs4_220916_model_1.0', format = \"cbm\")"
      ],
      "metadata": {
        "id": "f4ssK-iIDaWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with all features and class weights"
      ],
      "metadata": {
        "id": "EguzlLR0sifO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_27 = fit_model(\n",
        "    ################\n",
        "    train_27, test_27,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_27),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )"
      ],
      "metadata": {
        "id": "vooi_ahBskgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_27.save_model('0_Ergebnisse/Catboost/models/M1_27_cw_220916_model_1', format = \"cbm\")"
      ],
      "metadata": {
        "id": "pDdTEuUjsoTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection and class weights"
      ],
      "metadata": {
        "id": "O2JnU13s3Myp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_27 = fit_model(\n",
        "    ################\n",
        "    train_27, test_27,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_27),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "36hIdvnv3PPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_27.save_model('0_Ergebnisse/Catboost/models/M1_27_fs_cw_220914_model_1', format = \"cbm\")"
      ],
      "metadata": {
        "id": "pWNpL2NkjNCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 28"
      ],
      "metadata": {
        "id": "IlhAbL-WvKQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection"
      ],
      "metadata": {
        "id": "XTagJP_dPwoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "#Select maximum 4 features\n",
        "#CollisionType\n",
        "#Participant2\n",
        "#InjuryP2\n",
        "#PropertyDamage\n",
        "\n",
        "feat_m1_28 = select_features_lcpn(4, X_train_28, Y_train_28, X_test_28, Y_test_28, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "lmdafVZgPysm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_m1_28 = [\"Description\", 'CollisionType', 'Participant2', 'InjuryP2', 'PropertyDamage'  ]\n",
        "\n",
        "X_train_28 = X_train_28[features_m1_28]\n",
        "X_test_28 = X_test_28[features_m1_28]\n",
        "\n",
        "train_28 = Pool(X_train_28,\n",
        "                  label = Y_train_28,\n",
        "                  cat_features = [X_train_28.columns.get_loc(c) for c in cat_columns if c in X_train_28],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_28 = Pool(X_test_28,\n",
        "                  label = Y_test_28,\n",
        "                  cat_features = [X_test_28.columns.get_loc(c) for c in cat_columns if c in X_test_28],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "5wxeE9nNP77w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_28_220916_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_m1_28, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "Z2JbY79PQNlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_28_220916_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "rxm-36eQuHIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_28 = fit_model(\n",
        "    ################\n",
        "    train_28, test_28,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "kHmToCiXB-fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "#model_m1_28.save_model('0_Ergebnisse/Catboost/models/M1_28_220628_model_1.0', format = \"cbm\")\n",
        "model_m1_28.save_model('0_Ergebnisse/Catboost/models/M1_28_fs4_220916_model_1.0', format = \"cbm\")"
      ],
      "metadata": {
        "id": "r5b_lwtzDhta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with all features and class weights"
      ],
      "metadata": {
        "id": "Forj7PD4svct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_28 = fit_model(\n",
        "    ################\n",
        "    train_28, test_28,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_28),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )"
      ],
      "metadata": {
        "id": "IFyCC2ZWsxZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_28.save_model('0_Ergebnisse/Catboost/models/M1_28_cw_220916_model_1', format = \"cbm\")"
      ],
      "metadata": {
        "id": "iVzcDHNes1Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection and class weights"
      ],
      "metadata": {
        "id": "DemhU16z3YAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize single models\n",
        "\n",
        "model_m1_28 = fit_model(\n",
        "    ################\n",
        "    train_28, test_28,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    class_weights = get_weights(Y_train_28),\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "1qND8q5n3aSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_m1_28.save_model('0_Ergebnisse/Catboost/models/M1_28_fs_cw_220914_model_1', format = \"cbm\")"
      ],
      "metadata": {
        "id": "8WY_1opTjTNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 29"
      ],
      "metadata": {
        "id": "bHAfat6AvMkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For 29 is no model required, since there is only the value 299."
      ],
      "metadata": {
        "id": "POiMrhatCEOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LCPN: Prediction pipeline"
      ],
      "metadata": {
        "id": "02FqeAIcpePh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions"
      ],
      "metadata": {
        "id": "el4-UDLmvXbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_lcpn(X_data, cat_columns, model_two, model_20, model_21, model_22, model_23, model_24, model_25, model_26, model_27, model_28):\n",
        "\n",
        "\n",
        "  #Assign ID\n",
        "  X_data.loc[:,\"ID\"] = X_data.index\n",
        "\n",
        "\n",
        "  #Pool data for catboost algorithm\n",
        "  X_data_pool = Pool(X_data,\n",
        "                  cat_features = [X_data.columns.get_loc(c) for c in cat_columns if c in X_data],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                  )\n",
        "\n",
        "  #Predict two-digit accident type\n",
        "  class_two_digit = model_two.predict(X_data_pool)\n",
        "\n",
        "  #Combine prediction with original data\n",
        "  #X_new = pd.concat([X_data, pd.DataFrame(class_two_digit)], axis = 1)\n",
        "  X_n = X_data.copy()\n",
        "  X_n.loc[:, \"AccidentTypeTwo\"] = class_two_digit\n",
        "  #Rename last column, which is predicted two-digit accident type\n",
        "  #X_new.columns = [*X_new.columns[:-1], 'AccidentTypeTwo']\n",
        "  #Create ID column by index\n",
        "  X_new = X_n.copy()\n",
        "  #X_new.loc[:,\"ID\"] = X_new.index\n",
        "\n",
        "  #Filter by the single accident types\n",
        "  X_20 = X_new[X_new['AccidentTypeTwo'] == 20]\n",
        "  X_21 = X_new[X_new['AccidentTypeTwo'] == 21]\n",
        "  X_22 = X_new[X_new['AccidentTypeTwo'] == 22]\n",
        "  X_23 = X_new[X_new['AccidentTypeTwo'] == 23]\n",
        "  X_24 = X_new[X_new['AccidentTypeTwo'] == 24]\n",
        "  X_25 = X_new[X_new['AccidentTypeTwo'] == 25]\n",
        "  X_26 = X_new[X_new['AccidentTypeTwo'] == 26]\n",
        "  X_27 = X_new[X_new['AccidentTypeTwo'] == 27]\n",
        "  X_28 = X_new[X_new['AccidentTypeTwo'] == 28]\n",
        "  X_29 = X_new[X_new['AccidentTypeTwo'] == 29]\n",
        "\n",
        "  #Pool the single datasets for 3-digit-type prediction\n",
        "  #Pooling is only feasible, when there is at least one row per dataframe\n",
        "\n",
        "  if len(X_20) != 0:\n",
        "    X_20_pool = Pool(X_20,\n",
        "                    cat_features = [X_20.columns.get_loc(c) for c in cat_columns if c in X_20],\n",
        "                    text_features= [\"Description\"],\n",
        "                    embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                     )\n",
        "\n",
        "  if len(X_21) != 0:\n",
        "    X_21_pool = Pool(X_21,\n",
        "                    cat_features = [X_21.columns.get_loc(c) for c in cat_columns if c in X_21],\n",
        "                    text_features= [\"Description\"],\n",
        "                    embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                     )\n",
        "\n",
        "  if len(X_22) != 0:\n",
        "    X_22_pool = Pool(X_22,\n",
        "                    cat_features = [X_22.columns.get_loc(c) for c in cat_columns if c in X_22],\n",
        "                    text_features= [\"Description\"],\n",
        "                    embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                     )\n",
        "\n",
        "  if len(X_23) != 0:\n",
        "    X_23_pool = Pool(X_23,\n",
        "                    cat_features = [X_23.columns.get_loc(c) for c in cat_columns if c in X_23],\n",
        "                    text_features= [\"Description\"],\n",
        "                    embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                     )\n",
        "\n",
        "  if len(X_24) != 0:\n",
        "    X_24_pool = Pool(X_24,\n",
        "                    cat_features = [X_24.columns.get_loc(c) for c in cat_columns if c in X_24],\n",
        "                    text_features= [\"Description\"],\n",
        "                    embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                     )\n",
        "\n",
        "  if len(X_25) != 0:\n",
        "    X_25_pool = Pool(X_25,\n",
        "                    cat_features = [X_25.columns.get_loc(c) for c in cat_columns if c in X_25],\n",
        "                    text_features= [\"Description\"],\n",
        "                    embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                     )\n",
        "\n",
        "  if len(X_26) != 0:\n",
        "    X_26_pool = Pool(X_26,\n",
        "                    cat_features = [X_26.columns.get_loc(c) for c in cat_columns if c in X_26],\n",
        "                    text_features= [\"Description\"],\n",
        "                    embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                     )\n",
        "\n",
        "  if len(X_27) != 0:\n",
        "    X_27_pool = Pool(X_27,\n",
        "                    cat_features = [X_27.columns.get_loc(c) for c in cat_columns if c in X_27],\n",
        "                    text_features= [\"Description\"],\n",
        "                    embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                     )\n",
        "\n",
        "  if len(X_28) != 0:\n",
        "    X_28_pool = Pool(X_28,\n",
        "                    cat_features = [X_28.columns.get_loc(c) for c in cat_columns if c in X_28],\n",
        "                    text_features= [\"Description\"],\n",
        "                    embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                     )\n",
        "\n",
        "  #Make predictions\n",
        "\n",
        "  if len(X_20) != 0:\n",
        "    class_20 = model_20.predict(X_20_pool)\n",
        "  if len(X_21) != 0:\n",
        "    class_21 = model_21.predict(X_21_pool)\n",
        "  if len(X_22) != 0:\n",
        "    class_22 = model_22.predict(X_22_pool)\n",
        "  if len(X_23) != 0:\n",
        "    class_23 = model_23.predict(X_23_pool)\n",
        "  if len(X_24) != 0:\n",
        "    class_24 = model_24.predict(X_24_pool)\n",
        "  if len(X_25) != 0:\n",
        "    class_25 = model_25.predict(X_25_pool)\n",
        "  if len(X_26) != 0:\n",
        "    class_26 = model_26.predict(X_26_pool)\n",
        "  if len(X_27) != 0:\n",
        "    class_27 = model_27.predict(X_27_pool)\n",
        "  if len(X_28) != 0:\n",
        "    class_28 = model_28.predict(X_28_pool)\n",
        "\n",
        "\n",
        "  #Make copies\n",
        "  X_20_new = X_20.copy()\n",
        "  X_21_new = X_21.copy()\n",
        "  X_22_new = X_22.copy()\n",
        "  X_23_new = X_23.copy()\n",
        "  X_24_new = X_24.copy()\n",
        "  X_25_new = X_25.copy()\n",
        "  X_26_new = X_26.copy()\n",
        "  X_27_new = X_27.copy()\n",
        "  X_28_new = X_28.copy()\n",
        "  X_29_new = X_29.copy()\n",
        "\n",
        "  #Assign predictions\n",
        "  if len(X_20) != 0:\n",
        "    X_20_new.loc[:,\"AccidentType\"] = class_20\n",
        "  if len(X_21) != 0:\n",
        "    X_21_new.loc[:,\"AccidentType\"] = class_21\n",
        "  if len(X_22) != 0:\n",
        "    X_22_new.loc[:,\"AccidentType\"] = class_22\n",
        "  if len(X_23) != 0:\n",
        "    X_23_new.loc[:,\"AccidentType\"] = class_23\n",
        "  if len(X_24) != 0:\n",
        "    X_24_new.loc[:,\"AccidentType\"] = class_24\n",
        "  if len(X_25) != 0:\n",
        "    X_25_new.loc[:,\"AccidentType\"] = class_25\n",
        "  if len(X_26) != 0:\n",
        "    X_26_new.loc[:,\"AccidentType\"] = class_26\n",
        "  if len(X_27) != 0:\n",
        "    X_27_new.loc[:,\"AccidentType\"] = class_27\n",
        "  if len(X_28) != 0:\n",
        "    X_28_new.loc[:, \"AccidentType\"] = class_28\n",
        "  if len(X_29) != 0:\n",
        "    X_29_new.loc[:, \"AccidentType\"] = 46\n",
        "\n",
        "  #Bind data frames together\n",
        "  X_total = pd.concat([X_20_new, X_21_new, X_22_new, X_23_new, X_24_new, X_25_new, X_26_new, X_27_new, X_28_new, X_29_new])\n",
        "\n",
        "  #Sort by index in ascending order\n",
        "  X_total = X_total.sort_values(by = ['ID'], axis = 0, ascending = True)\n",
        "\n",
        "  #Return\n",
        "  return X_total\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rte9vNuSpgKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load models"
      ],
      "metadata": {
        "id": "fpnYRjLdvaP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved model\n",
        "\n",
        "model_m1_two = CatBoostClassifier()\n",
        "model_m1_two.load_model('0_Ergebnisse/Catboost/models/M1_two_220628_model_0.8835418672', format='cbm')"
      ],
      "metadata": {
        "id": "z-9fwq_CN2hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved model\n",
        "\n",
        "model_m1_20 = CatBoostClassifier()\n",
        "model_m1_20.load_model('0_Ergebnisse/Catboost/models/M1_20_220628_model_0.96875', format='cbm')"
      ],
      "metadata": {
        "id": "5oYI3B0gvgVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved model\n",
        "\n",
        "model_m1_21 = CatBoostClassifier()\n",
        "model_m1_21.load_model('0_Ergebnisse/Catboost/models/M1_21_220628_model_0.9878934625', format='cbm')"
      ],
      "metadata": {
        "id": "sNOp_643PDzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved model\n",
        "\n",
        "model_m1_22 = CatBoostClassifier()\n",
        "model_m1_22.load_model('0_Ergebnisse/Catboost/models/M1_22_220628_model_0.7692307692', format='cbm')"
      ],
      "metadata": {
        "id": "HkHexUVjPNXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved model\n",
        "\n",
        "model_m1_23 = CatBoostClassifier()\n",
        "model_m1_23.load_model('0_Ergebnisse/Catboost/models/M1_23_220628_model_0.9741935484', format='cbm')"
      ],
      "metadata": {
        "id": "Pk2mdGa0PWzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved model\n",
        "\n",
        "model_m1_24 = CatBoostClassifier()\n",
        "model_m1_24.load_model('0_Ergebnisse/Catboost/models/M1_24_220628_model_0.6891891892', format='cbm')"
      ],
      "metadata": {
        "id": "c3JfxDFLPehN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved model\n",
        "\n",
        "model_m1_25 = CatBoostClassifier()\n",
        "model_m1_25.load_model('0_Ergebnisse/Catboost/models/M1_25_220628_model_1.0', format='cbm')"
      ],
      "metadata": {
        "id": "dG2dDqDIPpTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved model\n",
        "\n",
        "model_m1_26 = CatBoostClassifier()\n",
        "model_m1_26.load_model('0_Ergebnisse/Catboost/models/M1_26_220628_model_0.9473684211', format='cbm')"
      ],
      "metadata": {
        "id": "wWpZD7eLPzWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved model\n",
        "\n",
        "model_m1_27 = CatBoostClassifier()\n",
        "model_m1_27.load_model('0_Ergebnisse/Catboost/models/M1_27_220628_model_1.0', format='cbm')"
      ],
      "metadata": {
        "id": "mS3LVTkLRNo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved model\n",
        "\n",
        "model_m1_28 = CatBoostClassifier()\n",
        "model_m1_28.load_model('0_Ergebnisse/Catboost/models/M1_28_220628_model_1.0', format='cbm')"
      ],
      "metadata": {
        "id": "mfw9vlCkRZNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LCPN: Prediction"
      ],
      "metadata": {
        "id": "ANWvkmXlWijG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "m1_test = predict_lcpn(X_test_two_all_pre, cat_columns, model_m1_two_cw, model_m1_20, model_m1_21, model_m1_22, model_m1_23, model_m1_24, model_m1_25, model_m1_26, model_m1_27, model_m1_28) #without feature selection\n",
        "#m1_test = predict_lcpn(Xtest_two_fs, cat_columns, model_m1_two, model_m1_20, model_m1_21, model_m1_22, model_m1_23, model_m1_24, model_m1_25, model_m1_26, model_m1_27, model_m1_28) #with feature selection\n",
        "#Report\n",
        "m1_test_report = get_report(Y_test_three, m1_test.AccidentType)\n",
        "#Save\n",
        "m1_test_report.to_pickle('0_Ergebnisse/Catboost/results/M1_cw_220917_test_report_0.814369 ')\n",
        "\n"
      ],
      "metadata": {
        "id": "mymnKASBufwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "m1_valid = predict_lcpn(X_valid_two_all_pre, cat_columns, model_m1_two_cw, model_m1_20, model_m1_21, model_m1_22, model_m1_23, model_m1_24, model_m1_25, model_m1_26, model_m1_27, model_m1_28) #without feature selection\n",
        "#m1_valid = predict_lcpn(Xvalid_two_fs, cat_columns, model_m1_two, model_m1_20, model_m1_21, model_m1_22, model_m1_23, model_m1_24, model_m1_25, model_m1_26, model_m1_27, model_m1_28) #with feature selection\n",
        "#Report\n",
        "#labels, m1_valid_report = get_report(Y_valid_three, m1_valid.AccidentType, classes_list)\n",
        "m1_valid_report = get_report(Y_valid_three, m1_valid.AccidentType)\n"
      ],
      "metadata": {
        "id": "LuIj89EfX-5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save\n",
        "m1_valid_report.to_pickle('0_Ergebnisse/Catboost/results/M1_cw_220917_valid_report_0.746629')\n",
        "\n",
        "#abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs_220914_valid_report_0.781415.pkl')\n",
        "#with open(str(abspath), 'wb') as handle:\n",
        " # pickle.dump(m1_valid_report, handle, protocol = pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "SkC230TfYOrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "m1_test_results = m1_test.copy()\n",
        "m1_test_results.loc[:, \"Y_three\"] = Y_test_three\n",
        "m1_test_results.to_pickle('0_Ergebnisse/Catboost/results/M1_cw_220917_test_results')\n",
        "\n",
        "m1_valid_results = m1_valid.copy()\n",
        "m1_valid_results.loc[:, \"Y_three\"] = Y_valid_three\n",
        "m1_valid_results.to_pickle('0_Ergebnisse/Catboost/results/M1_cw_220917_valid_results')\n",
        "\n"
      ],
      "metadata": {
        "id": "EYTw-8tqYc57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversampling: https://towardsdatascience.com/how-to-deal-with-imbalanced-multiclass-datasets-in-python-fe0bb3f2b669"
      ],
      "metadata": {
        "id": "GJgoN6GSzMbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CatBoost: Experiments with frequent 3ATs"
      ],
      "metadata": {
        "id": "U8Je-ZfWJct2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduction of the accident types to be predicted to those accident types for which sufficient samples are available and which can therefore be predicted with a high degree of probability."
      ],
      "metadata": {
        "id": "J8cigZvlJvQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import data"
      ],
      "metadata": {
        "id": "4N1QDF_NJpIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import preprocessed data: 3-digit accident type (3AT)\n",
        "\n",
        "#Training data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_train_three_all_pre.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  X_train_three_all_pre = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_train_three.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  Y_train_three = pickle.load(pkl)\n",
        "\n",
        "#Test data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_test_three_all_pre.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  X_test_three_all_pre = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_test_three.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  Y_test_three = pickle.load(pkl)\n",
        "\n",
        "#Validation data\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_X_valid_three_all_pre.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  X_valid_three_all_pre = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/220624_Y_valid_three.pkl')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  Y_valid_three = pickle.load(pkl)"
      ],
      "metadata": {
        "id": "LEV_3BpXJrFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Column specifications\n",
        "\n",
        "#Column specifications\n",
        "cat_columns = [\"Month\", \"Weekday\", \"StreetClass\", \"RoadCondition\", \"LightCondition\", \"Weather\" , \"Obstacle\",\"Urban\", \"Rural\", \"CyclePath\", \"Sidewalk\", \"TrafficLightOn\", \"TrafficLightOff\", \"Alcohol\", \"Drugs\", \"Medicines\", \"SpeedLimit\", \"HitAndRun\", \"CollisionType\",\"Cause\", \"Participant1\", \"InjuryP1\", \"CauseP1\",\"Participant2\", \"CauseP2\", \"InjuryP2\"]\n",
        "num_columns = [\"AgeP1\", \"AgeP2\", \"PropertyDamage\", \"TextLength\"]\n",
        "text_columns = [\"Description\"]\n",
        "emb_columns = [\"Embedding\"]"
      ],
      "metadata": {
        "id": "yiX0TDcqRIOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate Classes\n",
        "\n",
        "Align Y-values"
      ],
      "metadata": {
        "id": "hGCPzwzOJspF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Label rare accidents as rare -> two Groups\n",
        "def label_rare(Y_three):\n",
        "\n",
        "  Y = Y_three.copy()\n",
        "\n",
        "  #Rare accident types\n",
        "  #[2, 4, 7, 8, 9, 10, 15, 16, 19,\n",
        "  #20, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38,\n",
        "  #40, 41, 42, 43, 44, 45]\n",
        "\n",
        "  Y.replace(0,1, inplace = True) #201\n",
        "  Y.replace(1,1, inplace = True) #202\n",
        "  #\n",
        "  Y.replace(2,0, inplace = True) #203\n",
        "  #\n",
        "  Y.replace(3,1, inplace = True) #204\n",
        "  #\n",
        "  Y.replace(4,0, inplace = True) #209\n",
        "  #\n",
        "  Y.replace(5,1, inplace = True) #211\n",
        "  #\n",
        "  Y.replace(6,1, inplace = True) #212\n",
        "  #\n",
        "  Y.replace(7,0, inplace = True) #213\n",
        "  Y.replace(8,0, inplace = True) #214\n",
        "  Y.replace(9,0, inplace = True) #215\n",
        "  #\n",
        "  Y.replace(10,0, inplace = True) #219\n",
        "  #\n",
        "  Y.replace(11,1, inplace = True) #221\n",
        "  #\n",
        "  Y.replace(12,1, inplace = True) #222\n",
        "  #\n",
        "  Y.replace(13,1, inplace = True) #223\n",
        "  #\n",
        "  Y.replace(14,1, inplace = True) #224\n",
        "  #\n",
        "  Y.replace(15,0, inplace = True) #225\n",
        "  Y.replace(16,0, inplace = True) #229\n",
        "  #\n",
        "  Y.replace(17,1, inplace = True) #231\n",
        "  #\n",
        "  Y.replace(18,1, inplace = True) #232\n",
        "  #\n",
        "  Y.replace(19,0, inplace = True) #233\n",
        "  Y.replace(20,0, inplace = True) #239\n",
        "  #\n",
        "  Y.replace(21,1, inplace = True) #241\n",
        "  #\n",
        "  Y.replace(22,1, inplace = True) #242\n",
        "  #\n",
        "  Y.replace(23,1, inplace = True) #243\n",
        "  #\n",
        "  Y.replace(24,1, inplace = True) #244\n",
        "  #\n",
        "  Y.replace(25,1, inplace = True) #245\n",
        "  #\n",
        "  Y.replace(26,0, inplace = True) #249\n",
        "  Y.replace(27,0, inplace = True) #251\n",
        "  Y.replace(28,0, inplace = True) #252\n",
        "  Y.replace(29,0, inplace = True) #259\n",
        "  #\n",
        "  Y.replace(30,1, inplace = True) #261\n",
        "  #\n",
        "  Y.replace(31,0, inplace = True) #262\n",
        "  #\n",
        "  Y.replace(32,0, inplace = True) #269\n",
        "  #\n",
        "  Y.replace(33,1, inplace = True) #271\n",
        "  #\n",
        "  Y.replace(34,0, inplace = True) #272\n",
        "  Y.replace(35,0, inplace = True) #273\n",
        "  Y.replace(36,0, inplace = True) #274\n",
        "  Y.replace(37,0, inplace = True) #275\n",
        "  Y.replace(38,0, inplace = True) #279\n",
        "  #\n",
        "  Y.replace(39,1, inplace = True) #281\n",
        "  #\n",
        "  Y.replace(40,0, inplace = True) #282\n",
        "  Y.replace(41,0, inplace = True) #283\n",
        "  Y.replace(42,0, inplace = True) #284\n",
        "  Y.replace(43,0, inplace = True) #285\n",
        "  Y.replace(44,0, inplace = True) #28\n",
        "  Y.replace(45,0, inplace = True) #289\n",
        "  #\n",
        "  Y.replace(46,1, inplace = True) #299\n",
        "\n",
        "  #Return\n",
        "  return Y\n"
      ],
      "metadata": {
        "id": "CeeV5Qwwkobr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequent / Rare"
      ],
      "metadata": {
        "id": "bP7aq4eFgtfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mark accident types as frequent / rare\n",
        "#Train data\n",
        "Y_train_three_freq = label_rare(Y_train_three)\n",
        "#Test data\n",
        "Y_test_three_freq = label_rare(Y_test_three)\n",
        "#Valid data\n",
        "Y_valid_three_freq = label_rare(Y_valid_three)\n",
        "\n",
        "#Print\n",
        "print(len(np.unique(Y_train_three_freq)))\n",
        "#Folgende Klassen sollten vorhergesagt werden\n",
        "print(np.unique(Y_valid_three_freq))"
      ],
      "metadata": {
        "id": "11QxI3MPd7lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data for subsequent model (after classification in rare / frequent)"
      ],
      "metadata": {
        "id": "FaumvK6GnEx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rare accident types\n",
        "rarelist = [2, 4, 7, 8, 9, 10, 15, 16, 19, 20, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45]\n",
        "\n",
        "#Frequent accident types\n",
        "freqlist = [0, 1, 3, 5, 6, 11, 12, 13, 14, 17, 18, 21, 22, 23, 24, 25, 30, 33, 39, 46]\n",
        "\n",
        "\n",
        "#Prepare dataset\n",
        "def prepare_frequent_data(X, Y, freqlist):\n",
        "\n",
        "  #Combine X and Y\n",
        "  XY = pd.concat([X, Y], axis = 1)\n",
        "\n",
        "  #Filter for frequent accident types\n",
        "  XY_freq = XY[XY[\"AccidentType\"].isin(freqlist)]\n",
        "\n",
        "  #Split data\n",
        "  X_train = XY_freq.drop([\"AccidentType\"], axis = 1)\n",
        "  Y_train = XY_freq.AccidentType\n",
        "\n",
        "  #Return\n",
        "  return X_train, Y_train\n",
        "\n",
        "#Prepare data\n",
        "X_train_three_onlyfreq, Y_train_three_onlyfreq = prepare_frequent_data(X_train_three_all_pre, Y_train_three, freqlist)\n",
        "\n",
        "X_test_three_onlyfreq, Y_test_three_onlyfreq = prepare_frequent_data(X_test_three_all_pre, Y_test_three, freqlist)\n",
        "\n",
        "X_valid_three_onlyfreq, Y_valid_three_onlyfreq = prepare_frequent_data(X_valid_three_all_pre, Y_valid_three, freqlist)\n",
        "\n"
      ],
      "metadata": {
        "id": "EZ0dsREFnDcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_three_onlyfreq"
      ],
      "metadata": {
        "id": "oAgnxlIWo0JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling"
      ],
      "metadata": {
        "id": "7_aHwrwjQw4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequent / Rare"
      ],
      "metadata": {
        "id": "6kEhA9PtgyAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pool the data\n",
        "#Pool data: 3-digit-accident type\n",
        "train_three_data_freq = Pool(X_train_three_all_pre,\n",
        "                  label = Y_train_three_freq,\n",
        "                  cat_features = [X_train_three_all_pre.columns.get_loc(c) for c in cat_columns if c in X_train_three_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])\n",
        "\n",
        "\n",
        "test_three_data_freq = Pool(X_test_three_all_pre,\n",
        "                  label = Y_test_three_freq,\n",
        "                  cat_features = [X_test_three_all_pre.columns.get_loc(c) for c in cat_columns if c in X_test_three_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])\n",
        "\n",
        "\n",
        "valid_three_data_freq = Pool(X_valid_three_all_pre,\n",
        "                  label = Y_valid_three_freq,\n",
        "                  cat_features = [X_valid_three_all_pre.columns.get_loc(c) for c in cat_columns if c in X_valid_three_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])"
      ],
      "metadata": {
        "id": "nV8ArtTag0P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pool the data\n",
        "#Pool data: 3-digit-accident type\n",
        "train_three_data_onlyfreq = Pool(X_train_three_onlyfreq,\n",
        "                  label = Y_train_three_onlyfreq,\n",
        "                  cat_features = [X_train_three_all_pre.columns.get_loc(c) for c in cat_columns if c in X_train_three_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])\n",
        "\n",
        "\n",
        "test_three_data_onlyfreq = Pool(X_test_three_onlyfreq,\n",
        "                  label = Y_test_three_onlyfreq,\n",
        "                  cat_features = [X_test_three_all_pre.columns.get_loc(c) for c in cat_columns if c in X_test_three_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])\n",
        "\n",
        "\n",
        "valid_three_data_onlyfreq = Pool(X_valid_three_onlyfreq,\n",
        "                  label = Y_valid_three_onlyfreq,\n",
        "                  cat_features = [X_valid_three_all_pre.columns.get_loc(c) for c in cat_columns if c in X_valid_three_all_pre],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"])"
      ],
      "metadata": {
        "id": "xgaGXVIXpX8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model D1\n",
        "\n",
        "Model Freq / Rare"
      ],
      "metadata": {
        "id": "StQSUzAqTMEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "without feature selection"
      ],
      "metadata": {
        "id": "pXGln4pn1asD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "\n",
        "model_d1_freq = fit_model(\n",
        "    ################\n",
        "    train_three_data_freq, test_three_data_freq,\n",
        "    ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "2BCRGaUZ1d_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_d1_freq.save_model('0_Ergebnisse/Catboost/models/D1_freq_220918_model_0.9826756497', format = \"cbm\")"
      ],
      "metadata": {
        "id": "gas1dsCF1o8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection"
      ],
      "metadata": {
        "id": "4gyGnh2d1ZBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select the most suitable features\n",
        "\n",
        "from catboost import CatBoostClassifier, EShapCalcType, EFeaturesSelectionAlgorithm\n",
        "\n",
        "\n",
        "def select_features_freq(featurenumber, Xtrain, Ytrain, Xtest, Ytest, algorithm: EFeaturesSelectionAlgorithm, steps: int = 1):\n",
        "    print('Algorithm:', algorithm)\n",
        "    #Drop not needed columns\n",
        "    Xtrain = Xtrain.drop([\"Embedding\", \"Description\", \"ID\"], axis = 1, errors='ignore')\n",
        "    Xtest = Xtest.drop([\"Embedding\", \"Description\", \"ID\"], axis = 1, errors='ignore')\n",
        "    #Build model\n",
        "    model = CatBoostClassifier(iterations=2000, random_seed=0,  task_type = \"GPU\")\n",
        "    summary = model.select_features(\n",
        "        #Training features\n",
        "        Pool(Xtrain, Ytrain, cat_features = [Xtrain.columns.get_loc(c) for c in cat_columns if c in Xtrain]),\n",
        "        #Evaluation features\n",
        "        eval_set=Pool(Xtest, Ytest, cat_features = [Xtest.columns.get_loc(c) for c in cat_columns if c in Xtest]),\n",
        "        #Features to be selected\n",
        "        features_for_select = cat_columns + num_columns,\n",
        "        #Number of features to be selected\n",
        "        num_features_to_select= featurenumber,\n",
        "        steps=steps,\n",
        "        algorithm=algorithm,\n",
        "        shap_calc_type=EShapCalcType.Approximate, #EShapCalcType.Regular\n",
        "        #train_final_model=True,\n",
        "        train_final_model = False,\n",
        "        logging_level='Silent',\n",
        "        plot=True,\n",
        "    )\n",
        "    print('Selected features:', summary['selected_features_names'])\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "Ith0MUJlqxJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "\n",
        "#Perform feature selection\n",
        "#Most important features:\n",
        "#Drugs\n",
        "#Medicines\n",
        "#CollisionType\n",
        "#CauseP1\n",
        "\n",
        "\n",
        "feat_d1_freq = select_features_freq(4, X_train_three_all_pre, Y_train_three_freq, X_test_three_all_pre, Y_test_three_freq, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "6VyQcwUwln-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_d1_freq = [\"Description\", 'Drugs', 'Medicines', 'CollisionType', 'CauseP1']\n",
        "\n",
        "X_train_d1_freq = X_train_three_all_pre[features_d1_freq]\n",
        "X_test_d1_freq = X_test_three_all_pre[features_d1_freq]\n",
        "\n",
        "train_three_data_freq_fs = Pool(X_train_d1_freq,\n",
        "                  label = Y_train_three_freq,\n",
        "                  cat_features = [X_train_d1_freq.columns.get_loc(c) for c in cat_columns if c in X_train_d1_freq],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_three_data_freq_fs = Pool(X_test_d1_freq,\n",
        "                  label = Y_test_three_freq,\n",
        "                  cat_features = [X_test_d1_freq.columns.get_loc(c) for c in cat_columns if c in X_test_d1_freq],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "Wkh_XTygmk7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/D1_freq_220918_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_d1_freq, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "zrnT0KvfnTbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/D1_freq_220918_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "kNvGclqBuS2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "\n",
        "model_d1_freq_fs = fit_model(\n",
        "    ################\n",
        "    train_three_data_freq_fs, test_three_data_freq_fs,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n"
      ],
      "metadata": {
        "id": "bgXv6qVmTN5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_d1_freq_fs.save_model('0_Ergebnisse/Catboost/models/D1_freq_fs_220918_model_0.9826756497', format = \"cbm\")"
      ],
      "metadata": {
        "id": "BCjLmmNmT7MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submodel D1"
      ],
      "metadata": {
        "id": "FxCBc5AVUoR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submodel for frequent accident types"
      ],
      "metadata": {
        "id": "jmM_M3lgpzNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "without feature selection"
      ],
      "metadata": {
        "id": "NrUnyRZf0VKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model WITH FEATURE SELECTION\n",
        "\n",
        "model_d1_sub = fit_model(\n",
        "    ################\n",
        "    train_three_data_onlyfreq, test_three_data_onlyfreq,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n"
      ],
      "metadata": {
        "id": "keThflqS0WxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_d1_sub.save_model('0_Ergebnisse/Catboost/models/D1_sub_220918_model_0.8598039216', format = \"cbm\")"
      ],
      "metadata": {
        "id": "I-ze9q4j0qlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with feature selection"
      ],
      "metadata": {
        "id": "wyMb1f3v0S_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform feature selection\n",
        "\n",
        "#Most important features:\n",
        "#CyclePath\n",
        "#CollisionType\n",
        "#CauseP1\n",
        "#Pariticpant2\n",
        "\n",
        "\n",
        "feat_d1_sub_freq = select_features_freq(4, X_train_three_onlyfreq, Y_train_three_onlyfreq, X_test_three_onlyfreq, Y_test_three_onlyfreq, algorithm=EFeaturesSelectionAlgorithm.RecursiveByLossFunctionChange, steps=10)"
      ],
      "metadata": {
        "id": "rQLpNndPpSEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature vector with best features and get subset of full data set\n",
        "\n",
        "features_d1_sub_freq = [\"Description\", 'CyclePath', 'CollisionType', 'CauseP1', 'Participant2' ]\n",
        "\n",
        "X_train_d1_sub_freq = X_train_three_onlyfreq[features_d1_sub_freq]\n",
        "X_test_d1_sub_freq = X_test_three_onlyfreq[features_d1_sub_freq]\n",
        "\n",
        "train_three_data_onlyfreq_fs = Pool(X_train_d1_sub_freq,\n",
        "                  label = Y_train_three_onlyfreq,\n",
        "                  cat_features = [X_train_d1_sub_freq.columns.get_loc(c) for c in cat_columns if c in X_train_d1_sub_freq],\n",
        "                  text_features= [\"Description\"])\n",
        "\n",
        "test_three_data_onlyfreq_fs = Pool(X_test_d1_sub_freq,\n",
        "                  label = Y_test_three_onlyfreq,\n",
        "                  cat_features = [X_test_d1_sub_freq.columns.get_loc(c) for c in cat_columns if c in X_test_d1_sub_freq],\n",
        "                  text_features= [\"Description\"])"
      ],
      "metadata": {
        "id": "IhmS6qTVyaCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/D1_sub_freq_220918_feature_selection')\n",
        "with open(str(abspath), 'wb') as handle:\n",
        "  pickle.dump(feat_d1_sub_freq, handle, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "ZtSMSLy2zTmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open feature results\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/D1_sub_freq_220918_feature_selection')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  features = pickle.load(pkl)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "EBFksgWrue6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model WITH FEATURE SELECTION\n",
        "\n",
        "model_d1_sub_fs = fit_model(\n",
        "    ################\n",
        "    train_three_data_onlyfreq_fs, test_three_data_onlyfreq_fs,\n",
        "    #ignored_features = emb_columns ,\n",
        "    ###############\n",
        "    iterations=1700,\n",
        "    learning_rate = 0.1, #Learning rate is dependend on number of iterations for Multiclass and can be overwritten here.\n",
        "    ###############\n",
        "    task_type='GPU',\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cnvDKMILp2gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save catboost model\n",
        "model_d1_sub_fs.save_model('0_Ergebnisse/Catboost/models/D1_sub_fs_220918_model_0.8558823529', format = \"cbm\")"
      ],
      "metadata": {
        "id": "t7qfyERvaHqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Test-Data\n",
        "\n",
        "#Predict\n",
        "d1_sub_test_pred_class = model_d1_sub.predict(test_three_data_onlyfreq)\n",
        "#Report\n",
        "d1_sub_test_report = get_report(Y_test_three_onlyfreq, d1_sub_test_pred_class)\n"
      ],
      "metadata": {
        "id": "JMfc9pxiqbsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions: Valid-Data\n",
        "\n",
        "#Predict\n",
        "d1_sub_valid_pred_class = model_d1_sub.predict(valid_three_data_onlyfreq)\n",
        "#Report\n",
        "d1_sub_valid_report = get_report(Y_valid_three_onlyfreq, d1_sub_valid_pred_class)"
      ],
      "metadata": {
        "id": "Z9Ob8780qpGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline D1 Prediction"
      ],
      "metadata": {
        "id": "5DVFXfzqUtIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_frequent(X_data, cat_columns, model_d1_freq, model_d1_sub):\n",
        "\n",
        "  #Assign ID\n",
        "  X_data.loc[:, \"ID\"] = X_data.index\n",
        "\n",
        "  #Pool data for catboost algorithm\n",
        "  X_data_pool = Pool(X_data,\n",
        "                  cat_features = [X_data.columns.get_loc(c) for c in cat_columns if c in X_data],\n",
        "                  text_features= [\"Description\"],\n",
        "                  embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                  )\n",
        "\n",
        "  #Predict rare / frequent accident types\n",
        "  #1 = frequent\n",
        "  #0 = rare\n",
        "  class_frequent = model_d1_freq.predict(X_data_pool)\n",
        "\n",
        "  #Combine prediction with original data\n",
        "  X_n = X_data.copy()\n",
        "  X_n.loc[:, \"Frequency\"] = class_frequent\n",
        "  X_new = X_n.copy()\n",
        "\n",
        "  #Filter out the rare accidents -> we just want to make further predictions for the frequent accident types\n",
        "  X_freq = X_new[X_new[\"Frequency\"] == 1]\n",
        "  X_rare = X_new[X_new[\"Frequency\"] == 0]\n",
        "\n",
        "  #Pool the new dataset for 3-digit-type prediction\n",
        "  X_freq_pool = Pool(X_freq,\n",
        "                    cat_features = [X_freq.columns.get_loc(c) for c in cat_columns if c in X_freq],\n",
        "                    text_features= [\"Description\"],\n",
        "                    embedding_features = [\"Embedding\"] #comment out for feature selection\n",
        "                     )\n",
        "\n",
        "  #Make 3-digit-type prediction\n",
        "  class_at = model_d1_sub.predict(X_freq_pool)\n",
        "\n",
        "  #Make copy\n",
        "  X_freq_new = X_freq.copy()\n",
        "  X_rare_new = X_rare.copy()\n",
        "\n",
        "  #Assign predictions\n",
        "  X_freq_new.loc[:, \"AccidentType\"] = class_at\n",
        "\n",
        "  #if len(X_rare_new.loc[X_rare_new[\"Frequency\"] == 0]) != 0:\n",
        "    #X_rare_new.loc[:, \"AccidentType\"] = 999\n",
        "\n",
        "  #if X_rare_new.loc[X_rare_new[\"Frequency\"] == 0]) != 0:\n",
        "  X_rare_new.loc[:, \"AccidentType\"] = 47\n",
        "\n",
        "\n",
        "  #Bind data frames together\n",
        "  X_total = pd.concat([X_freq_new, X_rare_new])\n",
        "\n",
        "  #Sort by index in ascending order\n",
        "  X_total = X_total.sort_values(by = [\"ID\"], axis = 0, ascending = True)\n",
        "\n",
        "  #Return\n",
        "  return X_total\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BjCt8xjZU0US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#corrected list with 48 3ATs (including unknown )\n",
        "classes_list_freq = [201, 202, 203, 204, 209,\n",
        "                211, 212, 213, 214, 215, 219,\n",
        "                221, 222, 223, 224, 225, 229,\n",
        "                231, 232, 233, 239,\n",
        "                241, 242, 243, 244, 245, 249,\n",
        "                251, 252, 259,\n",
        "                261, 262, 269,\n",
        "                271, 272, 273, 274, 275, 279,\n",
        "                281, 282, 283, 284, 285, 286, 289,\n",
        "                299, 999]\n",
        "\n",
        "\n",
        "#classes_list_freq_red = [201, 202, 204, 211, 212, 221, 222, 223, 224, 231, 232, 241, 242, 243, 244, 261, 271, 281, 299, 999 ]"
      ],
      "metadata": {
        "id": "6gW53SmA3C-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to get classification report with correct accident type labels\n",
        "\n",
        "def get_report_freq(true, pred, labellist=None):\n",
        "\n",
        "  #Copy\n",
        "  Y_n = true.copy()\n",
        "\n",
        "  #Prepare input data for the correct classification\n",
        "  Y_rare = label_rare(Y_n)\n",
        "\n",
        "  #Combine\n",
        "  X_n = pd.DataFrame(Y_n.copy())\n",
        "  X_n.loc[:, \"Frequency\"] = Y_rare\n",
        "  X_n.loc[:, \"AccidentType\"] = Y_n\n",
        "\n",
        "  #Rename rare accident types\n",
        "  X_n.loc[X_n[\"Frequency\"] == 0, \"AccidentType\"] = 47\n",
        "\n",
        "  #Extract true label\n",
        "  truelabel = X_n.AccidentType\n",
        "\n",
        "  #Extract prediction\n",
        "  predlabel = pred.AccidentType\n",
        "\n",
        "  #Get initial report\n",
        "  report = classification_report(truelabel, predlabel, output_dict=True, labels = np.unique(truelabel))\n",
        "  #Transform it to pandas\n",
        "  report_pd = pd.DataFrame(report).transpose()\n",
        "  #Get true labels\n",
        "  if labellist != None:\n",
        "    #Get indicies\n",
        "    index_list = list(report_pd.index)\n",
        "    #Remove last three leements\n",
        "    index_list_short = index_list[:len(index_list)-3]\n",
        "    #Convert list elements to integer\n",
        "    index_list_short = [int(x) for x in index_list_short]\n",
        "    #Get true class labels based on index\n",
        "    label_series = pd.Series(labellist)\n",
        "    true_labels = list(label_series[index_list_short])\n",
        "    #Get new classification report with correct labels\n",
        "    report_new = classification_report(truelabel, predlabel, output_dict=True, target_names = true_labels)\n",
        "    #Transform to pandas again\n",
        "    report_new_pd = pd.DataFrame(report_new).transpose()\n",
        "    #Print report\n",
        "    print(report_new_pd)\n",
        "    #Return corrected Y labels, true labels (accident types), report\n",
        "    return truelabel, true_labels, report_new_pd\n",
        "  else:\n",
        "    print(report_pd)\n",
        "    return report_pd"
      ],
      "metadata": {
        "id": "kpl7vO2Jbz6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D1 Prediction"
      ],
      "metadata": {
        "id": "6BW54SGeaj_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without Feature Selection"
      ],
      "metadata": {
        "id": "FBgin46F2S52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Prediction\n",
        "#Predict\n",
        "d1_test = predict_frequent(X_test_three_all_pre, cat_columns, model_d1_freq, model_d1_sub)\n",
        "\n",
        "#Report\n",
        "d1_test_report = get_report_freq(true = Y_test_three, pred = d1_test, labellist = classes_list_freq_red)"
      ],
      "metadata": {
        "id": "nN-9_ykA2VDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Valid Prediction\n",
        "#Predict\n",
        "d1_valid = predict_frequent(X_valid_three_all_pre, cat_columns, model_d1_freq, model_d1_sub)\n",
        "\n",
        "#Report\n",
        "d1_valid_report = get_report_freq(true = Y_valid_three, pred = d1_valid)"
      ],
      "metadata": {
        "id": "acTqa0vK2Xbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Feature Selection"
      ],
      "metadata": {
        "id": "22mdtAAN1_Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Prediction\n",
        "#Predict\n",
        "d1_test_fs = predict_frequent(X_test_three_all_pre, cat_columns, model_d1_freq_fs, model_d1_sub_fs)\n",
        "\n",
        "#Report\n",
        "Y_test_three_freqresult, d1_test_fs_labels, d1_test_fs_report = get_report_freq(true = Y_test_three, pred = d1_test_fs,  labellist = classes_list_freq)\n",
        "\n",
        "#Save\n",
        "d1_test_fs_report.to_pickle('0_Ergebnisse/Catboost/results/D1_fs_221005_test_report_0.825458')"
      ],
      "metadata": {
        "id": "sG4eVEboalvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation data"
      ],
      "metadata": {
        "id": "SFwtDw3EhqEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Valid Prediction\n",
        "#Predict\n",
        "d1_valid_fs = predict_frequent(X_valid_three_all_pre, cat_columns, model_d1_freq_fs, model_d1_sub_fs)\n",
        "\n",
        "#Report\n",
        "Y_valid_three_freqresult, d1_valid_fs_labels, d1_valid_fs_report = get_report_freq(true = Y_valid_three, pred = d1_valid_fs, labellist = classes_list_freq)"
      ],
      "metadata": {
        "id": "mFhYYK0nhr0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save report\n",
        "d1_valid_fs_report.to_pickle('0_Ergebnisse/Catboost/results/D1_fs_221005_valid_report_0.808461')"
      ],
      "metadata": {
        "id": "Ph9UQPzyWX_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save prediction results\n",
        "d1_fs_results = pd.concat([pd.DataFrame(Y_test_three_freqresult), pd.DataFrame(d1_test_fs.AccidentType),pd.DataFrame(Y_valid_three_freqresult), pd.DataFrame(d1_valid_fs.AccidentType)], axis = 1)\n",
        "d1_fs_results.columns =[ \"Y_test\", \"Pred_test\", \"Y_valid\", \"Pred_valid\"]\n",
        "\n",
        "print(d1_fs_results)\n",
        "\n",
        "\n",
        "d1_fs_results.to_pickle('0_Ergebnisse/Catboost/results/D1_fs_221005_all_results')"
      ],
      "metadata": {
        "id": "BslY2uf1Syjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zUJpVrRfxY_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview over experiments"
      ],
      "metadata": {
        "id": "uHHz6r9Bt9aW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overview aligned with written paper:\n",
        "\n",
        "Paper | Colab\n",
        "\n",
        "B1.4 | V3a\n",
        "\n",
        "C1.1 | M1.1\n",
        "\n",
        "C1.2 | M1.2\n",
        "\n",
        "C1.3.1 | M1.3.1\n",
        "\n",
        "C1.3.2 | M1.3.2\n",
        "\n",
        "C1.4 | M1.4\n",
        "\n",
        "C2.1 | V3b\n",
        "\n",
        "C2.2 | V3afs\n",
        "\n",
        "C2.3 | V3bfscw\n",
        "\n",
        "D1   | D1fs\n",
        "\n"
      ],
      "metadata": {
        "id": "gCs0MDtIuCRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load classification reports"
      ],
      "metadata": {
        "id": "HIszYPaizjwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load classification reports for valid data from previous experiments\n",
        "\n",
        "###########################Variantenvergleich##############################################\n",
        "#V1\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V1_220627_valid_report_0.635688')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v1_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V1_220627_test_report_0.6891241578')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v1_test_report = pickle.load(pkl)\n",
        "\n",
        "#V2\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V2_220627_valid_report_0.790892')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v2_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V2_220627_test_report_0.8046198268')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v2_test_report = pickle.load(pkl)\n",
        "\n",
        "#V3a\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V3_220627_valid_report_0.808550')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3a_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V3_220627_test_report_0.8392685274')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3a_test_report = pickle.load(pkl)\n",
        "\n",
        "#V3b = C2.1: All features / class weights / global\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V3b_220629_valid_report_0.668216')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3b_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V3b_220629_test_report_0.546679376')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3b_test_report = pickle.load(pkl)\n",
        "\n",
        "#V4\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V4_220627_valid_report_0.663569')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v4_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V4_220627_test_report_0.7305101059')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v4_test_report = pickle.load(pkl)\n",
        "\n",
        "#V5\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V5_220627_valid_report_0.774164')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v5_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V5_220627_test_report_0.8267564966')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v5_test_report = pickle.load(pkl)\n",
        "\n",
        "#V6 (Bert)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V6_220702_valid_report_0.003')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v6_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V6_220703_test_report_0.002')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v6_test_report = pickle.load(pkl)\n",
        "\n",
        "#V7 (Bert)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V7_220702_valid_report_0.80')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v7_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V7_220703_test_report_0.81')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v7_test_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#V8 (Bert)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V8_220702_valid_report_0.79')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v8_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V8_220703_test_report_0.80')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v8_test_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#V9 (V6 Catboost only BERT embeddings)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V6_220909_valid_report_0.682156')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v9_valid_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V6_220909_test_report_0.7074109721')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v9_test_report = pickle.load(pkl)\n",
        "\n",
        "#V10 (V7 Catboost text and BERT embeddings)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V7_220909_valid_report_0.803903')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v10_valid_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V7_220909_test_report_0.8113570741')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v10_test_report = pickle.load(pkl)\n",
        "\n",
        "#V3afs (V3 with just selected features)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V3afs_220914_valid_report_0.799123')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3afs_valid_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V3afs_220914_test_report_0.8363811357')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3afs_test_report = pickle.load(pkl)\n",
        "\n",
        "#V3bfs (V3b with just selected features (fs) and class weights (cw))\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V8b_220914_valid_report_0.728589')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3bfscw_valid_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V8b_220914_test_report_0.5362665832')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3bfscw_test_report = pickle.load(pkl)\n",
        "\n",
        "###########################Modellkonzeption##############################################\n",
        "\n",
        "#M1.1 (LCPN) with all features\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_220629_valid_report_0.799257')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_220629_test_report_0.834456')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1_test_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#M1.2 (LCPN) with all features and class weights (cw)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_cw_220917_valid_report_0.746629')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1cw_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_cw_220917_test_report_0.814369 ')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1cw_test_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#M1.3.1 (LCPN) with selected features (fs)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs_220914_valid_report_0.781415')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fs_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs_220914_test_report_0.823512')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fs_test_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#M1.3.2 (LCPN) with four selected features (fs) per sumbodel\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs4_220916_valid_report_0.761246')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fs4_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs4_220916_test_report_0.817818 ')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fs4_test_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#M1.4 (LCPN) with selected features (fs) and class weights (cw)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs_cw_220914_valid_report_0.707274')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fscw_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs_cw_220914_test_report_0.715872')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fscw_test_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "###########################Aggregierte Vorhersage#########################################\n",
        "##D1 (Flat) with rare/freq accidents and then freq-model with features (fs)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/D1_fs_221005_valid_report_0.808461')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  d1fs_valid_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/D1_fs_221005_test_report_0.825458')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  d1fs_test_report = pickle.load(pkl)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############################Optimierung####################################################\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/O1_220703_test_report_0.8277189605')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  o1_test_report = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/O1_220703_valid_report_0.822491')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  o1_valid_report = pickle.load(pkl)"
      ],
      "metadata": {
        "id": "fEybBgt3zjRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v3bfscw_valid_report"
      ],
      "metadata": {
        "id": "SDjIgWP1UW-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Save reports for plotting in R studio with ggplot2\n",
        "\n",
        "#B1.4   f1-score valid: 0.792 / 17 predicted classes (V3a)\n",
        "v3a_valid_report.to_csv(('0_Ergebnisse/Overall/B1.4_V3a_220627_valid_report.csv'))\n",
        "\n",
        "#C1.3.1 f1-score valid: 0.781 / 18 predicted classes (M1fs)\n",
        "m1fs_valid_report.to_csv(('0_Ergebnisse/Overall/C1.3.1_M1_fs_220914_valid_report.csv'))\n",
        "\n",
        "\n",
        "#C2.1   f1-score valid: 0.706 / 23 predicted classes (V3b)\n",
        "v3b_valid_report.to_csv(('0_Ergebnisse/Overall/C2.1_V3b_220629_valid_report.csv'))\n",
        "\n",
        "\n",
        "#C2.2   f1-score valid: 0.799 / 17 predicted classes (v3afs)\n",
        "v3afs_valid_report.to_csv(('0_Ergebnisse/Overall/C2.2_V3afs_220914_valid_report.csv'))\n",
        "\n",
        "#C2.3   f1-score valid: 0.729 / 21 predicted classes (V3bfs)\n",
        "v3bfscw_valid_report.to_csv(('0_Ergebnisse/Overall/C2.3_V3bfscw_220914_valid_report.csv'))\n",
        "\n",
        "#D1fs   f1-score valid: 0.808461 / 18 predicted classes\n",
        "d1fs_valid_report.to_csv(('0_Ergebnisse/Overall/D1_D1fs_221005_valid_report.csv'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CnjLiHKdRYsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load prediction results"
      ],
      "metadata": {
        "id": "lHnikeZ-71X2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load prediction results of the single classifiers\n",
        "\n",
        "###########################Variantenvergleich##############################################\n",
        "\n",
        "#V1\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V1_220627_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v1_results = pickle.load(pkl)\n",
        "\n",
        "#V2\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V2_220627_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v2_results = pickle.load(pkl)\n",
        "\n",
        "#V3a\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V3_220627_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3a_results = pickle.load(pkl)\n",
        "\n",
        "#V3b = C2.1: All features / class weights / global\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V3b_220629_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3b_results = pickle.load(pkl)\n",
        "\n",
        "#V4\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V4_220627_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v4_results = pickle.load(pkl)\n",
        "\n",
        "#V5\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V5_220627_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v5_results = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#V6 (Bert)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V6_220702_valid_preds_0.003')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v6_results = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V6_220703_test_preds_0.002')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v6_results_test = pickle.load(pkl)\n",
        "\n",
        "#V7 (Bert)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V7_220702_valid_preds_0.80')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v7_results = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V7_220703_test_preds_0.81')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v7_results_test = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#V8 (Bert)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V8_220702_valid_preds_0.79')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v8_results = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Bert/results/V8_220703_test_preds_0.80')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v8_results_test = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#V9 (V6 Catboost only BERT embeddings)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V6_220909_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v9_results = pickle.load(pkl)\n",
        "\n",
        "\n",
        "\n",
        "#V10 (V7 Catboost text and BERT embeddings)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V7_220909_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v10_results = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#V3afs (V3a with just selected features (fs))\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V3afs_220914_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3afs_results = pickle.load(pkl)\n",
        "\n",
        "#V3bfs (V3b with just selected features (fs) and class weights (cw))\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/V8b_220914_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  v3bfscw_results = pickle.load(pkl)\n",
        "\n",
        "\n",
        "###########################Model design##############################################\n",
        "\n",
        "#M1 (LCPN) with all features and without class weights\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_220629_test_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1_test = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_220629_valid_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1_valid = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#M1.2 (LCPN) with all features and class weights (cw)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_cw_220917_test_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1cw_test = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_cw_220917_valid_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1cw_valid = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#M1.3.1 (LCPN) with selected features (fs)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs_220914_test_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fs_test = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs_220914_valid_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fs_valid = pickle.load(pkl)\n",
        "\n",
        "\n",
        "#M1.3.2 (LCPN) with four selected features (fs) per submodel\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs4_220916_test_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fs4_test = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs4_220916_valid_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fs4_valid = pickle.load(pkl)\n",
        "\n",
        "\n",
        "\n",
        "#M1.4 (LCPN) with selected features (fs) and class weights (cw)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs_cw_220914_test_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fscw_test = pickle.load(pkl)\n",
        "\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/M1_fs_cw_220914_valid_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  m1fscw_valid = pickle.load(pkl)\n",
        "\n",
        "\n",
        "###########################Frequent/rare prediction#########################################\n",
        "\n",
        "##D1 (Flat) with rare/freq accidents and then freq-model with features (fs)\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/D1_fs_221005_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  d1fs_results = pickle.load(pkl)\n",
        "\n",
        "\n",
        "###########################Optimization###################################################\n",
        "\n",
        "#O1\n",
        "abspath = os.path.abspath('0_Ergebnisse/Catboost/results/O1_220703_all_results')\n",
        "with open(str(abspath), 'rb') as pkl:\n",
        "  o1_results = pickle.load(pkl)\n"
      ],
      "metadata": {
        "id": "TGGJ0xpO74-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kappa Score\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1VgAd4gK9kTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute Kappa Score\n",
        "\n",
        "#Validation data\n",
        "v1_kappa_valid = cohen_kappa_score(v1_results.Y_valid, v1_results.Pred_valid)\n",
        "v2_kappa_valid = cohen_kappa_score(v2_results.Y_valid, v2_results.Pred_valid)\n",
        "v3a_kappa_valid = cohen_kappa_score(v3a_results.Y_valid, v3a_results.Pred_valid)\n",
        "v3b_kappa_valid = cohen_kappa_score(v3b_results.Y_valid, v3b_results.Pred_valid)\n",
        "v4_kappa_valid = cohen_kappa_score(v4_results.Y_valid, v4_results.Pred_valid)\n",
        "v5_kappa_valid = cohen_kappa_score(v5_results.Y_valid, v5_results.Pred_valid)\n",
        "v6_kappa_valid = cohen_kappa_score(v6_results.Y_valid, v6_results.Pred_valid)\n",
        "v7_kappa_valid = cohen_kappa_score(v7_results.Y_valid, v7_results.Pred_valid)\n",
        "v8_kappa_valid = cohen_kappa_score(v8_results.Y_valid, v8_results.Pred_valid)\n",
        "\n",
        "v9_kappa_valid = cohen_kappa_score(v9_results.Y_valid, v9_results.Pred_valid)\n",
        "v10_kappa_valid = cohen_kappa_score(v10_results.Y_valid, v10_results.Pred_valid)\n",
        "\n",
        "v3afs_kappa_valid = cohen_kappa_score(v3afs_results.Y_valid, v3afs_results.Pred_valid)\n",
        "v3bfs_kappa_valid = cohen_kappa_score(v3bfs_results.Y_valid, v3bfs_results.Pred_valid)\n",
        "\n",
        "m1_kappa_valid = cohen_kappa_score(m1_valid.Y_three, m1_valid.AccidentType)\n",
        "\n",
        "\n",
        "o1_kappa_valid = cohen_kappa_score(o1_results.Y_valid, o1_results.Pred_valid )\n",
        "###\n",
        "\n",
        "kappa_valid = [[\"V1\", v1_kappa_valid], [\"V2\", v2_kappa_valid], [\"V3a\", v3a_kappa_valid], [\"V3b\", v3b_kappa_valid],  [\"V4\", v4_kappa_valid], [\"V5\", v5_kappa_valid], [\"V6\", v6_kappa_valid], [\"V7\", v7_kappa_valid], [\"V8\", v8_kappa_valid], [\"V9\", v9_kappa_valid], [\"V10\", v10_kappa_valid],[\"V3afs\", v3afs_kappa_valid],[\"V3bfs\", v3bfs_kappa_valid], [\"M1\", m1_kappa_valid], [\"O1\", o1_kappa_valid]]\n",
        "kappa_valid_results = pd.DataFrame(kappa_valid, columns = [\"Experiment\", \"Valid: Cohens_kappa\"])\n",
        "\n",
        "print(kappa_valid_results)\n",
        "\n",
        "v3a_results[v3a_results['Y_test'].notna()].Y_test\n",
        "\n",
        "#Test data\n",
        "v1_kappa_test = cohen_kappa_score(v1_results[v1_results['Y_test'].notna()].Y_test, v1_results[v1_results['Pred_test'].notna()].Pred_test)\n",
        "v2_kappa_test = cohen_kappa_score(v2_results[v2_results['Y_test'].notna()].Y_test, v2_results[v2_results['Pred_test'].notna()].Pred_test)\n",
        "v3a_kappa_test = cohen_kappa_score(v3a_results[v3a_results['Y_test'].notna()].Y_test, v3a_results[v3a_results['Pred_test'].notna()].Pred_test)\n",
        "v3b_kappa_test = cohen_kappa_score(v3b_results[v3b_results['Y_test'].notna()].Y_test, v3b_results[v3b_results['Pred_test'].notna()].Pred_test)\n",
        "v4_kappa_test = cohen_kappa_score(v4_results[v4_results['Y_test'].notna()].Y_test, v4_results[v4_results['Pred_test'].notna()].Pred_test)\n",
        "v5_kappa_test = cohen_kappa_score(v5_results[v5_results['Y_test'].notna()].Y_test, v5_results[v5_results['Pred_test'].notna()].Pred_test)\n",
        "v6_kappa_test = cohen_kappa_score(v6_results_test[v6_results_test['Y_test'].notna()].Y_test, v6_results_test[v6_results_test['Pred_test'].notna()].Pred_test)\n",
        "v7_kappa_test = cohen_kappa_score(v7_results_test[v7_results_test['Y_test'].notna()].Y_test, v7_results_test[v7_results_test['Pred_test'].notna()].Pred_test)\n",
        "v8_kappa_test = cohen_kappa_score(v8_results_test[v8_results_test['Y_test'].notna()].Y_test, v8_results_test[v8_results_test['Pred_test'].notna()].Pred_test)\n",
        "\n",
        "v3afs_kappa_test = cohen_kappa_score(v3afs_results[v3afs_results['Y_test'].notna()].Y_test, v3afs_results[v3afs_results['Pred_test'].notna()].Pred_test)\n",
        "v3bfs_kappa_test = cohen_kappa_score(v3bfs_results[v3bfs_results['Y_test'].notna()].Y_test, v3bfs_results[v3bfs_results['Pred_test'].notna()].Pred_test)\n",
        "\n",
        "v9_kappa_test = cohen_kappa_score(v9_results[v9_results['Y_test'].notna()].Y_test, v9_results[v9_results['Pred_test'].notna()].Pred_test)\n",
        "v10_kappa_test = cohen_kappa_score(v10_results[v10_results['Y_test'].notna()].Y_test, v10_results[v10_results['Pred_test'].notna()].Pred_test)\n",
        "\n",
        "\n",
        "m1_kappa_test = cohen_kappa_score(m1_test.Y_three, m1_test.AccidentType)\n",
        "\n",
        "\n",
        "o1_kappa_test = cohen_kappa_score(o1_results[o1_results['Y_test'].notna()].Y_test, o1_results[o1_results['Pred_test'].notna()].Pred_test )\n",
        "###\n",
        "\n",
        "kappa_test = [[\"V1\", v1_kappa_test], [\"V2\", v2_kappa_test], [\"V3a\", v3a_kappa_test], [\"V3b\", v3b_kappa_test],  [\"V4\", v4_kappa_test], [\"V5\", v5_kappa_test], [\"V6\", v6_kappa_test], [\"V7\", v7_kappa_test], [\"V8\", v8_kappa_test], [\"V9\", v9_kappa_test], [\"V10\", v10_kappa_test], [\"V3afs\", v3afs_kappa_test],[\"V3bfs\", v3bfs_kappa_test], [\"M1\", m1_kappa_test], [\"O1\", o1_kappa_test]]\n",
        "kappa_test_results = pd.DataFrame(kappa_test, columns = [\"Experiment\", \"Test: Cohens_kappa\"])\n",
        "\n",
        "print(kappa_test_results)\n",
        "\n"
      ],
      "metadata": {
        "id": "YyxUdMq29ixj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F1 Score"
      ],
      "metadata": {
        "id": "twz371e00rnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get F1-score, accuracy, precision and recall from classification experiments\n",
        "\n",
        "#Validation data\n",
        "f1_valid = pd.DataFrame([v1_valid_report.loc[\"weighted avg\", \"f1-score\"], v2_valid_report.loc[\"weighted avg\", \"f1-score\"], v3a_valid_report.loc[\"weighted avg\", \"f1-score\"], v3b_valid_report.loc[\"weighted avg\", \"f1-score\"], v4_valid_report.loc[\"weighted avg\", \"f1-score\"], v5_valid_report.loc[\"weighted avg\", \"f1-score\"], v6_valid_report.loc[\"weighted avg\", \"f1-score\"], v7_valid_report.loc[\"weighted avg\", \"f1-score\"], v8_valid_report.loc[\"weighted avg\", \"f1-score\"], v9_valid_report.loc[\"weighted avg\", \"f1-score\"], v10_valid_report.loc[\"weighted avg\", \"f1-score\"],v3afs_valid_report.loc[\"weighted avg\", \"f1-score\"],v3bfs_valid_report.loc[\"weighted avg\", \"f1-score\"], m1_valid_report.loc[\"weighted avg\", \"f1-score\"], o1_valid_report.loc[\"weighted avg\", \"f1-score\"]])\n",
        "accuracy_valid = pd.DataFrame([v1_valid_report.loc[\"accuracy\", \"support\"], v2_valid_report.loc[\"accuracy\", \"support\"], v3a_valid_report.loc[\"accuracy\", \"support\"], v3b_valid_report.loc[\"accuracy\", \"support\"], v4_valid_report.loc[\"accuracy\", \"support\"], v5_valid_report.loc[\"accuracy\", \"support\"], v6_valid_report.loc[\"accuracy\", \"support\"], v7_valid_report.loc[\"accuracy\", \"support\"], v8_valid_report.loc[\"accuracy\", \"support\"],v9_valid_report.loc[\"accuracy\", \"support\"], v10_valid_report.loc[\"accuracy\", \"support\"],v3afs_valid_report.loc[\"accuracy\", \"support\"], v3bfs_valid_report.loc[\"accuracy\", \"support\"], m1_valid_report.loc[\"accuracy\", \"support\"], o1_valid_report.loc[\"accuracy\", \"support\"]])\n",
        "precision_valid = pd.DataFrame([v1_valid_report.loc[\"weighted avg\", \"precision\"], v2_valid_report.loc[\"weighted avg\", \"precision\"], v3a_valid_report.loc[\"weighted avg\", \"precision\"], v3b_valid_report.loc[\"weighted avg\", \"precision\"], v4_valid_report.loc[\"weighted avg\", \"precision\"], v5_valid_report.loc[\"weighted avg\", \"precision\"], v6_valid_report.loc[\"weighted avg\", \"precision\"], v7_valid_report.loc[\"weighted avg\", \"precision\"], v8_valid_report.loc[\"weighted avg\", \"precision\"],v9_valid_report.loc[\"weighted avg\", \"precision\"], v10_valid_report.loc[\"weighted avg\", \"precision\"],v3afs_valid_report.loc[\"weighted avg\", \"precision\"],v3bfs_valid_report.loc[\"weighted avg\", \"precision\"], m1_valid_report.loc[\"weighted avg\", \"precision\"], o1_valid_report.loc[\"weighted avg\", \"precision\"]])\n",
        "recall_valid = pd.DataFrame([v1_valid_report.loc[\"weighted avg\", \"recall\"], v2_valid_report.loc[\"weighted avg\", \"recall\"], v3a_valid_report.loc[\"weighted avg\", \"recall\"], v3b_valid_report.loc[\"weighted avg\", \"recall\"], v4_valid_report.loc[\"weighted avg\", \"recall\"], v5_valid_report.loc[\"weighted avg\", \"recall\"], v6_valid_report.loc[\"weighted avg\", \"recall\"], v7_valid_report.loc[\"weighted avg\", \"recall\"], v8_valid_report.loc[\"weighted avg\", \"recall\"], v9_valid_report.loc[\"weighted avg\", \"recall\"], v10_valid_report.loc[\"weighted avg\", \"recall\"],v3afs_valid_report.loc[\"weighted avg\", \"recall\"],v3bfs_valid_report.loc[\"weighted avg\", \"recall\"], m1_valid_report.loc[\"weighted avg\", \"recall\"], o1_valid_report.loc[\"weighted avg\", \"recall\"]])\n",
        "\n",
        "#Test data\n",
        "f1_test = pd.DataFrame([v1_test_report.loc[\"weighted avg\", \"f1-score\"], v2_test_report.loc[\"weighted avg\", \"f1-score\"], v3a_test_report.loc[\"weighted avg\", \"f1-score\"], v3b_test_report.loc[\"weighted avg\", \"f1-score\"], v4_test_report.loc[\"weighted avg\", \"f1-score\"], v5_test_report.loc[\"weighted avg\", \"f1-score\"], v6_test_report.loc[\"weighted avg\", \"f1-score\"], v7_test_report.loc[\"weighted avg\", \"f1-score\"], v8_test_report.loc[\"weighted avg\", \"f1-score\"],v9_test_report.loc[\"weighted avg\", \"f1-score\"], v10_test_report.loc[\"weighted avg\", \"f1-score\"],v3afs_test_report.loc[\"weighted avg\", \"f1-score\"],v3bfs_test_report.loc[\"weighted avg\", \"f1-score\"],  m1_test_report.loc[\"weighted avg\", \"f1-score\"], o1_test_report.loc[\"weighted avg\", \"f1-score\"]])\n",
        "accuracy_test = pd.DataFrame([v1_test_report.loc[\"accuracy\", \"support\"], v2_test_report.loc[\"accuracy\", \"support\"], v3a_test_report.loc[\"accuracy\", \"support\"], v3b_test_report.loc[\"accuracy\", \"support\"], v4_test_report.loc[\"accuracy\", \"support\"], v5_test_report.loc[\"accuracy\", \"support\"], v6_test_report.loc[\"accuracy\", \"support\"], v7_test_report.loc[\"accuracy\", \"support\"], v8_test_report.loc[\"accuracy\", \"support\"],v9_test_report.loc[\"accuracy\", \"support\"], v10_test_report.loc[\"accuracy\", \"support\"],v3afs_test_report.loc[\"accuracy\", \"support\"],v3bfs_test_report.loc[\"accuracy\", \"support\"], m1_test_report.loc[\"accuracy\", \"support\"], o1_test_report.loc[\"accuracy\", \"support\"]])\n",
        "precision_test = pd.DataFrame([v1_test_report.loc[\"weighted avg\", \"precision\"], v2_test_report.loc[\"weighted avg\", \"precision\"], v3a_test_report.loc[\"weighted avg\", \"precision\"], v3b_test_report.loc[\"weighted avg\", \"precision\"], v4_test_report.loc[\"weighted avg\", \"precision\"], v5_test_report.loc[\"weighted avg\", \"precision\"], v6_test_report.loc[\"weighted avg\", \"precision\"], v7_test_report.loc[\"weighted avg\", \"precision\"], v8_test_report.loc[\"weighted avg\", \"precision\"],v9_test_report.loc[\"weighted avg\", \"precision\"], v10_test_report.loc[\"weighted avg\", \"precision\"],v3afs_test_report.loc[\"weighted avg\", \"precision\"],v3bfs_test_report.loc[\"weighted avg\", \"precision\"],  m1_test_report.loc[\"weighted avg\", \"precision\"], o1_test_report.loc[\"weighted avg\", \"precision\"]])\n",
        "recall_test = pd.DataFrame([v1_test_report.loc[\"weighted avg\", \"recall\"], v2_test_report.loc[\"weighted avg\", \"recall\"], v3a_test_report.loc[\"weighted avg\", \"recall\"], v3b_test_report.loc[\"weighted avg\", \"recall\"], v4_test_report.loc[\"weighted avg\", \"recall\"], v5_test_report.loc[\"weighted avg\", \"recall\"], v6_test_report.loc[\"weighted avg\", \"recall\"], v7_test_report.loc[\"weighted avg\", \"recall\"], v8_test_report.loc[\"weighted avg\", \"recall\"], v9_test_report.loc[\"weighted avg\", \"recall\"],  v10_test_report.loc[\"weighted avg\", \"recall\"],v3afs_test_report.loc[\"weighted avg\", \"recall\"],v3bfs_test_report.loc[\"weighted avg\", \"recall\"],  m1_test_report.loc[\"weighted avg\", \"recall\"], o1_test_report.loc[\"weighted avg\", \"recall\"]])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Combine with kappa results\n",
        "results = kappa_test_results.copy()\n",
        "results.loc[:, \"Test: F1_weighted_avg\"] = f1_test\n",
        "results.loc[:, \"Test: Accuracy\"] = accuracy_test\n",
        "results.loc[:, \"Test: Precision\"] = precision_test\n",
        "results.loc[:, \"Test: Recall\"] = recall_test\n",
        "\n",
        "results.loc[:, \"Valid: Cohens_kappa\"] = kappa_valid_results.iloc[:, 1]\n",
        "results.loc[:, \"Valid: F1_weighted_avg\"] = f1_valid\n",
        "results.loc[:, \"Valid: Accuracy\"] = accuracy_valid\n",
        "results.loc[:, \"Valid: Precision\"] = precision_valid\n",
        "results.loc[:, \"Valid: Recall\"] = recall_valid\n",
        "\n",
        "print(results)\n",
        "\n"
      ],
      "metadata": {
        "id": "gi2c6V4B0tiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save results\n",
        "results_v1_o1_all = results.copy()\n",
        "\n",
        "results_v1_o1_all.to_pickle('0_Ergebnisse/Overall/V1_O1_220914_all_results')\n",
        "results_v1_o1_all.to_csv('0_Ergebnisse/Overall/V1_O1_220914_all_results.csv')\n"
      ],
      "metadata": {
        "id": "ds4GygLx7Day"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of predicted classes"
      ],
      "metadata": {
        "id": "DA1XQaWFi-Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to get predicted classes and samples and the unpredicted ones.\n",
        "\n",
        "\n",
        "def analyze_predictions(report, experiment, datatype):\n",
        "\n",
        "  test =  report.copy()\n",
        "  #Drop last 3 rows (accuracy, etc.)\n",
        "  test = test.iloc[:-3]\n",
        "  #print rows, where recall is zero and support ist not zero (otherwise the class does not exist in the dataset)\n",
        "  zero = test[(test[\"recall\"] == 0.0) & (test[\"support\"] != 0)]\n",
        "  notzero = test[(test[\"recall\"] != 0.0) & (test[\"support\"] != 0)]\n",
        "\n",
        "  #unpredicted samples\n",
        "  unpredicted_samples = zero['support'].sum()\n",
        "  unpredicted_samples\n",
        "\n",
        "  #unpredictec classes: classes which were never predicted, although they existed\n",
        "  unpredicted_classes = zero.index.values\n",
        "  unpredicted_classes_sum = len(unpredicted_classes)\n",
        "\n",
        "  #predicted classes\n",
        "  predicted_classes = notzero.index.values\n",
        "  predicted_classes_sum = len(predicted_classes)\n",
        "\n",
        "  #predicted classes with at least one correctly predicted sample\n",
        "  predicted_classes = len(test[test[\"recall\"] != 0.0])\n",
        "\n",
        "  #Make data frame\n",
        "  df = pd.DataFrame([[experiment, datatype, predicted_classes_sum, unpredicted_classes_sum, unpredicted_samples]], columns = ['Experiment','Data','PredictedClasses', 'UnpredictedClasses', 'UnpredictedSamples'])\n",
        "  #print(df)\n",
        "\n",
        "  #Return\n",
        "  return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qkut64ttjA6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyze valid reports\n",
        "\n",
        "v1_analyze_valid = analyze_predictions(v1_valid_report, experiment = \"V1\", datatype = \"Valid\")\n",
        "v2_analyze_valid = analyze_predictions(v2_valid_report, experiment = \"V2\", datatype = \"Valid\")\n",
        "v3a_analyze_valid = analyze_predictions(v3a_valid_report, experiment = \"V3a\", datatype = \"Valid\")\n",
        "v3b_analyze_valid = analyze_predictions(v3b_valid_report, experiment = \"V3b\", datatype = \"Valid\")\n",
        "v4_analyze_valid = analyze_predictions(v4_valid_report, experiment = \"V4\", datatype = \"Valid\")\n",
        "v5_analyze_valid = analyze_predictions(v5_valid_report, experiment = \"V5\", datatype = \"Valid\")\n",
        "v6_analyze_valid = analyze_predictions(v6_valid_report, experiment = \"V6\", datatype = \"Valid\")\n",
        "v7_analyze_valid = analyze_predictions(v7_valid_report, experiment = \"V7\", datatype = \"Valid\")\n",
        "v8_analyze_valid = analyze_predictions(v8_valid_report, experiment = \"V8\", datatype = \"Valid\")\n",
        "v9_analyze_valid = analyze_predictions(v9_valid_report, experiment = \"V9\", datatype = \"Valid\")\n",
        "v10_analyze_valid = analyze_predictions(v10_valid_report, experiment = \"V10\", datatype = \"Valid\")\n",
        "v3afs_analyze_valid = analyze_predictions(v3afs_valid_report, experiment = \"V3afs\", datatype = \"Valid\") #with feature selection\n",
        "v3bfs_analyze_valid = analyze_predictions(v3bfs_valid_report, experiment = \"V3bfs\", datatype = \"Valid\") #with feature selection\n",
        "m1_analyze_valid = analyze_predictions(m1_valid_report, experiment = \"M1fs\", datatype = \"Valid\") #with feature selection\n",
        "o1_analyze_valid = analyze_predictions(o1_valid_report, experiment = \"O1\", datatype = \"Valid\")\n",
        "\n",
        "report_analyze_valid = pd.concat([v1_analyze_valid, v2_analyze_valid, v3a_analyze_valid, v3b_analyze_valid, v4_analyze_valid, v5_analyze_valid, v6_analyze_valid, v7_analyze_valid, v8_analyze_valid,v9_analyze_valid, v10_analyze_valid,v3afs_analyze_valid,v3bfs_analyze_valid, m1_analyze_valid, o1_analyze_valid], axis = 0)\n",
        "print(report_analyze_valid)\n",
        "\n",
        "\n",
        "#Analyze test reports\n",
        "\n",
        "v1_analyze_test = analyze_predictions(v1_test_report, experiment = \"V1\", datatype = \"Test\")\n",
        "v2_analyze_test = analyze_predictions(v2_test_report, experiment = \"V2\", datatype = \"Test\")\n",
        "v3a_analyze_test = analyze_predictions(v3a_test_report, experiment = \"V3a\", datatype = \"Test\")\n",
        "v3b_analyze_test = analyze_predictions(v3b_test_report, experiment = \"V3b\", datatype = \"Test\")\n",
        "v4_analyze_test = analyze_predictions(v4_test_report, experiment = \"V4\", datatype = \"Test\")\n",
        "v5_analyze_test = analyze_predictions(v5_test_report, experiment = \"V5\", datatype = \"Test\")\n",
        "v6_analyze_test = analyze_predictions(v6_test_report, experiment = \"V6\", datatype = \"Test\")\n",
        "v7_analyze_test = analyze_predictions(v7_test_report, experiment = \"V7\", datatype = \"Test\")\n",
        "v8_analyze_test = analyze_predictions(v8_test_report, experiment = \"V8\", datatype = \"Test\")\n",
        "v9_analyze_test = analyze_predictions(v9_test_report, experiment = \"V9\", datatype = \"Test\")\n",
        "v10_analyze_test = analyze_predictions(v10_test_report, experiment = \"V10\", datatype = \"Test\")\n",
        "v3afs_analyze_test = analyze_predictions(v3afs_test_report, experiment = \"V3afs\", datatype = \"Test\") #with feature selection\n",
        "v3bfs_analyze_test = analyze_predictions(v3bfs_test_report, experiment = \"V3bfs\", datatype = \"Test\") #with feature selection\n",
        "m1_analyze_test = analyze_predictions(m1_test_report, experiment = \"M1fs\", datatype = \"Test\") #with feature selection\n",
        "o1_analyze_test = analyze_predictions(o1_test_report, experiment = \"O1\", datatype = \"Test\")\n",
        "\n",
        "report_analyze_test = pd.concat([v1_analyze_test, v2_analyze_test, v3a_analyze_test, v3b_analyze_test, v4_analyze_test, v5_analyze_test, v6_analyze_test, v7_analyze_test, v8_analyze_test,v9_analyze_test,v10_analyze_test,v3afs_analyze_test,v3bfs_analyze_test, m1_analyze_test, o1_analyze_test], axis = 0)\n",
        "print(report_analyze_test)\n",
        "\n",
        "#Bind both reports\n",
        "report_analyze = pd.concat([report_analyze_test, report_analyze_valid.iloc[:, 1:]], axis = 1)\n",
        "report_analyze\n"
      ],
      "metadata": {
        "id": "-XpmTvNVpBBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save\n",
        "\n",
        "report_analyze.to_pickle('0_Ergebnisse/Overall/V1_O1_220914_report_analyze')\n",
        "report_analyze.to_csv('0_Ergebnisse/Overall/V1_O1_220914_report_analyze.csv')"
      ],
      "metadata": {
        "id": "1yZSpz8Jyleq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v3bfscw_valid_report"
      ],
      "metadata": {
        "id": "Hdy7NNeKexQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v3bfscw_analyze_valid = analyze_predictions(v3bfscw_valid_report, experiment = \"C2.3\", datatype = \"Valid\")\n",
        "\n",
        "print(v3bfscw_analyze_valid)"
      ],
      "metadata": {
        "id": "APMVMEPG4NAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v3bfscw_analyze_test = analyze_predictions(v3bfscw_test_report, experiment = \"C2.3\", datatype = \"Test\")\n",
        "\n",
        "print(v3bfscw_analyze_test)"
      ],
      "metadata": {
        "id": "JLbhNGAE4SBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrices"
      ],
      "metadata": {
        "id": "vcJQfk-lHbqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for export (matrices are plotted in R)\n",
        "\n",
        "def dataexportvalid_cm(results, classlist):\n",
        "\n",
        "  #Get data from results\n",
        "  true = results[results['Y_valid'].notna()].Y_valid.astype(int)\n",
        "  pred = results[results[\"Pred_valid\"].notna()].Pred_valid.astype(int)\n",
        "\n",
        "  #Map true accident types\n",
        "  true_classlist = pd.DataFrame({\"TrueClasses\": classlist})\n",
        "  true_classlist[\"Y_valid\"] = true_classlist.index\n",
        "\n",
        "  true_classes = pd.merge(true, true_classlist, on = \"Y_valid\", how = \"left\")\n",
        "\n",
        "  #Map pred accident types\n",
        "  pred_classlist = pd.DataFrame({\"PredClasses\": classlist})\n",
        "  pred_classlist[\"Pred_valid\"] = pred_classlist.index\n",
        "\n",
        "  pred_classes = pd.merge(pred, pred_classlist, on = \"Pred_valid\", how = \"left\")\n",
        "\n",
        "  #Combine to final dataframe\n",
        "  export = pd.concat([true_classes, pred_classes], axis = 1)\n",
        "  print(export)\n",
        "\n",
        "  #Return\n",
        "  return export\n"
      ],
      "metadata": {
        "id": "vogiBSH-tZqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create export data"
      ],
      "metadata": {
        "id": "LPJfDeUAzRW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v3a_valid_preds = dataexportvalid_cm(v3a_results, classes_list)"
      ],
      "metadata": {
        "id": "4PRhes1MycbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v3b_valid_preds = dataexportvalid_cm(v3b_results, classes_list)"
      ],
      "metadata": {
        "id": "vQOdvWpazq9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d1fs_valid_preds = dataexportvalid_cm(d1fs_results, classes_list_freq)"
      ],
      "metadata": {
        "id": "RGvWGRbU0Frx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save export data"
      ],
      "metadata": {
        "id": "r6K87usJzTZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save for creating diagrams in R with ggplot2 (optional)\n",
        "\n",
        "#B1.4\n",
        "v3a_valid_preds.to_csv('0_Ergebnisse/Overall/V3a_B1.4_220708_valid_preds.csv')\n",
        "\n",
        "#C2.1\n",
        "v3b_valid_preds.to_csv('0_Ergebnisse/Overall/V3b_C2.1_220629_valid_preds.csv')\n",
        "\n",
        "\n",
        "#D1\n",
        "d1fs_valid_preds.to_csv('0_Ergebnisse/Overall/D1fs_D1_221005_valid_preds.csv')"
      ],
      "metadata": {
        "id": "0vbznRN5y0-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WordCloud"
      ],
      "metadata": {
        "id": "OnvZwmvjp3xA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Overall word cloud"
      ],
      "metadata": {
        "id": "DvuExeXC26pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud"
      ],
      "metadata": {
        "id": "jMROSM56pLVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "dm_eUBRTp6AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine single files to create wordcloud over the whole data without distinguishing between train, test and valid data\n",
        "overall_data = pd.concat([train_bbgcpure_three, test_bbgcpure_three, valid_bbgcpure_three], axis = 0)\n"
      ],
      "metadata": {
        "id": "iQ2YKU3EzROE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_bbgcpure_three.Description\n",
        "#Prepare data for wordcloud\n",
        "\n",
        "text = overall_data.Description\n",
        "textnp = train_bbgcpure_three.Description.to_numpy() #Length: 5198\n",
        "#textnpcop = textnp.flatten().copy()\n",
        "\n",
        "#Convert numpy to string\n",
        "string = np.array2string(textnp, threshold = np.inf) #3608\n",
        "#split string into single words\n",
        "word_list = string.split()\n"
      ],
      "metadata": {
        "id": "qqJs50Hxp_ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Not interesting words\n",
        "remove = \"die der das und den dem des Die Der Den Dem Des Das ihrem seinem mehr es Es kam wird wurde ein \"\n",
        "remove_list = remove.split()\n",
        "\n",
        "\n",
        "#Update stopwords\n",
        "STOPWORDS.update(remove_list)\n",
        "\n",
        "#Constraint to 100 words without stopwords\n",
        "wordcloud = WordCloud(relative_scaling = 0.5, colormap = \"gray\", background_color = \"white\", normalize_plurals = False, width =1600, height = 800, max_words = 100).generate(string)\n",
        "\n",
        "plt.figure(figsize=(20,10), facecolor='k')\n",
        "plt.imshow(wordcloud, interpolation = \"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()\n",
        "#plt.savefig('0_Ergebnisse/Overall/220713_Wordcloud_traindata.png')"
      ],
      "metadata": {
        "id": "7SKnvvtWpbnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get most frequent words from word list\n",
        "\n",
        "#Apply counter\n",
        "word_count = Counter(word_list)\n",
        "\n",
        "#Get most frequent words\n",
        "most_frequent = word_count.most_common(100)\n",
        "most_frequent"
      ],
      "metadata": {
        "id": "t8HAOb_ztihx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Words: 201 | 222 | 231\n",
        "\n",
        "201 = Label 0 |\n",
        "222 = Label 12 |\n",
        "231 = Label 17 |"
      ],
      "metadata": {
        "id": "zimWyt0r29FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train_bbgcpure_three.Description\n",
        "#Prepare data for wordcloud\n",
        "\n",
        "text_train_201 = train_bbgcpure_three[train_bbgcpure_three['AccidentType'] == 0].Description\n",
        "text_train_222 = train_bbgcpure_three[train_bbgcpure_three['AccidentType'] == 12].Description\n",
        "text_train_221 = train_bbgcpure_three[train_bbgcpure_three['AccidentType'] == 11].Description\n",
        "text_train_231 = train_bbgcpure_three[train_bbgcpure_three['AccidentType'] == 17].Description\n",
        "\n",
        "#Get text\n",
        "textnp_201 = text_train_201.to_numpy()\n",
        "textnp_221 = text_train_221.to_numpy()\n",
        "textnp_222 = text_train_222.to_numpy()\n",
        "textnp_231 = text_train_231.to_numpy()\n",
        "\n",
        "#Convert numpy to string\n",
        "string_201 = np.array2string(textnp_201, threshold = np.inf)\n",
        "string_221 = np.array2string(textnp_221, threshold = np.inf)\n",
        "string_222 = np.array2string(textnp_222, threshold = np.inf)\n",
        "string_231 = np.array2string(textnp_231, threshold = np.inf)\n",
        "\n",
        "\n",
        "#split string into single words\n",
        "wordlist_201 = string_201.split()\n",
        "wordlist_221 = string_221.split()\n",
        "wordlist_222 = string_222.split()\n",
        "wordlist_231 = string_231.split()"
      ],
      "metadata": {
        "id": "ZF-sgvUq3PCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Stopwords\n",
        "\n",
        "stopwords = \"die der das und den dem des Die Der Den Dem Des Das ihrem seinem mehr es Es kam wird wurde ein Beteiligter\"\n",
        "stopword_list = stopwords.split()\n",
        "\n",
        "\n",
        "def remove_stopwords(wordlist, stopword_list):\n",
        "\n",
        "  listcopy = wordlist.copy()\n",
        "\n",
        "  for stopword in stopword_list:\n",
        "\n",
        "    while stopword in listcopy:listcopy.remove(stopword)\n",
        "\n",
        "  return listcopy\n",
        "\n",
        "\n",
        "wordlistclean_201 = remove_stopwords(wordlist_201, stopword_list)\n",
        "wordlistclean_221 = remove_stopwords(wordlist_221, stopword_list)\n",
        "wordlistclean_222 = remove_stopwords(wordlist_222, stopword_list)\n",
        "wordlistclean_231 = remove_stopwords(wordlist_231, stopword_list)"
      ],
      "metadata": {
        "id": "D6NIv2Y2MuoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count\n",
        "#Apply counter\n",
        "counter_201 = Counter(wordlistclean_201)\n",
        "print(counter_201)\n",
        "counter_221 = Counter(wordlistclean_221)\n",
        "print(counter_221)\n",
        "counter_222 = Counter(wordlistclean_222)\n",
        "print(counter_222)\n",
        "counter_231 = Counter(wordlistclean_231)\n",
        "print(counter_231)\n"
      ],
      "metadata": {
        "id": "L75anhvWLMW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get most frequent words\n",
        "\n",
        "freq = 17 #Number of most frequent words\n",
        "\n",
        "most_201 = counter_201.most_common(freq)\n",
        "print(most_201)\n",
        "most_221 = counter_221.most_common(freq)\n",
        "print(most_221)\n",
        "most_222 = counter_222.most_common(freq)\n",
        "print(most_222)\n",
        "most_231 = counter_231.most_common(freq)\n",
        "print(most_231)"
      ],
      "metadata": {
        "id": "KFTJqVNKPca_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to Dataframes\n",
        "\n",
        "mostpd_201 = pd.DataFrame.from_records(most_201, columns = ['Word201', 'Freq201'])\n",
        "mostpd_221 = pd.DataFrame.from_records(most_221, columns = ['Word221', 'Freq221'])\n",
        "mostpd_222 = pd.DataFrame.from_records(most_222, columns = ['Word222', 'Freq222'])\n",
        "mostpd_231 = pd.DataFrame.from_records(most_231, columns = ['Word231', 'Freq231'])\n",
        "\n",
        "most_all = pd.concat([mostpd_201, mostpd_221, mostpd_222, mostpd_231], axis = 1)\n",
        "print(most_all)"
      ],
      "metadata": {
        "id": "pdWCXlgOQeET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save all results\n",
        "most_all.to_csv(('0_Ergebnisse/Overall/17MostFrequentWords_201_221_222_231_trainingdata.csv'))"
      ],
      "metadata": {
        "id": "OC8o4FBbdDPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqlist_201 = set(list(mostpd_201.Word201))\n",
        "freqlist_221 = set(list(mostpd_221.Word221))\n",
        "freqlist_222 = set(list(mostpd_222.Word222))\n",
        "freqlist_231 = set(list(mostpd_231.Word231))\n",
        "\n",
        "#Intersection of list 222 and 231\n",
        "int201_231 = list(freqlist_201.intersection(freqlist_231))\n",
        "print(int201_231)\n",
        "int222_231 = list(freqlist_222.intersection(freqlist_231))\n",
        "print(int222_231)\n",
        "int221_222 = list(freqlist_221.intersection(freqlist_222))\n",
        "print(int221_222)\n",
        "\n",
        "#Difference between the lists\n",
        "diff201_231 = freqlist_201^freqlist_231\n",
        "#print(diff201_231)\n",
        "diff222_231 = freqlist_222^freqlist_231\n",
        "#print(diff222_231)\n",
        "diff221_222 = freqlist_221^freqlist_222\n",
        "print(\"diff221_222\")\n",
        "print(diff221_222)"
      ],
      "metadata": {
        "id": "r06dnozcRx9A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}